{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Feature Engineering com s√©ries de pre√ßos de ativos financeiros\"\n",
        "format:\n",
        "  html:\n",
        "    css: styles.css\n",
        "    self-contained: true\n",
        "    toc: true\n",
        "    code-fold: true\n",
        "    df-print: paged\n",
        "editor: visual\n",
        "---\n",
        "\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "<left> ![](https://raw.githubusercontent.com/profrhozon/site/main/logo_FAE.png){width=\"15%\"} </left>\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "```         \n",
        "```\n",
        "\n",
        "::: callout-note\n",
        "## Resumo\n",
        "\n",
        "Este documento apresenta o processo de Feature Engineering aplicado a dados de s√©ries temporais financeiras, contemplando:\n",
        "\n",
        "-   Download de dados de commodities via `yahooquery`\n",
        "-   C√°lculo de log-retornos e an√°lise de distribui√ß√µes (assimetria, histograma)\n",
        "-   Modelagem GARCH(1,1) para estimar vari√¢ncia condicional\n",
        "-   Visualiza√ß√£o de resultados utilizando `timetk` no R\n",
        ":::\n",
        "\n",
        "## üìå Introdu√ß√£o: Feature Engineering em dados de s√©ries financeiras\n",
        "\n",
        "\n",
        "```{=html}\n",
        "<!-- \n",
        "Escrever a intro do documento aqui ....\n",
        "-->\n",
        "```\n",
        "\n",
        "\n",
        "### Medindo a Volatilidade: Com e Sem GARCH\n",
        "\n",
        "A abordagem tradicional calcula a volatilidade como o desvio padr√£o dos retornos hist√≥ricos em uma janela m√≥vel de tamanho $N$: (dias de negocia√ß√£o)\n",
        "\n",
        "$$\n",
        "\\sigma_{\\text{hist}} = \\sqrt{\\frac{1}{N-1}\\sum_{i=1}^{N}(r_i - \\bar{r})^2}\n",
        "$$\n",
        "\n",
        "**Vantagens:**\n",
        "\n",
        "-   Simplicidade e facilidade de implementa√ß√£o.\n",
        "\n",
        "**Desvantagens:**\n",
        "\n",
        "-   Assume volatilidade constante durante a janela. (ou seja precisa de um range dias e n√£o √© capaz de medir o desvio ou o risco/volatilidade de um dia pro outro.)\n",
        "\n",
        "-   N√£o capta a persist√™ncia dos choques (efeito de clustering).\n",
        "\n",
        "-   N√£o reage dinamicamente a choques recentes.\n",
        "\n",
        "### Volatilidade com o GARCH\n",
        "\n",
        "O modelo GARCH(1,1) estima a vari√¢ncia condicional de forma din√¢mica:\n",
        "\n",
        "$$\n",
        "\\sigma_t^2 = \\omega + \\alpha \\epsilon_{t-1}^2 + \\beta \\sigma_{t-1}^2.\n",
        "$$\n",
        "\n",
        "Onde: - $\\epsilon_{t-1}^2$ reflete o impacto dos choques recentes. - $\\sigma_{t-1}^2$ reflete a persist√™ncia da volatilidade do per√≠odo anterior. - $\\omega > 0$, $\\alpha \\geq 0$ e $\\beta \\geq 0$ s√£o par√¢metros estimados.\n",
        "\n",
        "A soma $\\alpha + \\beta$ mede a persist√™ncia total da volatilidade:\n",
        "\n",
        "-   **Pr√≥ximo de 1:** Choques t√™m efeitos duradouros; a volatilidade permanece alta por v√°rios per√≠odos.\n",
        "\n",
        "-   **Menor que 1:** Os choques se dissipam mais rapidamente; a volatilidade retorna ao seu n√≠vel m√©dio mais r√°pido.\n",
        "\n",
        "**Vantagens do GARCH:**\n",
        "\n",
        "-   Modela a volatilidade de forma din√¢mica.\n",
        "\n",
        "-   Captura o efeito de \"clustering\" dos choques.\n",
        "\n",
        "-   Permite previs√µes mais precisas da volatilidade futura.\n",
        "\n",
        "**Desvantagens do GARCH:**\n",
        "\n",
        "-   Requer estima√ß√£o de par√¢metros e pressup√µe uma estrutura espec√≠fica para a volatilidade.\n",
        "\n",
        "-   Pode ser sens√≠vel √† escolha da distribui√ß√£o dos res√≠duos (por exemplo, normal vs. $t$ de Student).\n",
        "\n",
        "::: panel-tabset\n",
        "## Python\n"
      ],
      "id": "e2cd872f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#import yfinance as yf\n",
        "from yahooquery import Ticker\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "#import seaborn as sns\n",
        "from datetime import datetime\n",
        "from arch import arch_model # Lib do Python pra estimar as volatilidades (ARCH/GARCH)\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "from plotnine import ggplot, aes, geom_line, facet_wrap, labs, theme, element_text, theme_minimal"
      ],
      "id": "c17c1f5f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Tickers for portfolio\n",
        "TICKERS = [\n",
        "  \"BRFS3.SA\",\n",
        "  \"JBSS3.SA\",\n",
        "  \"BEEF3.SA\",\n",
        "  \"MRFG3.SA\",\n",
        "  \"TSN\",\n",
        "  \"HRL\",\n",
        "  \"GIS\"\n",
        "]\n",
        "\n",
        "# Baixar os dados hist√≥ricos com yahooquery\n",
        "tickers = Ticker(TICKERS)\n",
        "data = tickers.history(period=\"5y\")\n",
        "\n",
        "# Resetar o √≠ndice corretamente\n",
        "data = data.reset_index()\n",
        "\n",
        "# O yahooquery retorna um MultiIndex, ent√£o √© preciso garantir que a coluna \"date\" exista corretamente\n",
        "if \"date\" not in data.columns:\n",
        "    raise ValueError(\"A coluna 'date' n√£o foi encontrada no dataset! Verifique a estrutura do DataFrame.\")\n",
        "\n",
        "# Selecionar apenas as colunas de interesse e reformatar\n",
        "portfolio_prices = data.pivot(index=\"date\", columns=\"symbol\", values=\"close\").reset_index()\n",
        "\n",
        "# Garantir que n√£o h√° valores ausentes\n",
        "portfolio_prices.dropna(inplace=True)\n",
        "\n",
        "portfolio_prices.head()"
      ],
      "id": "915120d6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotamos os gr√°ficos das s√©ries temporais de pre√ßos\n",
        "\n",
        "```         \n",
        "```\n"
      ],
      "id": "5e16bbc3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# Retire o comando #| eval: false pra conseguir executar essa celula dentro do Quarto\n",
        "import plotly.express as px\n",
        "\n",
        "# Certifique-se de que a coluna \"date\" est√° em formato datetime\n",
        "portfolio_prices['date'] = pd.to_datetime(portfolio_prices['date'])\n",
        "\n",
        "# Transformar os pre√ßos para o formato longo (melt) para facilitar o plot\n",
        "prices_long = portfolio_prices.melt(id_vars='date', var_name='Ativo', value_name='Valor')\n",
        "\n",
        "fig = px.line(prices_long, x='date', y='Valor', color='Ativo',\n",
        "              title='S√©ries Temporais de Pre√ßos')\n",
        "fig.show()\n"
      ],
      "id": "ecf268bd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "mas essas s√©ries temporais tem um problema....os pre√ßos est√£o em seus \"n√≠veis\", e isso em an√°lise de s√©ries temporais n√£o √© o ideal. Precisamos trabalhar com as s√©ries estacion√°rias e analisar os retornos dos pre√ßos.\n",
        "\n",
        "*A stationary time series is one whose statistical properties do not depend on the time at which the series is observed.18 Thus, time series with trends, or with seasonality, are not stationary ‚Äî the trend and seasonality will affect the value of the time series at different times. On the other hand, a white noise series is stationary ‚Äî it does not matter when you observe it, it should look much the same at any point in time.*\n",
        "\n",
        "*Some cases can be confusing ‚Äî a time series with cyclic behaviour (but with no trend or seasonality) is stationary. This is because the cycles are not of a fixed length, so before we observe the series we cannot be sure where the peaks and troughs of the cycles will be.*\n",
        "\n",
        "*In general, a stationary time series will have no predictable patterns in the long-term. Time plots will show the series to be roughly horizontal (although some cyclic behaviour is possible), with constant variance.*\n",
        "\n",
        "(Hyndman, R.J., & Athanasopoulos, G. (2021) **Forecasting: principles and practice**, 3rd edition, OTexts: Melbourne, Australia. <https://otexts.com/fpp3/stationarity.html>. Accessed on 2025/march.)\n",
        "\n",
        "Estacionar uma s√©rie temporal econ√¥mica √© importante pois:\n",
        "\n",
        "*\"Uma s√©rie temporal √© dita estacion√°ria se suas propriedades estat√≠sticas, como a m√©dia e a vari√¢ncia, permanecem constantes ao longo do tempo. Em outras palavras, n√£o h√° uma tend√™ncia determin√≠stica na s√©rie, e as flutua√ß√µes ao redor da m√©dia s√£o est√°veis. Se a s√©rie n√£o for estacion√°ria, suas previs√µes podem ser pouco confi√°veis, pois os padr√µes passados podem n√£o ser representativos do futuro.\"* (Gujarati & Porter, 2009, p. 753).\n"
      ],
      "id": "558f5758"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calcular os log-retornos\n",
        "log_returns = portfolio_prices.copy()\n",
        "log_returns.iloc[:, 1:] = np.log(portfolio_prices.iloc[:, 1:]).diff()\n",
        "\n",
        "# Remover a primeira linha que cont√©m NaN ap√≥s a diferencia√ß√£o\n",
        "log_returns = log_returns.dropna()"
      ],
      "id": "e02ced20",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```         \n",
        "```\n"
      ],
      "id": "bd0d85cd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# Retire o comando #| eval: false pra conseguir executar essa celula dentro do Quarto\n",
        "# Garantir que a coluna \"date\" esteja em formato datetime\n",
        "log_returns['date'] = pd.to_datetime(log_returns['date'])\n",
        "\n",
        "# Transformar para formato longo\n",
        "log_returns_long = log_returns.melt(id_vars='date', var_name='Ativo', value_name='Log_Retorno')\n",
        "\n",
        "fig = px.line(log_returns_long, x='date', y='Log_Retorno', color='Ativo',\n",
        "              title='S√©ries Temporais de Log-Retornos')\n",
        "fig.show()\n"
      ],
      "id": "9d1a5c9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analisar as distribui√ß√µes dos retornos √© fundamental para entender o comportamento estat√≠stico dos ativos financeiros. Essa an√°lise nos permite identificar caracter√≠sticas importantes, como a presen√ßa de assimetria e caudas pesadas. <mark>Por exemplo, uma assimetria negativa indica que os retornos tendem a oscilar mais para valores baixos, sugerindo um risco maior de perdas acentuadas, enquanto uma assimetria positiva indica uma tend√™ncia para oscila√ß√µes para valores mais altos</mark>. Al√©m disso, observar a forma da distribui√ß√£o ajuda a avaliar se a hip√≥tese de normalidade √© v√°lida ou se √© necess√°rio adotar distribui√ß√µes alternativas, como a distribui√ß√£o $t$ de Student, que captura melhor a ocorr√™ncia de eventos extremos. Essa compreens√£o √© crucial para a modelagem de riscos, desenvolvimento de estrat√©gias de investimento e aprimoramento dos modelos econom√©tricos utilizados na previs√£o dos pre√ßos.\n"
      ],
      "id": "db9feb3e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Seleciona apenas as colunas dos ativos (excluindo a coluna \"date\")\n",
        "ativos = log_returns.columns[1:]\n",
        "\n",
        "# Calcula a assimetria para cada ativo\n",
        "skewness = log_returns[ativos].skew()\n",
        "\n",
        "# Cria um DataFrame para visualizar os resultados\n",
        "skew_table = pd.DataFrame({\n",
        "    'Ativo': skewness.index,\n",
        "    'Skewness': skewness.values\n",
        "})\n",
        "\n",
        "# Adiciona a coluna que indica a dire√ß√£o da assimetria\n",
        "skew_table['Direcao'] = skew_table['Skewness'].apply(\n",
        "    lambda x: '√Ä direita' if x > 0 else ('√Ä esquerda' if x < 0 else 'Sim√©trica')\n",
        ")\n",
        "\n",
        "# Exibe a tabela atualizada\n",
        "skew_table"
      ],
      "id": "2ee1906c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Agora teremos que ver se o range de nossa sele√ß√£o de an√°lise ter√° mais retornos positivos do que negativos, olhando os histogramas:\n",
        "\n",
        "```         \n",
        "```\n"
      ],
      "id": "3401de42"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# Retire o comando #| eval: false caso queira executar essa celula\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Transformar os log-retornos para formato longo (melt)\n",
        "log_returns_long = log_returns.melt(id_vars=[\"date\"], var_name=\"Ativo\", value_name=\"Log_Retorno\")\n",
        "\n",
        "# Criar gr√°fico com Seaborn\n",
        "plt.figure(figsize=(12, 8))\n",
        "g = sns.FacetGrid(log_returns_long, col=\"Ativo\", col_wrap=2, sharex=False, sharey=False)\n",
        "g.map_dataframe(sns.histplot, x=\"Log_Retorno\", kde=True, bins=30, color=\"black\", alpha=0.5)\n",
        "\n",
        "# Ajustar t√≠tulo dos gr√°ficos\n",
        "g.set_titles(col_template=\"{col_name}\")\n",
        "\n",
        "# Melhorar layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "f5f180b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como medida de risco, utilizamos as vari√¢ncias condicionais (volatilidades) para lidar melhor com a varia√ß√£o di√°ria dos log-retornos dos pre√ßos.\n",
        "\n",
        "### Volatilidade com desvio-padr√£o\n",
        "\n",
        "A volatilidade hist√≥rica pode ser medida como o desvio-padr√£o dos log-retornos calculado em uma janela m√≥vel de $N$ dias de negocia√ß√£o.\n",
        "\n",
        "Neste exemplo, adotamos uma janela m√≥vel de 5 dias (aproximadamente uma semana de negocia√ß√£o. Para um m√™s de negocia√ß√£o, utilizar 22 e um ano 252) para capturar a volatilidade di√°ria dos ativos.\n",
        "\n",
        "**Vantagens:**\n",
        "\n",
        "-   Simplicidade e facilidade de implementa√ß√£o.\n",
        "\n",
        "**Desvantagens:**\n",
        "\n",
        "-   Assume volatilidade constante durante a janela.\n",
        "\n",
        "-   N√£o capta a persist√™ncia dos choques.\n",
        "\n",
        "-   N√£o reage dinamicamente a choques recentes.\n"
      ],
      "id": "00d16e93"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calcular a volatilidade hist√≥rica com uma janela m√≥vel de 5 dias\n",
        "\n",
        "# Supondo que 'log_returns' j√° foi calculado e possui a coluna 'date' e os log-retornos dos ativos\n",
        "window = 5\n",
        "\n",
        "# Cria um DataFrame para armazenar a volatilidade hist√≥rica\n",
        "vol_hist = pd.DataFrame({'date': log_returns[\"date\"]})\n",
        "\n",
        "# Calcula o desvio-padr√£o m√≥vel (volatilidade) para cada ativo\n",
        "for col in log_returns.columns[1:]:\n",
        "    vol_hist[col] = log_returns[col].rolling(window=window).std()\n",
        "\n",
        "# Exibe as ultimas linhas do DataFrame de volatilidade hist√≥rica\n",
        "#print(vol_hist.head()) # 5 primeiros ser√£o NaN\n",
        "print(vol_hist.tail())"
      ],
      "id": "c1a02edc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotando temos:\n",
        "\n",
        "```         \n",
        "```\n"
      ],
      "id": "0cf1c9ab"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# Retire o comando #| eval: false pra conseguir executar essa celula dentro do Quarto\n",
        "# Certificar que \"date\" √© datetime (j√° feito)\n",
        "vol_hist['date'] = pd.to_datetime(vol_hist['date'])\n",
        "\n",
        "# Transformar para formato longo\n",
        "vol_hist_long = vol_hist.melt(id_vars='date', var_name='Ativo', value_name='Volatilidade_Hist')\n",
        "\n",
        "fig = px.line(vol_hist_long, x='date', y='Volatilidade_Hist', color='Ativo',\n",
        "              title='Volatilidade Hist√≥rica (Desvio-Padr√£o) com janela de 5 dias')\n",
        "fig.show()"
      ],
      "id": "cf65c3c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Volatilidade com GARCH(1,1)\n",
        "\n",
        "O desvio-padr√£o assume que precisaremos de um range maior do que 2 pontos no tempo, o que limita nossa an√°lise pois a incompatibiliza, uma vez que precisaremos comparar os riscos di√°rios x retornos di√°rios (como feito anteriormente). Ou seja, n√£o podemos comparar retornos dia-a-dia x volatilidades (risco) de 5 em 5 dias p. ex.\n",
        "\n",
        "Os modelos heteroced√°sticos (da fam√≠lia ARCH) estimam a vari√¢ncia condicional dos nossos dados, ou seja, em linguagem de finan√ßas, eles s√£o capazes de capturar as volatilidades ou risco dos retornos dos pre√ßos de ativos financeiros ponto a ponto no tempo, ou seja, dia a dia.\n",
        "\n",
        "O modelo GARCH(1,1) com distribui√ß√£o $t$ assim√©trica n√£o est√° dispon√≠vel diretamente na maioria das bibliotecas Python. No entanto, podemos utilizar um GARCH(1,1) com uma distribui√ß√£o $t$ padr√£o para estimar a vari√¢ncia condicional. O modelo √© representado por:\n",
        "\n",
        "$$\n",
        "r_t = \\mu + \\epsilon_t\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\epsilon_t = \\sigma_t z_t, \\quad z_t \\sim t_{\\nu}(0, 1)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\sigma_t^2 = \\omega + \\alpha \\epsilon_{t-1}^2 + \\beta \\sigma_{t-1}^2\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "\n",
        "-   $r_t$ √© o log-retorno no tempo $t$.\n",
        "-   $\\mu$ √© a m√©dia dos retornos.\n",
        "-   $\\epsilon_t$ √© o termo de erro, condicionado √†s informa√ß√µes passadas.\n",
        "-   $\\sigma_t^2$ √© a vari√¢ncia condicional no tempo $t$.\n",
        "-   $\\omega, \\alpha, \\beta$ s√£o os par√¢metros a serem estimados, com $\\omega > 0, \\alpha \\geq 0, \\beta \\geq 0$.\n",
        "-   $z_t$ segue uma distribui√ß√£o $t$ de Student com $ŒΩ$ graus de liberdade para capturar as caudas pesadas observadas em retornos financeiros.\n",
        "\n",
        "A soma $\\alpha + \\beta$ √© frequentemente utilizada para medir a persist√™ncia da volatilidade: quanto mais pr√≥ximos de 1, maior a persist√™ncia dos choques na volatilidade.\n",
        "\n",
        "Vamos estimar a vari√¢ncia condicional ($\\sigma^2_{t}$ ) para cada ativo:\n"
      ],
      "id": "9ebc6118"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Estimar o modelo GARCH(1,1) e salvar vari√¢ncia condicional\n",
        "var_condicional = pd.DataFrame({\"date\": log_returns[\"date\"]})\n",
        "\n",
        "for col in log_returns.columns[1:]:\n",
        "    am = arch_model(log_returns[col], vol=\"Garch\", p=1, q=1, dist=\"t\")\n",
        "    res = am.fit(disp=\"off\")\n",
        "    var_condicional[col] = res.conditional_volatility ** 2\n",
        "\n",
        "var_condicional.head()"
      ],
      "id": "62132e92",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos avaliar os par√¢metros estimados do modelo:\n"
      ],
      "id": "00addb82"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inferir sobre os par√¢metros do modelo GARCH(1,1) para cada ativo do portf√≥lio\n",
        "\n",
        "params_list = []\n",
        "\n",
        "# Iterar sobre cada ativo (exceto a coluna 'date')\n",
        "for col in log_returns.columns[1:]:\n",
        "    am = arch_model(log_returns[col], vol=\"Garch\", p=1, q=1, dist=\"t\")\n",
        "    res = am.fit(disp=\"off\")\n",
        "    \n",
        "    par = res.params\n",
        "    alpha_val = par.get(\"alpha[1]\", None)\n",
        "    beta_val  = par.get(\"beta[1]\", None)\n",
        "    alpha_beta_sum = (alpha_val if alpha_val is not None else 0) + (beta_val if beta_val is not None else 0)\n",
        "    \n",
        "    # Interpreta√ß√£o curta\n",
        "    if alpha_beta_sum >= 0.9:\n",
        "        interp = f\"Alta persist√™ncia (Œ±+Œ≤ = {alpha_beta_sum:.4f}).\"\n",
        "    else:\n",
        "        interp = f\"Baixa/moderada persist√™ncia (Œ±+Œ≤ = {alpha_beta_sum:.4f}).\"\n",
        "    \n",
        "    params_list.append({\n",
        "         \"Ativo\": col,\n",
        "         \"mu\": par.get(\"mu\", None),\n",
        "         \"omega\": par.get(\"omega\", None),\n",
        "         \"alpha\": alpha_val,\n",
        "         \"beta\": beta_val,\n",
        "         \"alpha+beta\": alpha_beta_sum,\n",
        "         \"nu\": par.get(\"nu\", None),\n",
        "         \"Interpretacao\": interp\n",
        "    })\n",
        "\n",
        "garch_params = pd.DataFrame(params_list)"
      ],
      "id": "789e5f8e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A soma $\\alpha + \\beta$ √© um indicador crucial na modelagem GARCH para avaliar a persist√™ncia da volatilidade. Em termos pr√°ticos, os par√¢metros $\\alpha$ e $\\beta$ t√™m fun√ß√µes distintas:\n",
        "\n",
        "-   $\\alpha$: Representa o impacto dos choques recentes (a inova√ß√£o ou termo de erro $\\epsilon_{t-1}^2$ na volatilidade atual. Um valor mais alto de $\\alpha$ indica que choques recentes t√™m um efeito maior em aumentar a volatilidade.\n",
        "-   $\\beta$: Captura a persist√™ncia da volatilidade ao longo do tempo, ou seja, o efeito da volatilidade passada ($\\sigma_{t-1}^2)$ sobre a volatilidade presente. Valores maiores de $\\beta$ sugerem que a volatilidade tende a se manter elevada por um per√≠odo mais longo.\n",
        "\n",
        "Quando somamos esses dois par√¢metros, ou seja, quando calculamos $\\alpha + \\beta$, obtemos uma medida da persist√™ncia total da volatilidade:\n",
        "\n",
        "-   Se $\\alpha + \\beta$ estiver **pr√≥ximo de 1**, isso indica que os choques que afetam a volatilidade t√™m efeitos de longa dura√ß√£o. Em outras palavras, um choque na volatilidade tem um impacto que se dissipa muito lentamente, mantendo a volatilidade elevada por v√°rios per√≠odos.\n",
        "-   Se $\\alpha + \\beta$ for **significativamente menor que 1**, os efeitos dos choques s√£o de curta dura√ß√£o e a volatilidade retorna rapidamente ao seu n√≠vel m√©dio ap√≥s um impacto.\n",
        "\n",
        "Em alguns casos, quando $\\alpha + \\beta = 1$, o modelo √© denominado **IGARCH** (Integrated GARCH), o que implica que os choques t√™m efeitos persistentes permanentemente, ou seja, a volatilidade n√£o reverte para um valor m√©dio fixo.\n",
        "\n",
        "Esta caracter√≠stica √© particularmente importante na an√°lise de s√©ries financeiras, pois a persist√™ncia alta da volatilidade pode implicar maior risco de mercado e desafios na previs√£o dos retornos futuros. Assim, a soma $\\alpha + \\beta$ serve como uma medida de \"mem√≥ria\" dos choques, indicando se a volatilidade reage de forma passageira ou duradoura a eventos inesperados.\n",
        "\n",
        "Graficamente temos:\n",
        "\n",
        "```         \n",
        "```\n"
      ],
      "id": "ed9067d0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# Retire o comando #| eval: false pra conseguir executar essa celula dentro do Quarto\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Para o ativo \"ZC=F\"\n",
        "returns_zc = log_returns[['date', 'BEEF3.SA']].copy()\n",
        "vol_zc = var_condicional[['date', 'BEEF3.SA']].copy()\n",
        "\n",
        "# Converter \"date\" para datetime, se necess√°rio\n",
        "returns_zc['date'] = pd.to_datetime(returns_zc['date'])\n",
        "vol_zc['date'] = pd.to_datetime(vol_zc['date'])\n",
        "\n",
        "# Criar figura com dois subplots compartilhando o eixo x\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=1,\n",
        "    shared_xaxes=True,\n",
        "    vertical_spacing=0.05,\n",
        "    subplot_titles=(\"Retornos Di√°rios - BEEF3.SA\", \"Volatilidade Condicional (GARCH) - BEEF3.SA\")\n",
        ")\n",
        "\n",
        "# Adicionar o gr√°fico de retornos\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=returns_zc['date'], y=returns_zc['ZC=F'], mode='lines', name='Retornos'),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Adicionar o gr√°fico de volatilidade condicional\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=vol_zc['date'], y=vol_zc['ZC=F'], mode='lines', name='Volatilidade'),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,\n",
        "    width=900,\n",
        "    title_text=\"Retorno vs. Volatilidade (GARCH) - ZC=F\",\n",
        "    xaxis2_title=\"Data\",\n",
        "    yaxis1_title=\"Retorno\",\n",
        "    yaxis2_title=\"Volatilidade Condicional\"\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "id": "faf64823",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Em alguns casos, a vari√¢ncia condicional pode apresentar grandes oscila√ß√µes se houver outliers nos retornos ou problemas de converg√™ncia do modelo. Verifique:\n",
        "\n",
        "-   Qualidade e limpeza dos dados\n",
        "-   Resumo do ajuste (par√¢metros $\\alpha,\\beta$ plaus√≠veis?)\n",
        "-   Distribui√ß√£o ($t$ vs. normal)\n",
        "-   Modelos alternativos (EGARCH, GJR-GARCH, etc.)\n",
        "\n",
        "### Plotando retorno x risco\n",
        "\n",
        "Aqui iremos visualizar o comportamento do ativo `ZC=F`, futuros de milho:\n",
        "\n",
        "```         \n",
        "```\n",
        "\n",
        "Esse gr√°fico em Python, pode ser obtido com:\n"
      ],
      "id": "4ccc4e90"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Para o ativo \"ZC=F\"\n",
        "returns_zc = log_returns[['date', 'BEEF3.SA']].copy()\n",
        "vol_zc = var_condicional[['date', 'BEEF3.SA']].copy()\n",
        "\n",
        "# Converter \"date\" para datetime, se necess√°rio\n",
        "returns_zc['date'] = pd.to_datetime(returns_zc['date'])\n",
        "vol_zc['date'] = pd.to_datetime(vol_zc['date'])\n",
        "\n",
        "# Criar figura com dois subplots compartilhando o eixo x\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=1,\n",
        "    shared_xaxes=True,\n",
        "    vertical_spacing=0.05,\n",
        "    subplot_titles=(\"Retornos Di√°rios - BEEF3.SA\", \"Volatilidade Condicional (GARCH) - BEEF3.SA\")\n",
        ")\n",
        "\n",
        "# Adicionar o gr√°fico de retornos\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=returns_zc['date'], y=returns_zc['BEEF3.SA'], mode='lines', name='Retornos'),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Adicionar o gr√°fico de volatilidade condicional\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=vol_zc['date'], y=vol_zc['BEEF3.SA'], mode='lines', name='Volatilidade'),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,\n",
        "    width=900,\n",
        "    title_text=\"Retorno vs. Volatilidade (GARCH) - BEEF3.SA\",\n",
        "    xaxis2_title=\"Data\",\n",
        "    yaxis1_title=\"Retorno\",\n",
        "    yaxis2_title=\"Volatilidade Condicional\"\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "id": "b7760240",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "# References\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "Gujarati, D. N., & Porter, D. C. (2009). **Basic econometrics** (5th ed.). McGraw-Hill.\n",
        "\n",
        "Hyndman, R.J., & Athanasopoulos, G. (2021) **Forecasting: principles and practice**, 3rd edition, OTexts: Melbourne, Australia. OTexts.com/fpp3. Accessed on march 2025.\\"
      ],
      "id": "d17201e8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\kuiav\\anaconda3\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}