[
  {
    "objectID": "page4.html",
    "href": "page4.html",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "",
    "text": "Esta análise tem como objetivo demonstrar um fluxo de trabalho para buscar dados de mercado de ações, realizar previsões de preços (forecasting) e treinar um agente de Reinforcement Learning (RL) para gerar sinais de compra e venda. Utilizaremos R para a coleta inicial de dados e Python (via reticulate) para a modelagem e visualização.\nNota: As previsões e sinais gerados são para fins demonstrativos e educacionais, não constituindo recomendação financeira."
  },
  {
    "objectID": "page4.html#introdução",
    "href": "page4.html#introdução",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "",
    "text": "Esta análise tem como objetivo demonstrar um fluxo de trabalho para buscar dados de mercado de ações, realizar previsões de preços (forecasting) e treinar um agente de Reinforcement Learning (RL) para gerar sinais de compra e venda. Utilizaremos R para a coleta inicial de dados e Python (via reticulate) para a modelagem e visualização.\nNota: As previsões e sinais gerados são para fins demonstrativos e educacionais, não constituindo recomendação financeira."
  },
  {
    "objectID": "page4.html#configuração-do-ambiente",
    "href": "page4.html#configuração-do-ambiente",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "1. Configuração do Ambiente",
    "text": "1. Configuração do Ambiente\nPrimeiro, vamos carregar as bibliotecas R necessárias e configurar o reticulate para usar nosso ambiente Python.\n\n\nMostrar/Ocultar Código\n# Bibliotecas R\nlibrary(tidyverse) # Para manipulação de dados e ggplot2\nlibrary(plotly)    # Para gráficos interativos (se for recriar em R)\nlibrary(reticulate)  # Para executar código Python\nlibrary(dplyr)     # Especificamente para a função de busca de dados\nlibrary(quantmod)  # Para buscar dados financeiros\n\n\nConfiguração do Python com reticulate\nCertifique-se de que o ambiente Python que você especificar abaixo tenha todas as bibliotecas Python necessárias instaladas: yahooquery, gymnasium, torch, numpy, pandas, matplotlib, yfinance, plotly.\n\n\nMostrar/Ocultar Código\n# Exemplo de como especificar um ambiente conda:\n# use_condaenv(\"meu_ambiente_python\", required = TRUE)\n\n# Ou um ambiente virtual:\n# use_virtualenv(\"caminho/para/meu_ambiente_virtual\", required = TRUE)\n\n# Ou especificar o executável Python diretamente:\n# use_python(\"/usr/bin/python3\", required = TRUE)\n\n# Se as bibliotecas não estiverem instaladas, você pode tentar instalá-las via reticulate:\n# py_install(c(\"yahooquery\", \"gymnasium\", \"torch\", \"numpy\", \"pandas\", \"matplotlib\", \"yfinance\", \"plotly\"), pip = TRUE)\n\nE o bloco de importações de bibliotecas também precisa estar dentro de um bloco de código delimitado corretamente:\n\n#| label: python-library-imports\n#| message: false\n#| warning: false\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom yahooquery import Ticker\nimport yfinance as yf\nfrom collections import deque\n\nimport gymnasium as gym\nfrom gymnasium import spaces\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"Bibliotecas Python importadas com sucesso.\")"
  },
  {
    "objectID": "page4.html#aquisição-de-dados-de-preços",
    "href": "page4.html#aquisição-de-dados-de-preços",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "2. Aquisição de Dados de Preços",
    "text": "2. Aquisição de Dados de Preços\nUtilizaremos um script R para buscar os preços de fechamento ajustados para os tickers selecionados e salvá-los em um arquivo CSV.\n\n\nMostrar/Ocultar Código\nfetch_close_prices_qm &lt;- function(tickers, start, end, cache_path = \"prices_qm.csv\") {\n  # Se já existe CSV em cache, carrega e retorna\n  if (file.exists(cache_path)) {\n    df &lt;- read.csv(cache_path, stringsAsFactors = FALSE) %&gt;%\n      mutate(date = as.Date(date))\n    message(\"Dados carregados do cache: \", cache_path)\n    return(df)\n  }\n\n  # Senão, faz o download para cada ticker\n  all_data &lt;- lapply(tickers, function(tk) {\n    # getSymbols retorna um objeto xts com colunas Open, High, Low, Close, Volume, Adjusted\n    xts_data &lt;- tryCatch({\n        getSymbols(tk, src = \"yahoo\", from = start, to = end, auto.assign = FALSE)\n    }, error = function(e) {\n        message(paste(\"Erro ao buscar dados para\", tk, \":\", e$message))\n        return(NULL)\n    })\n\n    if (is.null(xts_data)) return(NULL)\n\n    close_prices &lt;- Ad(xts_data)  # usa Preço Ajustado (Adjusted Close)\n    data.frame(\n      date   = index(close_prices),\n      ticker = tk,\n      close  = as.numeric(close_prices),\n      row.names = NULL\n    )\n  })\n\n  # Remove NULLs (tickers com erro) e combina\n  all_data &lt;- all_data[!sapply(all_data, is.null)]\n  if (length(all_data) == 0) {\n    stop(\"Nenhum dado foi baixado para os tickers especificados.\")\n  }\n  df &lt;- bind_rows(all_data)\n\n  # Salva em CSV para próximas execuções\n  write.csv(df, cache_path, row.names = FALSE)\n  message(\"Dados salvos no cache: \", cache_path)\n\n  return(df)\n}\n\n\n\n\nMostrar/Ocultar Código\ntickers &lt;- c(\"BRFS3.SA\", \"JBSS3.SA\", \"BEEF3.SA\", \"MRFG3.SA\", \"TSN\", \"HRL\", \"GIS\")\nstart_date &lt;- \"2020-01-01\" \nend_date &lt;- format(Sys.Date(), \"%Y-%m-%d\") # Usar data atual para 'to'\n\ndf_prices_r &lt;- fetch_close_prices_qm(tickers, start_date, end_date, cache_path = \"prices_analise.csv\") \n\n\nDados carregados do cache: prices_analise.csv\n\n\nMostrar/Ocultar Código\ntail(df_prices_r)\n\n\n           date ticker close\n9385 2025-05-08    GIS 54.71\n9386 2025-05-09    GIS 54.50\n9387 2025-05-12    GIS 54.84\n9388 2025-05-13    GIS 53.77\n9389 2025-05-14    GIS 53.28\n9390 2025-05-15    GIS 54.40"
  },
  {
    "objectID": "page4.html#preparação-e-análise-exploratória-dos-dados-python",
    "href": "page4.html#preparação-e-análise-exploratória-dos-dados-python",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "3. Preparação e Análise Exploratória dos Dados (Python)",
    "text": "3. Preparação e Análise Exploratória dos Dados (Python)\nCarregamos os dados do CSV em um DataFrame pandas e o pivotamos para facilitar a análise por ticker.\n\n\nMostrar/Ocultar Código\nimport pandas as pd\n# Carregar dados do CSV salvo pelo R\ndf_prices = pd.read_csv('prices_analise.csv', parse_dates=['date'])\nprint(\"Tail do df_prices carregado:\")\n\n\nTail do df_prices carregado:\n\n\nMostrar/Ocultar Código\nprint(df_prices.tail())\n\n\n           date ticker      close\n9385 2025-05-09    GIS  54.500000\n9386 2025-05-12    GIS  54.840000\n9387 2025-05-13    GIS  53.770000\n9388 2025-05-14    GIS  53.279999\n9389 2025-05-15    GIS  54.400002\n\n\nMostrar/Ocultar Código\n# Pivotear somente as colunas 'ticker' e 'close'\ndf_pivot = df_prices.pivot(index='date', columns='ticker', values='close')\ndf_pivot = df_pivot.reset_index() # Manter 'date' como coluna\n\nprint(\"\\\\nTail do df_pivot:\")\n\n\n\\nTail do df_pivot:\n\n\nMostrar/Ocultar Código\nprint(df_pivot.tail())\n\n\nticker       date  BEEF3.SA   BRFS3.SA  ...   JBSS3.SA   MRFG3.SA        TSN\n1380   2025-05-09      4.96  19.200001  ...  42.360001  19.850000  55.299999\n1381   2025-05-12      5.07  19.709999  ...  41.889999  19.820000  55.990002\n1382   2025-05-13      5.11  20.200001  ...  40.849998  20.090000  55.360001\n1383   2025-05-14      5.15  19.680000  ...  39.349998  19.799999  54.500000\n1384   2025-05-15      5.14  20.620001  ...  39.180000  20.660000  55.650002\n\n[5 rows x 8 columns]"
  },
  {
    "objectID": "page4.html#forecasting-de-preços-python-com-plotly",
    "href": "page4.html#forecasting-de-preços-python-com-plotly",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "4. Forecasting de Preços (Python com Plotly)",
    "text": "4. Forecasting de Preços (Python com Plotly)\nRealizamos uma simulação simples de forecasting baseada na média e desvio padrão dos retornos logarítmicos históricos.\n\n\nMostrar/Ocultar Código\nimport numpy as np\nimport pandas as pd \nimport plotly.express as px\n# Defina a data de corte e o período do forecast\n# Usar a data mais recente do df_pivot como CUT\nCUT = df_pivot[\"date\"].max()\nforecast_days = 30\nfuture_dates = pd.date_range(CUT + pd.Timedelta(days=1), periods=forecast_days, freq=\"D\")\n\n# Lista de ativos (tickers)\nassets = df_pivot.columns[1:]  # Ignorando a coluna 'date'\n\n# Lista para armazenar os dados de forecast\nforecast_data = []\n\n# Gera previsões para cada ativo (simulação simples)\nfor asset in assets:\n    # Pega os dados históricos até a data de corte\n    df_asset_hist = df_pivot[[\"date\", asset]].copy() # Usar .copy() para evitar SettingWithCopyWarning\n    df_asset_hist = df_asset_hist[df_asset_hist[\"date\"] &lt;= CUT]\n    df_asset_hist.dropna(subset=[asset], inplace=True) # Remover NaNs que podem atrapalhar pct_change\n\n    if len(df_asset_hist) &lt; 2: # Precisa de pelo menos 2 pontos para pct_change\n        print(f\"Dados insuficientes para forecasting do ativo: {asset}\")\n        continue\n\n    # Calcula a média e desvio padrão dos retornos históricos\n    df_asset_hist[\"logret\"] = df_asset_hist[asset].pct_change()\n    # Remover o primeiro NaN de logret e quaisquer outros NaNs/infs\n    df_asset_hist.replace([np.inf, -np.inf], np.nan, inplace=True)\n    df_asset_hist.dropna(subset=['logret'], inplace=True)\n\n    if df_asset_hist[\"logret\"].empty:\n        print(f\"Não foi possível calcular retornos para o ativo: {asset}\")\n        mu = 0 # Default mu\n        sigma = 0.01 # Default sigma para evitar erro com scale=0\n    else:\n        mu = df_asset_hist[\"logret\"].mean()\n        sigma = df_asset_hist[\"logret\"].std()\n        if pd.isna(sigma) or sigma == 0: # Adiciona uma pequena volatilidade se std for 0 ou NaN\n            sigma = 0.01 \n\n    # Simula os retornos futuros\n    simulated_logrets = np.random.normal(loc=mu, scale=sigma, size=forecast_days)\n    last_price = df_asset_hist[asset].iloc[-1]\n    if pd.isna(last_price): # Se o último preço for NaN, use um preço padrão ou pule\n        print(f\"Último preço é NaN para o ativo: {asset}. Pulando forecast.\")\n        continue\n        \n    simulated_prices = last_price * (1 + simulated_logrets).cumprod()\n\n    # Adiciona os dados de forecast\n    for date_val, value in zip(future_dates, simulated_prices):\n        forecast_data.append({\n            \"date\": date_val,\n            \"asset\": asset,\n            \"price\": value,\n            \"rep\": \"Forecast\"\n        })\n\ndf_forecast = pd.DataFrame(forecast_data)\n\n# Prepara o histórico para plotar junto, filtrando até a data de corte\nhist_data = df_pivot[df_pivot[\"date\"] &lt;= CUT].copy()\nhist_data = hist_data.melt(id_vars=\"date\", var_name=\"asset\", value_name=\"price\")\nhist_data[\"rep\"] = \"Histórico\"\n\n# Junta histórico e forecast\ndf_plot = pd.concat([hist_data, df_forecast], ignore_index=True)\n\n# Filtra os dados para mostrar apenas o período relevante (últimos N dias de histórico + forecast)\n# Por exemplo, últimos 60 dias de histórico + 30 dias de forecast\nstart_plot_date = CUT - pd.Timedelta(days=60)\nend_plot_date = CUT + pd.Timedelta(days=forecast_days)\n\ndf_plot_filtered = df_plot[(df_plot[\"date\"] &gt;= start_plot_date) & (df_plot[\"date\"] &lt;= end_plot_date)]\n\nif not df_plot_filtered.empty:\n    fig_forecast = px.line(\n        df_plot_filtered,\n        x=\"date\",\n        y=\"price\",\n        color=\"rep\",\n        facet_col=\"asset\",\n        facet_col_wrap=2, # Ajuste conforme o número de tickers\n        labels={\"date\": \"Data\", \"price\": \"Preço (Moeda Local/USD)\", \"rep\": \"Série\"},\n        title=f\"Forecasting de Preços ({forecast_days} dias) a partir de {CUT.strftime('%Y-%m-%d')}\"\n    )\n    fig_forecast.update_layout(width=1000, height=300 * (len(assets)//2 + len(assets)%2)) # Ajusta altura\n    fig_forecast.update_xaxes(matches=None, nticks=5)\n    fig_forecast.show()\nelse:\n    print(\"Nenhum dado para plotar no gráfico de forecast.\")\n\n\n                        \n                                            \nForecasting de Preços para os Tickers da Carteira (Próximos 30 dias)"
  },
  {
    "objectID": "page4.html#reinforcement-learning-para-sinais-de-trading",
    "href": "page4.html#reinforcement-learning-para-sinais-de-trading",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "5. Reinforcement Learning para Sinais de Trading",
    "text": "5. Reinforcement Learning para Sinais de Trading\n\n5.1. Definição do Agente e Funções Auxiliares\nDefinimos a função getState e a classe Agent que representa nosso agente de RL.\n\n\nMostrar/Ocultar Código\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\ndef getState(data, t, window_size):\n    \"\"\"\n    Converte uma janela de preços em vetor de retornos normalizados.\n    \"\"\"\n    d = t - window_size + 1\n    block = data[d:t+1] if d &gt;= 0 else -d * [data[0]] + list(data[0:t+1])\n    # Evitar divisão por zero se block[i] for 0\n    res = []\n    for i in range(len(block)-1):\n        if block[i] != 0:\n            res.append((block[i+1] - block[i]) / block[i])\n        else:\n            res.append(0) # Retorno zero se o preço base for zero\n    return np.array(res, dtype=np.float32)\n\nclass Agent(nn.Module):\n    def __init__(\n        self,\n        state_size,\n        hidden_size=64,\n        lr=1e-4,\n        gamma=0.95,\n        epsilon=1.0,\n        epsilon_min=0.01,\n        epsilon_decay=0.995\n    ):\n        super(Agent, self).__init__()\n        self.gamma = gamma\n        self.epsilon = epsilon\n        self.epsilon_min = epsilon_min\n        self.epsilon_decay = epsilon_decay\n        self.inventory = [] # Adicionado para manter o inventário do agente\n        \n        self.model = nn.Sequential(\n            nn.Linear(state_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, 3)  # Q para 3 ações: 0=HOLD, 1=BUY, 2=SELL\n        )\n        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n        self.criterion = nn.MSELoss()\n\n    def act(self, state):\n        if np.random.rand() &lt; self.epsilon:\n            return np.random.choice([0,1,2]) # 0: HOLD, 1: BUY, 2: SELL\n        state_t = torch.from_numpy(state).unsqueeze(0)\n        q_values = self.model(state_t).detach().numpy()[0]\n        return np.argmax(q_values)\n\n    def train_step(self, state, action, reward, next_state, done): # Adicionado 'done'\n        state_t = torch.from_numpy(state).unsqueeze(0)\n        next_t = torch.from_numpy(next_state).unsqueeze(0)\n        \n        q_values = self.model(state_t)\n        \n        with torch.no_grad():\n            q_next = self.model(next_t).max(1)[0]\n            if done: # Se for o estado terminal, o valor do próximo estado é 0\n                 target_q_value = reward\n            else:\n                 target_q_value = reward + self.gamma * q_next\n\n        target = q_values.clone().detach()\n        target[0, action] = target_q_value\n        \n        loss = self.criterion(q_values, target)\n        self.optimizer.zero_grad()\n        loss.backward()\n        self.optimizer.step()\n        \n        if self.epsilon &gt; self.epsilon_min:\n            self.epsilon *= self.epsilon_decay\n\nprint(\"Definições do Agente RL carregadas.\")\n\n\nDefinições do Agente RL carregadas.\n\n\n\n\n5.2. Treinamento do Agente RL\nTreinamos o agente para cada ticker da nossa lista.\n\n\nMostrar/Ocultar Código\nimport numpy as np\nimport torch\nimport torch.nn as nn\n# Parâmetros de treinamento\nwindow_size = 10  # Deve ser state_size - 1 se getState retorna len(block)-1\nepisodes    = 50 # Reduzido para demonstração rápida, pode aumentar para melhor performance\nrl_results  = {}\n\n# Tickers para o treinamento (obtidos do df_pivot)\n# A primeira coluna é 'date', então pegamos da segunda em diante\ntrain_tickers = df_pivot.columns[1:].tolist() \n\nfor tk in train_tickers:\n    print(f\"\\\\n=== Treinando para {tk} ===\")\n    \n    # Prepara série de preços para o ticker\n    prices = df_prices[df_prices['ticker'] == tk].sort_values(\"date\")['close'].values\n    prices = prices[~np.isnan(prices)] # Remover NaNs dos preços\n\n    if len(prices) &lt; window_size + 2: # Checagem mais robusta para dados suficientes\n        print(f\"Dados insuficientes para {tk} após remover NaNs. Pulando ticker.\")\n        rl_results[tk] = [0] * episodes # Adiciona placeholder para evitar erro no plot\n        continue\n\n    # O state_size é o tamanho da saída de getState, que é window_size\n    agent = Agent(state_size=window_size) \n    total_profits_tk = []\n\n    for e in range(episodes):\n        state = getState(prices, 0, window_size + 1) # getState espera window_size + 1 para gerar 'window_size' retornos\n        agent.inventory = []\n        total_profit   = 0.0 # Inicializar como float\n\n        for t in range(len(prices)-1): # Loop até o penúltimo preço\n            action     = agent.act(state)\n            # O next_state é para o tempo t+1, então o último t+1 será len(prices)-1\n            next_state = getState(prices, t + 1, window_size + 1)\n            reward     = 0.0 # Inicializar como float\n            done = (t == len(prices) - 2) # 'done' é true no último passo\n\n            # Executa ação: BUY, SELL ou HOLD\n            if action == 1:  # BUY\n                agent.inventory.append(prices[t])\n            elif action == 2 and agent.inventory:  # SELL\n                bought_price = agent.inventory.pop(0)\n                profit       = prices[t] - bought_price\n                if bought_price != 0: # Evitar divisão por zero\n                    reward = profit / bought_price\n                else:\n                    reward = 0.0\n                total_profit += profit\n            \n            agent.train_step(state, action, reward, next_state, done)\n            state = next_state\n\n        total_profits_tk.append(total_profit)\n        if (e+1) % 10 == 0 or e == episodes -1 : # Imprimir a cada 10 episódios e no último\n            print(f\"Episódio {e+1}/{episodes} — Lucro: {total_profit:.2f}\")\n    \n    rl_results[tk] = total_profits_tk\n\n\n\\n=== Treinando para BEEF3.SA ===\nEpisódio 10/50 — Lucro: -26.10\nEpisódio 20/50 — Lucro: 0.41\nEpisódio 30/50 — Lucro: 2.11\nEpisódio 40/50 — Lucro: -7.35\nEpisódio 50/50 — Lucro: -9.26\n\\n=== Treinando para BRFS3.SA ===\nEpisódio 10/50 — Lucro: -89.21\nEpisódio 20/50 — Lucro: -91.17\nEpisódio 30/50 — Lucro: -20.19\nEpisódio 40/50 — Lucro: 27.47\nEpisódio 50/50 — Lucro: -58.99\n\\n=== Treinando para GIS ===\nEpisódio 10/50 — Lucro: 12.79\nEpisódio 20/50 — Lucro: -41.09\nEpisódio 30/50 — Lucro: 146.72\nEpisódio 40/50 — Lucro: 185.10\nEpisódio 50/50 — Lucro: 135.61\n\\n=== Treinando para HRL ===\nEpisódio 10/50 — Lucro: -10.18\nEpisódio 20/50 — Lucro: -10.11\nEpisódio 30/50 — Lucro: 4.67\nEpisódio 40/50 — Lucro: 0.00\nEpisódio 50/50 — Lucro: -10.53\n\\n=== Treinando para JBSS3.SA ===\nEpisódio 10/50 — Lucro: 0.20\nEpisódio 20/50 — Lucro: 4.93\nEpisódio 30/50 — Lucro: 8.24\nEpisódio 40/50 — Lucro: 27.23\nEpisódio 50/50 — Lucro: 0.47\n\\n=== Treinando para MRFG3.SA ===\nEpisódio 10/50 — Lucro: 21.75\nEpisódio 20/50 — Lucro: 49.00\nEpisódio 30/50 — Lucro: 522.64\nEpisódio 40/50 — Lucro: 307.52\nEpisódio 50/50 — Lucro: 1.28\n\\n=== Treinando para TSN ===\nEpisódio 10/50 — Lucro: 6.39\nEpisódio 20/50 — Lucro: 1.51\nEpisódio 30/50 — Lucro: 156.62\nEpisódio 40/50 — Lucro: 56.09\nEpisódio 50/50 — Lucro: 67.57\n\n\nMostrar/Ocultar Código\n# Plot da evolução do lucro\nif rl_results: # Apenas plotar se houver resultados\n    df_hist_profit = pd.DataFrame(rl_results)\n    # Adicionar coluna 'Episódio' se o índice não for usado diretamente\n    if not isinstance(df_hist_profit.index, pd.RangeIndex) or df_hist_profit.index.name != 'Episódio':\n        df_hist_profit = df_hist_profit.reset_index().rename(columns={'index': 'Episódio'})\n        # Se o índice já é RangeIndex (0 a N-1), apenas nomeie-o ou use-o diretamente\n    elif df_hist_profit.index.name != 'Episódio':\n         df_hist_profit.index.name = 'Episódio'\n         df_hist_profit = df_hist_profit.reset_index()\n\n    df_melt_profit = df_hist_profit.melt(\n        id_vars='Episódio',\n        var_name='ticker',\n        value_name='Lucro'\n    )\n\n    fig_profit_evol = px.line(\n        df_melt_profit,\n        x='Episódio',\n        y='Lucro',\n        color='ticker',\n        title='Evolução do Lucro Total por Episódio (Treinamento RL)'\n    )\n    fig_profit_evol.update_layout(\n        xaxis_title='Episódio',\n        yaxis_title='Lucro Total (Moeda Local/USD)'\n    )\n    fig_profit_evol.show()\nelse:\n    print(\"Nenhum resultado de treinamento RL para plotar.\")\n\n\n                        \n                                            \nEvolução do Lucro Total por Episódio Durante o Treinamento do Agente RL\n\n\n\n\n5.3. Geração de Sinais de Trading e Visualização\nApós o treinamento, usamos o agente para gerar sinais de COMPRA/VENDA e os visualizamos.\n\n\nMostrar/Ocultar Código\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots # Importe make_subplots aqui\nimport torch\nimport torch.nn as nn\n# 1) Gera sinais para cada ticker\nall_signals = {}\n# Usar a última instância do agente treinada ou treinar um novo/carregar\n# Para este exemplo, vamos reusar a última instância 'agent' do loop de treinamento,\n# que foi treinada no último ticker da lista 'train_tickers'.\n# Idealmente, você teria um agente treinado por ticker ou um agente geral.\n# Aqui, vamos gerar sinais para todos os tickers usando o agente treinado no ÚLTIMO ticker.\n# Isto é mais para demonstração da plotagem.\n# Para uma análise real, você deveria ter um agente específico por ticker ou um agente treinado em todos.\n\n# Se 'agent' não foi definido (ex: todos os tickers foram pulados no treinamento)\nif 'agent' not in locals() and train_tickers:\n    print(\"Agente não treinado. Treinando um agente no primeiro ticker disponível para demonstração de sinais.\")\n    tk_demo = train_tickers[0]\n    prices_demo = df_prices[df_prices['ticker'] == tk_demo].sort_values(\"date\")['close'].values\n    prices_demo = prices_demo[~np.isnan(prices_demo)]\n    if len(prices_demo) &gt;= window_size + 2:\n        agent = Agent(state_size=window_size)\n        # Treinamento rápido apenas para ter um agente\n        for e_demo in range(5): # Treino muito curto\n            state_demo = getState(prices_demo, 0, window_size + 1)\n            for t_demo in range(len(prices_demo) -1):\n                action_demo = agent.act(state_demo)\n                next_state_demo = getState(prices_demo, t_demo + 1, window_size + 1)\n                # Recompensa e 'done' simplificados para este agente de demonstração\n                agent.train_step(state_demo, action_demo, 0, next_state_demo, (t_demo == len(prices_demo) - 2))\n                state_demo = next_state_demo\n    else:\n        agent = None # Não foi possível treinar agente de demonstração\n        print(f\"Não foi possível treinar agente de demonstração para {tk_demo}\")\n\n\nif agent: # Prossiga apenas se o agente existir\n    for tk_signal in train_tickers: # Usar train_tickers para consistência\n        agent.epsilon = agent.epsilon_min # Usar política greedy para geração de sinais\n        \n        current_prices_tk = df_prices[df_prices.ticker==tk_signal].sort_values('date')\n        \n        if current_prices_tk.empty or 'close' not in current_prices_tk.columns:\n            print(f\"Aviso: Nenhum dado de preço para {tk_signal} na geração de sinais. Pulando.\")\n            all_signals[tk_signal] = pd.DataFrame(columns=['date', 'action', 'price'])\n            continue\n\n        dates_signal  = current_prices_tk['date'].values\n        values_signal = current_prices_tk['close'].values\n        values_signal = values_signal[~np.isnan(values_signal)] # Remover NaNs\n\n        if len(values_signal) &lt; window_size + 2:\n            print(f\"Dados insuficientes para {tk_signal} na geração de sinais após remover NaNs. Pulando.\")\n            all_signals[tk_signal] = pd.DataFrame(columns=['date', 'action', 'price'])\n            continue\n            \n        state_signal = getState(values_signal, 0, window_size+1)\n        agent.inventory = [] # Resetar inventário para cada ticker\n        signals_current_tk = []\n\n        for t_signal in range(len(values_signal)-1):\n            action_signal = agent.act(state_signal)\n            date_val  = dates_signal[t_signal]\n            price_val = values_signal[t_signal]\n            \n            if action_signal == 1: # BUY\n                signals_current_tk.append({'date': date_val, 'action': 'BUY',  'price': price_val})\n                agent.inventory.append(price_val)\n            elif action_signal == 2 and agent.inventory: # SELL\n                signals_current_tk.append({'date': date_val, 'action': 'SELL', 'price': price_val})\n                agent.inventory.pop(0)\n            \n            next_state_signal = getState(values_signal, t_signal+1, window_size+1)\n            state_signal = next_state_signal\n\n        if signals_current_tk:\n            all_signals[tk_signal] = pd.DataFrame(signals_current_tk)\n        else:\n            all_signals[tk_signal] = pd.DataFrame(columns=['date', 'action', 'price'])\nelse:\n    print(\"Agente RL não está definido. Pulando geração e visualização de sinais.\")\n    all_signals = {tk: pd.DataFrame(columns=['date', 'action', 'price']) for tk in train_tickers}\n\n\nnp.float64(6.81380176544189)\nnp.float64(5.26593589782715)\nnp.float64(7.30055618286133)\nnp.float64(10.0992479324341)\nnp.float64(8.27000045776367)\nnp.float64(5.21999979019165)\nnp.float64(5.80999994277954)\nnp.float64(33.1086006164551)\nnp.float64(18.5222930908203)\nnp.float64(20.1985607147217)\nnp.float64(16.0724201202393)\nnp.float64(14.4671220779419)\nnp.float64(18.6311626434326)\nnp.float64(24.614538192749)\nnp.float64(23.6902770996094)\nnp.float64(55.8949966430664)\nnp.float64(62.6845550537109)\nnp.float64(60.6441955566406)\nnp.float64(65.2206649780273)\nnp.float64(71.687370300293)\nnp.float64(66.9289932250977)\nnp.float64(36.5912933349609)\nnp.float64(36.9240226745605)\nnp.float64(30.8655300140381)\nnp.float64(12.1882457733154)\nnp.float64(11.409553527832)\nnp.float64(25.4968242645264)\nnp.float64(24.4868927001953)\nnp.float64(31.2252235412598)\nnp.float64(5.63424777984619)\nnp.float64(4.23390340805054)\nnp.float64(12.4057178497314)\nnp.float64(6.6918420791626)\nnp.float64(9.22000026702881)\nnp.float64(11.7200002670288)\nnp.float64(71.0657501220703)\nnp.float64(70.7318954467773)\nnp.float64(77.8379211425781)\nnp.float64(54.7825660705566)\nnp.float64(47.6663703918457)\nnp.float64(47.2522888183594)\nnp.float64(44.1221313476562)\nnp.float64(55.1122856140137)\nnp.float64(58.9212226867676)\nnp.float64(61.2099990844727)\n\n\nMostrar/Ocultar Código\n# 2) Cria figura com uma linha por ticker\nif train_tickers and all_signals : # Apenas se houver tickers e sinais\n    fig_signals = make_subplots(\n        rows=len(train_tickers), cols=1,\n        shared_xaxes=True,\n        subplot_titles=train_tickers,\n        vertical_spacing=0.02\n    )\n\n    for i, tk_plot in enumerate(train_tickers, start=1):\n        prices_tk_plot = df_prices[df_prices.ticker==tk_plot].sort_values('date')\n        sig_df_plot = all_signals.get(tk_plot, pd.DataFrame(columns=['date', 'action', 'price']))\n\n        if not prices_tk_plot.empty and 'close' in prices_tk_plot.columns:\n            fig_signals.add_trace(\n                go.Scatter(x=prices_tk_plot['date'], y=prices_tk_plot['close'], mode='lines', name=f'Preço {tk_plot}', legendgroup=f'group{tk_plot}'),\n                row=i, col=1\n            )\n        \n        buy_signals_plot = sig_df_plot.query(\"action=='BUY'\")\n        if not buy_signals_plot.empty:\n            fig_signals.add_trace(\n                go.Scatter(x=buy_signals_plot['date'],\n                           y=buy_signals_plot['price'],\n                           mode='markers', marker_symbol='triangle-up',\n                           marker_size=8, marker_color='green', \n                           name=f'Compra', showlegend=(i==1), legendgroup=f'group_buy'), # Mostrar legenda apenas uma vez\n                row=i, col=1\n            )\n        \n        sell_signals_plot = sig_df_plot.query(\"action=='SELL'\")\n        if not sell_signals_plot.empty:\n            fig_signals.add_trace(\n                go.Scatter(x=sell_signals_plot['date'],\n                           y=sell_signals_plot['price'],\n                           mode='markers', marker_symbol='triangle-down',\n                           marker_size=8, marker_color='red',\n                           name=f'Venda', showlegend=(i==1), legendgroup=f'group_sell'), # Mostrar legenda apenas uma vez\n                row=i, col=1\n            )\n\n    fig_signals.update_layout(\n        height=max(300 * len(train_tickers), 800), # Ajusta altura dinamicamente, mínimo de 800px\n        title_text='Sinais de Compra/Venda por Ticker (Agente RL)',\n        legend_tracegroupgap = 180 # Espaçamento entre grupos de legenda\n    )\n    fig_signals.update_yaxes(title_text=\"Preço\") \n    # Aplicar título do eixo X apenas ao último subplot visível\n    # Encontrar o último subplot que realmente tem dados para o eixo X\n    last_row_with_data = 0\n    for r in range(len(train_tickers), 0, -1):\n        if not df_prices[df_prices.ticker==train_tickers[r-1]].empty:\n            last_row_with_data = r\n            break\n    if last_row_with_data &gt; 0:\n      fig_signals.update_xaxes(title_text=\"Data\", row=last_row_with_data, col=1)\n    \n    fig_signals.show()\nelse:\n    print(\"Nenhum ticker ou sinal para plotar.\")\n\n\n                        \n                                            \nSinais de Compra/Venda Gerados pelo Agente RL por Ticker"
  },
  {
    "objectID": "page4.html#conclusão",
    "href": "page4.html#conclusão",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "6. Conclusão",
    "text": "6. Conclusão\nEste documento demonstrou um pipeline para análise de dados financeiros, incluindo coleta de dados, forecasting e a aplicação de um agente de Reinforcement Learning para gerar sinais de trading. Os resultados visuais do forecasting e dos sinais do agente RL fornecem insights que podem auxiliar na tomada de decisões de investimento, lembrando sempre da importância de análises complementares e do gerenciamento de risco.\nOs gráficos de evolução do lucro durante o treinamento do agente RL indicam a capacidade de aprendizado do modelo em diferentes ativos, embora a performance possa variar significativamente. A visualização final dos sinais de compra e venda sobrepostos aos preços históricos permite uma avaliação qualitativa da estratégia do agente."
  },
  {
    "objectID": "page2.html",
    "href": "page2.html",
    "title": "Ciência de Dados para Negócios: Big Data for Finance Project",
    "section": "",
    "text": "Resumo\n\n\n\n\n\nAnálise de Séries de Preços e Log-Retornos\n\n\n\n\n\nIntro\n\n1️⃣ Conversão para Log-Retornos2️⃣ Construção e Avaliação das Distribuições3️⃣ Cálculo da Variância\n\n\nConverter a série de preços em log-retornos utilizando a seguinte fórmula:\n[ p_t = \\ln(p_t) - \\ln(p_{t-1}) ]\nEssa transformação nos permite analisar os retornos percentuais de forma mais adequada.\n\n\n\n\nConstruir os histogramas de cada série de retornos transformada.\nAvaliar a assimetria das distribuições e identificar se há predominância de retornos positivos ou negativos no período analisado.\n\n\n\n\nCalcular a variância da série de retornos logarítmicos utilizando:\n\n🔹 O desvio padrão como medida direta (volatilidade histórica com janela de 5 dias).\n🔹 Ou de maneira mais acurada, modelos econométricos (ex.: GARCH(1,1)) para obter a variância condicional.\n\ndate BEEF3.SA BRFS3.SA GIS HRL JBSS3.SA MRFG3.SA \\ 1238 2025-03-14 0.031093 0.024722 0.024976 0.014724 0.015667 0.024863 1239 2025-03-17 0.031816 0.026581 0.028208 0.015502 0.016132 0.028757 1240 2025-03-18 0.022213 0.040627 0.021501 0.014557 0.073009 0.036127 1241 2025-03-19 0.021905 0.039398 0.015938 0.007907 0.073728 0.035161 1242 2025-03-20 0.033103 0.034645 0.016877 0.007681 0.071088 0.039908\nTSN 1238 0.011254 1239 0.011458 1240 0.011033 1241 0.006089 1242 0.006956\n\n\n\n\n4️⃣ Visualizações\n\n\n\n📉 Gráficos de séries temporais de preços:"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre Nós",
    "section": "",
    "text": "Daniel K Junior\nArthur Lauffer\nDavi Kemper\nJoão Niquele"
  },
  {
    "objectID": "about.html#sumário",
    "href": "about.html#sumário",
    "title": "Sobre Nós",
    "section": "",
    "text": "Daniel K Junior\nArthur Lauffer\nDavi Kemper\nJoão Niquele"
  },
  {
    "objectID": "about.html#arthur-lauffer",
    "href": "about.html#arthur-lauffer",
    "title": "Sobre Nós",
    "section": "Arthur Lauffer",
    "text": "Arthur Lauffer\n\nCargo: É analista de BI e estudante de Ciência de Dados para Negócios na FAE Business School. Ele administra sua própria empresa de BI, prestando serviços para outras empresas, e também gerencia uma empresa de SaaS focada em projetos de longo prazo. Com grande experiência em Power BI, ele desenvolve dashboards e modelos de dados para diversas áreas, incluindo vendas, RH e faturamento. Além disso, atua como administrador do Workspace do Google da sua empresa. No tempo livre, tem interesse em música eletrônica e está organizando a festa Synapse. 🔗 Portfolio"
  },
  {
    "objectID": "about.html#davi-kemper",
    "href": "about.html#davi-kemper",
    "title": "Sobre Nós",
    "section": "Daniel K Junior",
    "text": "Daniel K Junior\n\nCargo: Formado na Escola de Sargento das Armas no ano de 2021, decidiu fazer a transição de carreira para a área de Dados já no ínicio da faculdade, concluindo a transição no final do ano de 2024, hoje atua como Analista de BI na EZ Chart.\n🔗 Portfolio"
  },
  {
    "objectID": "about.html#davi-kemper-1",
    "href": "about.html#davi-kemper-1",
    "title": "Sobre Nós",
    "section": "Davi Kemper",
    "text": "Davi Kemper\n\nCargo: Estudante de Ciência de Dados na FAE, atuou como Analista de BI do grupo Metronorte. 🔗 Portfolio"
  },
  {
    "objectID": "about.html#joão-niquele",
    "href": "about.html#joão-niquele",
    "title": "Sobre Nós",
    "section": "João Niquele",
    "text": "João Niquele\n\nCargo: Estudante de Ciência de Dados na FAE 🔗 Portfolio"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Projeto Finanças",
    "section": "",
    "text": "Usaremos seguintes ações da bolsa :\n\nBRFS3: A BRF é uma empresa transnacional brasileira do ramo alimentício, fruto da fusão entre Sadia e Perdigão, duas das principais empresas de alimentos do Brasil.\nJBSS3: JBS é uma empresa brasileira do setor de alimentos fundada em 1953 em Goiás. A companhia opera no processamento de carnes bovina, suína, ovina, de frango, de peixe e plant-based, além de atuar no processamento de couros\nBEEF3: Minerva Foods é uma empresa brasileira de alimentos fundada em 1924 na cidade de Barretos. A companhia tem atuação na comercialização de carne in natura, couros, derivados, e na exportação de gado vivo, além de atuar no processamento de carnes.\nMRFG3: Marfrig Global Foods é uma empresa brasileira de alimentos. Fundada no ano 2000, é a segunda maior produtora de carne bovina do mundo e líder na produção de hambúrgueres.\nTSN: A Tyson Foods é uma empresa multinacional americana fundada por John W. Tyson em 1931 e sediada em Springdale, Arkansas, que opera na indústria alimentícia.\nHRL: A Hormel Foods Corporation é uma empresa alimentícia estadunidense com sede em Austin, Minnesota, conhecida pela fabricação do Spam. Em 24 de agosto de 2017, a empresa anunciou a compra da empresa brasileira Ceratti.\nGIS: General Mills é uma multinacional americana produtora de alimentos classificada na Fortune 500 e uma das 10 maiores empresas de alimentos do mundo. É sediada em Golden Valley, Minnesota, Minneapolis.\n\nUtilizamos a API Yahoo! Finance para conseguir os dados utilizados para as analises a seguir.\nAnalisando os dados em uma tabela:\n\n\nCode\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(timeSeries)\nlibrary(fPortfolio)\nlibrary(quantmod)\nlibrary(cowplot) \nlibrary(lattice)\nlibrary(timetk)\nlibrary(quantmod)\nlibrary(DT) \n\n\nTICKERS &lt;- c(\n  \"BRFS3.SA\",\n  \"JBSS3.SA\",\n  \"BEEF3.SA\",\n  \"MRFG3.SA\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n)\n\n\n\n\n\nportfolioPrices &lt;- NULL\nfor ( Ticker in TICKERS )\n  portfolioPrices &lt;- cbind(\n    portfolioPrices, \n    getSymbols(\n      Ticker,\n      src = \"yahoo\",\n      from = \"2019-01-01\",\n      auto.assign = FALSE\n    )[,4]\n  )\n\nportfolioPrices &lt;- portfolioPrices[apply(portfolioPrices, 1, function(x) all(!is.na(x))),]\n\ncolnames(portfolioPrices) &lt;- c(\n  \"BRFS3\",\n  \"JBSS3\",\n  \"BEEF3\",\n  \"MRFG3\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n)\n\n\n\n\nCode\n# Visualizar com DT\ndatatable(tail(portfolioPrices), options = list(pageLength = 10, scrollX = TRUE)) \n\n\n\n\n\n\nE então a gente faz uma analise temporal dos dados, tendo o eixo X sendo a variável tempo, e o eixo Y sendo o preço:\n\n\nCode\nportfolioPrices |&gt; as.data.frame() |&gt;\n  mutate(\n    time = seq_along(GIS)\n  ) |&gt;\n  pivot_longer(\n    !time,\n    names_to = \"Variables\",\n    values_to = \"Value\"  \n  ) |&gt;\n  group_by(Variables) |&gt;\n  plot_time_series(\n    time,\n    Value,\n    .interactive = F, # Change for TRUE for better visualization\n    .facet_ncol = 2,\n    .smooth = FALSE\n  ) +\n  theme(\n    strip.background = element_rect(fill = \"white\", colour = \"white\")\n  )"
  },
  {
    "objectID": "page3.html",
    "href": "page3.html",
    "title": "Ciência de Dados para Negócios: Big Data for Finance Project",
    "section": "",
    "text": "Resumo\n\n\n\n\nteste de futuro para as ações\n\n\n\n\nIntro\nescrever\n\nR\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(modeltime)\nlibrary(timetk)\nlibrary(purrr)\nlibrary(tidyquant)\nlibrary(tsibble)\nlibrary(prophet)\nlibrary(feasts)\nlibrary(fable)\nlibrary(fabletools)\nlibrary(lubridate)\nlibrary(tictoc)\n\n\nCarregamos os dados:\n\n\nCode\ntickers &lt;- c(\n         \"BRFS3.SA\",\n  \"JBSS3.SA\",\n  \"BEEF3.SA\",\n  \"MRFG3.SA\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n)\n\n\nEntão baixo os dados via Yahoo!Finance:\n\n\nCode\nportfolioPrices &lt;- NULL\n  for ( Ticker in tickers )\n    portfolioPrices &lt;- cbind(\n      portfolioPrices, \n      quantmod::getSymbols.yahoo(\n        Ticker,\n        from = \"2019-01-01\",\n        auto.assign = FALSE\n      )[,4]\n    )\n\nportfolioPrices &lt;- portfolioPrices[apply(portfolioPrices, 1, function(x) all(!is.na(x))),]\n\ncolnames(portfolioPrices) &lt;- c(\n  \"BRFS3.SA\",\n  \"JBSS3.SA\",\n  \"BEEF3.SA\",\n  \"MRFG3.SA\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n)\n\n# Visualizar com DT\n#DT::datatable(tail(portfolioPrices), options = list(pageLength = 10, scrollX = TRUE)) \n\n\nVisualizando os dados dos nossos últimos retornos dos preços, temos:\n\n\nCode\nlog_returns &lt;- log(portfolioPrices) - log(lag(portfolioPrices))\nlog_returns &lt;- na.omit(log_returns)\nlog_returns &lt;- log_returns |&gt; \n  timetk::tk_tbl(preserve_index = TRUE, rename_index = \"date\")\n\ntail(log_returns)\n\n\n\n  \n\n\n\n\n\nCode\nln_returns &lt;- log_returns\n\nln_returns |&gt; as.data.frame() |&gt;\n  dplyr::mutate(\n    time = seq_along( TSN )\n  ) |&gt; select(-date) |&gt;\n  tidyr::pivot_longer(\n    !time,\n    names_to = \"Variables\",\n    values_to = \"Value\"  \n      ) |&gt;\n  dplyr::group_by(Variables) |&gt;\n  timetk::plot_time_series(\n    time,\n    Value,\n    .interactive = F, # Change for TRUE for better visualization\n    .facet_ncol = 2,\n    .smooth = FALSE\n  ) +\n  ggplot2::theme(\n    strip.background = ggplot2::element_rect(fill = \"white\", colour = \"white\")\n  )\n\n\n\n\n\n\n\n\n\n\nModelagem com fpp3 e validação cruzada temporal\nPrecisaremos fazer um forecasting de curto prazo com nossos dados históricos de retornos pra formularmos nossas recomendações posteriores de compra, venda e espera:\n\nVamos começar com uma série por vez \\(\\Rightarrow\\) TSN\n\n\n\nCode\n# Primeiro converto pra tsibble\n\nlnretTSN &lt;- log_returns |&gt; \n  select(date, TSN) |&gt; \n  as_tsibble(index = date)\n\nglimpse(lnretTSN)\n\n\nRows: 1,541\nColumns: 2\n$ date &lt;date&gt; 2019-01-03, 2019-01-04, 2019-01-07, 2019-01-08, 2019-01-09, 2019…\n$ TSN  &lt;dbl&gt; 0.0211432803, 0.0122208208, 0.0160060857, 0.0264099860, -0.017528…\n\n\n\n\nCode\ntreino &lt;- lnretTSN |&gt;\n  filter_index(~\"2025-01-01\")\n\n\nWar models\n\n\nCode\ntic()\n\nModelos &lt;- treino |&gt;\n  model(\n    AjusteExp = ETS(TSN ~ error(\"A\") + trend(\"N\") + season(\"N\")), # Ajuste Exponencial com auto\n    \n    AjExp_aditivo = ETS(TSN ~ error(\"A\") + trend(\"A\") + season(\"A\")), # Ajuste Exponencial Aditivo\n    \n    AjExp_multiplicativo = ETS(TSN ~ error(\"M\") + trend(\"A\") + season(\"M\")), # Ajuste Exponencial Multiplicativo\n    \n    Croston = CROSTON(TSN), # Modelo Croston\n    \n    HoltWinters = ETS(TSN ~ error(\"M\") + trend(\"Ad\") + season(\"M\")), # Holt Winters\n    \n    Holt = ETS(TSN ~ error(\"A\") + trend(\"A\") + season(\"N\")), # Holt\n    \n    HoltAmort = ETS(TSN ~ error(\"A\") + trend(\"Ad\", phi = 0.9) + season(\"N\")), # Holt Amortecida\n    \n    Regr_Comp = TSLM(TSN ~ trend() + season()), # Regressao com tendencia e sazonalidade auto\n    \n    Regr_Harmonica = TSLM(TSN ~ trend() + fourier(K = 2)), # Regressao harmonica\n    \n    Regr_Quebras = TSLM(TSN ~ trend(knots = c(2018, 2019, 2020))), # Regressao com quebras estruturais\n    \n    Snaive = SNAIVE(TSN), # SNAIVE\n    \n    Naive = NAIVE(TSN), #NAIVE\n    \n    Media_Movel = ARIMA(TSN ~ pdq(0,0,1)), # Media Movel Simples\n    \n    autoARIMA = ARIMA(TSN, stepwise = FALSE, approx = FALSE), # Auto ARIMA\n    \n    autoARIMA_saz = ARIMA(TSN, stepwise = FALSE, approx = FALSE, seasonal = TRUE), # AutoARIMA Sazonal\n    \n    #    Regr_erros_ARIMA = auto.arima(TSN, xreg = fourier(K = 3), seasonal = FALSE), # Regressao com erros ARIMA\n    \n    ARIMA_saz_012011 = ARIMA(TSN ~ pdq(0,1,2) + PDQ(0,1,1)), # ARIMA Sazonal ordem 012011\n    \n    ARIMA_saz_210011 = ARIMA(TSN ~ pdq(2,1,0) + PDQ(0,1,1)), # ARIMA Sazonal ordem 210011\n    \n    ARIMA_saz_0301012 = ARIMA(TSN ~ 0 + pdq(3,0,1) + PDQ(0,1,2)), # ARIMA sazonal\n    \n    ARIMA_quad = ARIMA(TSN ~ I(trend()^2)), # ARIMA com tendencia temporal quadratica\n    \n    ARIMA_determ = ARIMA(TSN ~ 1 + trend() + pdq(d = 0)), # ARIMA com tendencia deterministica\n    \n    ARIMA_estocastico = ARIMA(TSN ~ pdq(d = 1)), # ARIMA com tendência estocastica\n    \n    Regr_Harm_dinamica = ARIMA(TSN ~ fourier(K=2) + PDQ(0,0,0)), # Regressao Harmonica Dinamica\n    \n    Regr_Harm_Din_MultSaz = ARIMA(TSN ~ PDQ(0, 0, 0) + pdq(d = 0) + fourier(period = 7*30, K = 10) + fourier(period = 7*30, K = 5)), \n    \n    Regr_Harm_Din_Saz = ARIMA(TSN ~ PDQ(0, 0, 0) + pdq(d = 0) + fourier(period = \"month\", K = 10) +\n                                fourier(period = \"year\", K = 2) ), # Rgr Harm Mult Saz Complexa\n    \n#    Auto_Prophet = prophet(TSN), # Auto prophet\n    \n#    Prophet_mult = prophet(TSN ~ season(period = \"month\", order = 2, type = \"multiplicative\")),\n    \n#    Prophet_aditivo = prophet(TSN ~ season(period = \"month\", order = 2, type = \"additive\")),\n    \n#    Prophet_geom = prophet(TSN ~ growth(\"geometric\") + season(period = \"month\", order = 2, type = \"multiplicative\")),\n    \n#    Prophet_memo = prophet(TSN ~ growth(\"geometric\") + season(period = \"month\", order = 5) +\n#                             season(period = \"year\", order = 2, type = \"multiplicative\")),\n    \n    Modelo_VAR = VAR(TSN, ic = \"bic\"), # Vetor Autoregressivo \n    \n    Random_Walk = RW(TSN ~ drift()), # Random Walk com drift\n    \n    Rede_Neural_AR = NNETAR(TSN, bootstrap =  TRUE)#, # Rede Neural com auto AR e bootstraping nos erros\n    \n    #    x11 = X_13ARIMA_SEATS(TSN ~ x11()) # X11 ARIMA Seats\n    \n  ) |&gt;\n  \n  forecast(h = \"24 months\") # Horizonte de projecao para os proximos 30 dias apos corte no treino\n\ntoc()  \n\n\n1.05 sec elapsed\n\n\nSelecionamos o melhor modelo (1 fold de validação cruzada somente):\n\n\nCode\nModelos |&gt;\n  accuracy(lnretTSN) |&gt;\n  arrange(RMSE) # Seleção da acuracia pelo menor RMSE para o conjunto de modelos\n\n\n\n  \n\n\n\nGero um cenário com o modelo:\n\n\nCode\nfit &lt;- lnretTSN |&gt;\n  model(\n    Regr_Quebras = TSLM(TSN ~ trend(knots = c(2018, 2019, 2020))), # Regressao com quebras estruturais\n  )\n\nsim &lt;- fit |&gt; generate(h = 30, times = 5, bootstrap = TRUE)\n\n\nPlotamos os forecasts com esse modelo pra três cenários distintos no futuro:\n\n\nCode\nlnretTSN |&gt;\n  filter_index(\"2025-01-01\"~.) |&gt;\n  ggplot(aes(x = date)) +\n  geom_line(aes(y = TSN)) +\n  geom_line(aes(y = .sim, colour = as.factor(.rep)),\n    data = sim) +\n  labs(title=\"Valores projetados de retornos de preços de contratos futuros da TSN\", y=\"$US\" ) +\n  guides(colour = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Primeiro converto pra tsibble\n\nlnretGIS &lt;- log_returns |&gt; \n  select(date, GIS) |&gt; \n  as_tsibble(index = date)\n\nglimpse(lnretGIS)\n\n\nRows: 1,541\nColumns: 2\n$ date &lt;date&gt; 2019-01-03, 2019-01-04, 2019-01-07, 2019-01-08, 2019-01-09, 2019…\n$ GIS  &lt;dbl&gt; 0.0154921374, 0.0200387411, 0.0164387227, 0.0149567729, -0.016440…\n\n\n\n\nCode\ntreino &lt;- lnretGIS |&gt;\n  filter_index(~\"2025-01-01\")\n\n\n\n\nCode\ntic()\n\nModelos &lt;- treino |&gt;\n  model(\n    AjusteExp = ETS(GIS ~ error(\"A\") + trend(\"N\") + season(\"N\")), # Ajuste Exponencial com auto\n    \n    AjExp_aditivo = ETS(GIS ~ error(\"A\") + trend(\"A\") + season(\"A\")), # Ajuste Exponencial Aditivo\n    \n    AjExp_multiplicativo = ETS(GIS ~ error(\"M\") + trend(\"A\") + season(\"M\")), # Ajuste Exponencial Multiplicativo\n    \n    Croston = CROSTON(GIS), # Modelo Croston\n    \n    HoltWinters = ETS(GIS ~ error(\"M\") + trend(\"Ad\") + season(\"M\")), # Holt Winters\n    \n    Holt = ETS(GIS ~ error(\"A\") + trend(\"A\") + season(\"N\")), # Holt\n    \n    HoltAmort = ETS(GIS ~ error(\"A\") + trend(\"Ad\", phi = 0.9) + season(\"N\")), # Holt Amortecida\n    \n    Regr_Comp = TSLM(GIS ~ trend() + season()), # Regressao com tendencia e sazonalidade auto\n    \n    Regr_Harmonica = TSLM(GIS ~ trend() + fourier(K = 2)), # Regressao harmonica\n    \n    Regr_Quebras = TSLM(GIS ~ trend(knots = c(2018, 2019, 2020))), # Regressao com quebras estruturais\n    \n    Snaive = SNAIVE(GIS), # SNAIVE\n    \n    Naive = NAIVE(GIS), #NAIVE\n    \n    Media_Movel = ARIMA(GIS ~ pdq(0,0,1)), # Media Movel Simples\n    \n    autoARIMA = ARIMA(GIS, stepwise = FALSE, approx = FALSE), # Auto ARIMA\n    \n    autoARIMA_saz = ARIMA(GIS, stepwise = FALSE, approx = FALSE, seasonal = TRUE), # AutoARIMA Sazonal\n    \n    #    Regr_erros_ARIMA = auto.arima(TSN, xreg = fourier(K = 3), seasonal = FALSE), # Regressao com erros ARIMA\n    \n    ARIMA_saz_012011 = ARIMA(GIS ~ pdq(0,1,2) + PDQ(0,1,1)), # ARIMA Sazonal ordem 012011\n    \n    ARIMA_saz_210011 = ARIMA(GIS ~ pdq(2,1,0) + PDQ(0,1,1)), # ARIMA Sazonal ordem 210011\n    \n    ARIMA_saz_0301012 = ARIMA(GIS ~ 0 + pdq(3,0,1) + PDQ(0,1,2)), # ARIMA sazonal\n    \n    ARIMA_quad = ARIMA(GIS ~ I(trend()^2)), # ARIMA com tendencia temporal quadratica\n    \n    ARIMA_determ = ARIMA(GIS ~ 1 + trend() + pdq(d = 0)), # ARIMA com tendencia deterministica\n    \n    ARIMA_estocastico = ARIMA(GIS ~ pdq(d = 1)), # ARIMA com tendência estocastica\n    \n    Regr_Harm_dinamica = ARIMA(GIS ~ fourier(K=2) + PDQ(0,0,0)), # Regressao Harmonica Dinamica\n    \n    Regr_Harm_Din_MultSaz = ARIMA(GIS ~ PDQ(0, 0, 0) + pdq(d = 0) + fourier(period = 7*30, K = 10) + fourier(period = 7*30, K = 5)), \n    \n    Regr_Harm_Din_Saz = ARIMA(GIS ~ PDQ(0, 0, 0) + pdq(d = 0) + fourier(period = \"month\", K = 10) +\n                                fourier(period = \"year\", K = 2) ), # Rgr Harm Mult Saz Complexa\n    \n#    Auto_Prophet = prophet(TSN), # Auto prophet\n    \n#    Prophet_mult = prophet(TSN ~ season(period = \"month\", order = 2, type = \"multiplicative\")),\n    \n#    Prophet_aditivo = prophet(TSN ~ season(period = \"month\", order = 2, type = \"additive\")),\n    \n#    Prophet_geom = prophet(TSN ~ growth(\"geometric\") + season(period = \"month\", order = 2, type = \"multiplicative\")),\n    \n#    Prophet_memo = prophet(TSN ~ growth(\"geometric\") + season(period = \"month\", order = 5) +\n#                             season(period = \"year\", order = 2, type = \"multiplicative\")),\n    \n    Modelo_VAR = VAR(GIS, ic = \"bic\"), # Vetor Autoregressivo \n    \n    Random_Walk = RW(GIS ~ drift()), # Random Walk com drift\n    \n    Rede_Neural_AR = NNETAR(GIS, bootstrap =  TRUE)#, # Rede Neural com auto AR e bootstraping nos erros\n    \n    #    x11 = X_13ARIMA_SEATS(TSN ~ x11()) # X11 ARIMA Seats\n    \n  ) |&gt;\n  \n  forecast(h = \"24 months\") # Horizonte de projecao para os proximos 30 dias apos corte no treino\n\ntoc()  \n\n\n0.93 sec elapsed\n\n\n\n\nCode\nfit &lt;- lnretGIS |&gt;\n  model(\n    Regr_Quebras = TSLM(GIS ~ trend(knots = c(2018, 2019, 2020))), # Regressao com quebras estruturais\n  )\n\nsim &lt;- fit |&gt; generate(h = 30, times = 5, bootstrap = TRUE)\n\n\n\n\nCode\nlnretTSN |&gt;\n  filter_index(\"2025-01-01\"~.) |&gt;\n  ggplot(aes(x = date)) +\n  geom_line(aes(y = TSN)) +\n  geom_line(aes(y = .sim, colour = as.factor(.rep)),\n    data = sim) +\n  labs(title=\"Valores projetados de retornos de preços de contratos futuros da SALESFORCE\", y=\"$US\" ) +\n  guides(colour = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n \n\n\n\nReferences\n\nMarkowitz, H. (1952). Portfolio Selection. The Journal of Finance, 7(1), 77–91.\nLink\nSharpe, W. F. (1966). Mutual Fund Performance. The Journal of Business, 39(1), 119–138.\nLink\nElton, E. J., Gruber, M. J., Brown, S. J., & Goetzmann, W. N. (2007). Modern Portfolio Theory and Investment Analysis (9th ed.). Wiley.\nHilpisch, Y. (2018). Python for Finance: Mastering Data-Driven Finance. O’Reilly Media."
  }
]