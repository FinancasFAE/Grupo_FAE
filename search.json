[
  {
    "objectID": "page4.html",
    "href": "page4.html",
    "title": "An√°lise de Carteira com Forecasting e Reinforcement Learning",
    "section": "",
    "text": "Esta an√°lise tem como objetivo demonstrar um fluxo de trabalho para buscar dados de mercado de a√ß√µes, realizar previs√µes de pre√ßos (forecasting) e treinar um agente de Reinforcement Learning (RL) para gerar sinais de compra e venda. Utilizaremos R para a coleta inicial de dados e Python (via reticulate) para a modelagem e visualiza√ß√£o.\nNota: As previs√µes e sinais gerados s√£o para fins demonstrativos e educacionais, n√£o constituindo recomenda√ß√£o financeira."
  },
  {
    "objectID": "page4.html#introdu√ß√£o",
    "href": "page4.html#introdu√ß√£o",
    "title": "An√°lise de Carteira com Forecasting e Reinforcement Learning",
    "section": "",
    "text": "Esta an√°lise tem como objetivo demonstrar um fluxo de trabalho para buscar dados de mercado de a√ß√µes, realizar previs√µes de pre√ßos (forecasting) e treinar um agente de Reinforcement Learning (RL) para gerar sinais de compra e venda. Utilizaremos R para a coleta inicial de dados e Python (via reticulate) para a modelagem e visualiza√ß√£o.\nNota: As previs√µes e sinais gerados s√£o para fins demonstrativos e educacionais, n√£o constituindo recomenda√ß√£o financeira."
  },
  {
    "objectID": "page4.html#configura√ß√£o-do-ambiente",
    "href": "page4.html#configura√ß√£o-do-ambiente",
    "title": "An√°lise de Carteira com Forecasting e Reinforcement Learning",
    "section": "1. Configura√ß√£o do Ambiente",
    "text": "1. Configura√ß√£o do Ambiente\nPrimeiro, vamos carregar as bibliotecas R necess√°rias e configurar o reticulate para usar nosso ambiente Python.\n\n\nMostrar/Ocultar C√≥digo\n# Bibliotecas R\nlibrary(tidyverse) # Para manipula√ß√£o de dados e ggplot2\nlibrary(plotly)    # Para gr√°ficos interativos (se for recriar em R)\nlibrary(reticulate)  # Para executar c√≥digo Python\nlibrary(dplyr)     # Especificamente para a fun√ß√£o de busca de dados\nlibrary(quantmod)  # Para buscar dados financeiros\n\n\nConfigura√ß√£o do Python com reticulate\nCertifique-se de que o ambiente Python que voc√™ especificar abaixo tenha todas as bibliotecas Python necess√°rias instaladas: yahooquery, gymnasium, torch, numpy, pandas, matplotlib, yfinance, plotly.\n\n\nMostrar/Ocultar C√≥digo\n# Exemplo de como especificar um ambiente conda:\n# use_condaenv(\"meu_ambiente_python\", required = TRUE)\n\n# Ou um ambiente virtual:\n# use_virtualenv(\"caminho/para/meu_ambiente_virtual\", required = TRUE)\n\n# Ou especificar o execut√°vel Python diretamente:\n# use_python(\"/usr/bin/python3\", required = TRUE)\n\n# Se as bibliotecas n√£o estiverem instaladas, voc√™ pode tentar instal√°-las via reticulate:\n# py_install(c(\"yahooquery\", \"gymnasium\", \"torch\", \"numpy\", \"pandas\", \"matplotlib\", \"yfinance\", \"plotly\"), pip = TRUE)\n\nE o bloco de importa√ß√µes de bibliotecas tamb√©m precisa estar dentro de um bloco de c√≥digo delimitado corretamente:\n\n#| label: python-library-imports\n#| message: false\n#| warning: false\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom yahooquery import Ticker\nimport yfinance as yf\nfrom collections import deque\n\nimport gymnasium as gym\nfrom gymnasium import spaces\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"Bibliotecas Python importadas com sucesso.\")"
  },
  {
    "objectID": "page4.html#aquisi√ß√£o-de-dados-de-pre√ßos",
    "href": "page4.html#aquisi√ß√£o-de-dados-de-pre√ßos",
    "title": "An√°lise de Carteira com Forecasting e Reinforcement Learning",
    "section": "2. Aquisi√ß√£o de Dados de Pre√ßos",
    "text": "2. Aquisi√ß√£o de Dados de Pre√ßos\nUtilizaremos um script R para buscar os pre√ßos de fechamento ajustados para os tickers selecionados e salv√°-los em um arquivo CSV.\n\n\nMostrar/Ocultar C√≥digo\nfetch_close_prices_qm &lt;- function(tickers, start, end, cache_path = \"prices_qm.csv\") {\n  # Se j√° existe CSV em cache, carrega e retorna\n  if (file.exists(cache_path)) {\n    df &lt;- read.csv(cache_path, stringsAsFactors = FALSE) %&gt;%\n      mutate(date = as.Date(date))\n    message(\"Dados carregados do cache: \", cache_path)\n    return(df)\n  }\n\n  # Sen√£o, faz o download para cada ticker\n  all_data &lt;- lapply(tickers, function(tk) {\n    # getSymbols retorna um objeto xts com colunas Open, High, Low, Close, Volume, Adjusted\n    xts_data &lt;- tryCatch({\n        getSymbols(tk, src = \"yahoo\", from = start, to = end, auto.assign = FALSE)\n    }, error = function(e) {\n        message(paste(\"Erro ao buscar dados para\", tk, \":\", e$message))\n        return(NULL)\n    })\n\n    if (is.null(xts_data)) return(NULL)\n\n    close_prices &lt;- Ad(xts_data)  # usa Pre√ßo Ajustado (Adjusted Close)\n    data.frame(\n      date   = index(close_prices),\n      ticker = tk,\n      close  = as.numeric(close_prices),\n      row.names = NULL\n    )\n  })\n\n  # Remove NULLs (tickers com erro) e combina\n  all_data &lt;- all_data[!sapply(all_data, is.null)]\n  if (length(all_data) == 0) {\n    stop(\"Nenhum dado foi baixado para os tickers especificados.\")\n  }\n  df &lt;- bind_rows(all_data)\n\n  # Salva em CSV para pr√≥ximas execu√ß√µes\n  write.csv(df, cache_path, row.names = FALSE)\n  message(\"Dados salvos no cache: \", cache_path)\n\n  return(df)\n}\n\n\n\n\nMostrar/Ocultar C√≥digo\ntickers &lt;- c(\"BRFS3.SA\", \"JBSS3.SA\", \"BEEF3.SA\", \"MRFG3.SA\", \"TSN\", \"HRL\", \"GIS\")\nstart_date &lt;- \"2020-01-01\" \nend_date &lt;- format(Sys.Date(), \"%Y-%m-%d\") # Usar data atual para 'to'\n\ndf_prices_r &lt;- fetch_close_prices_qm(tickers, start_date, end_date, cache_path = \"prices_analise.csv\") \n\n\nDados carregados do cache: prices_analise.csv\n\n\nMostrar/Ocultar C√≥digo\ntail(df_prices_r)\n\n\n           date ticker close\n9385 2025-05-08    GIS 54.71\n9386 2025-05-09    GIS 54.50\n9387 2025-05-12    GIS 54.84\n9388 2025-05-13    GIS 53.77\n9389 2025-05-14    GIS 53.28\n9390 2025-05-15    GIS 54.40"
  },
  {
    "objectID": "page4.html#prepara√ß√£o-e-an√°lise-explorat√≥ria-dos-dados-python",
    "href": "page4.html#prepara√ß√£o-e-an√°lise-explorat√≥ria-dos-dados-python",
    "title": "An√°lise de Carteira com Forecasting e Reinforcement Learning",
    "section": "3. Prepara√ß√£o e An√°lise Explorat√≥ria dos Dados (Python)",
    "text": "3. Prepara√ß√£o e An√°lise Explorat√≥ria dos Dados (Python)\nCarregamos os dados do CSV em um DataFrame pandas e o pivotamos para facilitar a an√°lise por ticker.\n\n\nMostrar/Ocultar C√≥digo\nimport pandas as pd\n# Carregar dados do CSV salvo pelo R\ndf_prices = pd.read_csv('prices_analise.csv', parse_dates=['date'])\nprint(\"Tail do df_prices carregado:\")\n\n\nTail do df_prices carregado:\n\n\nMostrar/Ocultar C√≥digo\nprint(df_prices.tail())\n\n\n           date ticker      close\n9385 2025-05-09    GIS  54.500000\n9386 2025-05-12    GIS  54.840000\n9387 2025-05-13    GIS  53.770000\n9388 2025-05-14    GIS  53.279999\n9389 2025-05-15    GIS  54.400002\n\n\nMostrar/Ocultar C√≥digo\n# Pivotear somente as colunas 'ticker' e 'close'\ndf_pivot = df_prices.pivot(index='date', columns='ticker', values='close')\ndf_pivot = df_pivot.reset_index() # Manter 'date' como coluna\n\nprint(\"\\\\nTail do df_pivot:\")\n\n\n\\nTail do df_pivot:\n\n\nMostrar/Ocultar C√≥digo\nprint(df_pivot.tail())\n\n\nticker       date  BEEF3.SA   BRFS3.SA  ...   JBSS3.SA   MRFG3.SA        TSN\n1380   2025-05-09      4.96  19.200001  ...  42.360001  19.850000  55.299999\n1381   2025-05-12      5.07  19.709999  ...  41.889999  19.820000  55.990002\n1382   2025-05-13      5.11  20.200001  ...  40.849998  20.090000  55.360001\n1383   2025-05-14      5.15  19.680000  ...  39.349998  19.799999  54.500000\n1384   2025-05-15      5.14  20.620001  ...  39.180000  20.660000  55.650002\n\n[5 rows x 8 columns]"
  },
  {
    "objectID": "page4.html#forecasting-de-pre√ßos-python-com-plotly",
    "href": "page4.html#forecasting-de-pre√ßos-python-com-plotly",
    "title": "An√°lise de Carteira com Forecasting e Reinforcement Learning",
    "section": "4. Forecasting de Pre√ßos (Python com Plotly)",
    "text": "4. Forecasting de Pre√ßos (Python com Plotly)\nRealizamos uma simula√ß√£o simples de forecasting baseada na m√©dia e desvio padr√£o dos retornos logar√≠tmicos hist√≥ricos.\n\n\nMostrar/Ocultar C√≥digo\nimport numpy as np\nimport pandas as pd \nimport plotly.express as px\n# Defina a data de corte e o per√≠odo do forecast\n# Usar a data mais recente do df_pivot como CUT\nCUT = df_pivot[\"date\"].max()\nforecast_days = 30\nfuture_dates = pd.date_range(CUT + pd.Timedelta(days=1), periods=forecast_days, freq=\"D\")\n\n# Lista de ativos (tickers)\nassets = df_pivot.columns[1:]  # Ignorando a coluna 'date'\n\n# Lista para armazenar os dados de forecast\nforecast_data = []\n\n# Gera previs√µes para cada ativo (simula√ß√£o simples)\nfor asset in assets:\n    # Pega os dados hist√≥ricos at√© a data de corte\n    df_asset_hist = df_pivot[[\"date\", asset]].copy() # Usar .copy() para evitar SettingWithCopyWarning\n    df_asset_hist = df_asset_hist[df_asset_hist[\"date\"] &lt;= CUT]\n    df_asset_hist.dropna(subset=[asset], inplace=True) # Remover NaNs que podem atrapalhar pct_change\n\n    if len(df_asset_hist) &lt; 2: # Precisa de pelo menos 2 pontos para pct_change\n        print(f\"Dados insuficientes para forecasting do ativo: {asset}\")\n        continue\n\n    # Calcula a m√©dia e desvio padr√£o dos retornos hist√≥ricos\n    df_asset_hist[\"logret\"] = df_asset_hist[asset].pct_change()\n    # Remover o primeiro NaN de logret e quaisquer outros NaNs/infs\n    df_asset_hist.replace([np.inf, -np.inf], np.nan, inplace=True)\n    df_asset_hist.dropna(subset=['logret'], inplace=True)\n\n    if df_asset_hist[\"logret\"].empty:\n        print(f\"N√£o foi poss√≠vel calcular retornos para o ativo: {asset}\")\n        mu = 0 # Default mu\n        sigma = 0.01 # Default sigma para evitar erro com scale=0\n    else:\n        mu = df_asset_hist[\"logret\"].mean()\n        sigma = df_asset_hist[\"logret\"].std()\n        if pd.isna(sigma) or sigma == 0: # Adiciona uma pequena volatilidade se std for 0 ou NaN\n            sigma = 0.01 \n\n    # Simula os retornos futuros\n    simulated_logrets = np.random.normal(loc=mu, scale=sigma, size=forecast_days)\n    last_price = df_asset_hist[asset].iloc[-1]\n    if pd.isna(last_price): # Se o √∫ltimo pre√ßo for NaN, use um pre√ßo padr√£o ou pule\n        print(f\"√öltimo pre√ßo √© NaN para o ativo: {asset}. Pulando forecast.\")\n        continue\n        \n    simulated_prices = last_price * (1 + simulated_logrets).cumprod()\n\n    # Adiciona os dados de forecast\n    for date_val, value in zip(future_dates, simulated_prices):\n        forecast_data.append({\n            \"date\": date_val,\n            \"asset\": asset,\n            \"price\": value,\n            \"rep\": \"Forecast\"\n        })\n\ndf_forecast = pd.DataFrame(forecast_data)\n\n# Prepara o hist√≥rico para plotar junto, filtrando at√© a data de corte\nhist_data = df_pivot[df_pivot[\"date\"] &lt;= CUT].copy()\nhist_data = hist_data.melt(id_vars=\"date\", var_name=\"asset\", value_name=\"price\")\nhist_data[\"rep\"] = \"Hist√≥rico\"\n\n# Junta hist√≥rico e forecast\ndf_plot = pd.concat([hist_data, df_forecast], ignore_index=True)\n\n# Filtra os dados para mostrar apenas o per√≠odo relevante (√∫ltimos N dias de hist√≥rico + forecast)\n# Por exemplo, √∫ltimos 60 dias de hist√≥rico + 30 dias de forecast\nstart_plot_date = CUT - pd.Timedelta(days=60)\nend_plot_date = CUT + pd.Timedelta(days=forecast_days)\n\ndf_plot_filtered = df_plot[(df_plot[\"date\"] &gt;= start_plot_date) & (df_plot[\"date\"] &lt;= end_plot_date)]\n\nif not df_plot_filtered.empty:\n    fig_forecast = px.line(\n        df_plot_filtered,\n        x=\"date\",\n        y=\"price\",\n        color=\"rep\",\n        facet_col=\"asset\",\n        facet_col_wrap=2, # Ajuste conforme o n√∫mero de tickers\n        labels={\"date\": \"Data\", \"price\": \"Pre√ßo (Moeda Local/USD)\", \"rep\": \"S√©rie\"},\n        title=f\"Forecasting de Pre√ßos ({forecast_days} dias) a partir de {CUT.strftime('%Y-%m-%d')}\"\n    )\n    fig_forecast.update_layout(width=1000, height=300 * (len(assets)//2 + len(assets)%2)) # Ajusta altura\n    fig_forecast.update_xaxes(matches=None, nticks=5)\n    fig_forecast.show()\nelse:\n    print(\"Nenhum dado para plotar no gr√°fico de forecast.\")\n\n\n                        \n                                            \nForecasting de Pre√ßos para os Tickers da Carteira (Pr√≥ximos 30 dias)"
  },
  {
    "objectID": "page4.html#reinforcement-learning-para-sinais-de-trading",
    "href": "page4.html#reinforcement-learning-para-sinais-de-trading",
    "title": "An√°lise de Carteira com Forecasting e Reinforcement Learning",
    "section": "5. Reinforcement Learning para Sinais de Trading",
    "text": "5. Reinforcement Learning para Sinais de Trading\n\n5.1. Defini√ß√£o do Agente e Fun√ß√µes Auxiliares\nDefinimos a fun√ß√£o getState e a classe Agent que representa nosso agente de RL.\n\n\nMostrar/Ocultar C√≥digo\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\ndef getState(data, t, window_size):\n    \"\"\"\n    Converte uma janela de pre√ßos em vetor de retornos normalizados.\n    \"\"\"\n    d = t - window_size + 1\n    block = data[d:t+1] if d &gt;= 0 else -d * [data[0]] + list(data[0:t+1])\n    # Evitar divis√£o por zero se block[i] for 0\n    res = []\n    for i in range(len(block)-1):\n        if block[i] != 0:\n            res.append((block[i+1] - block[i]) / block[i])\n        else:\n            res.append(0) # Retorno zero se o pre√ßo base for zero\n    return np.array(res, dtype=np.float32)\n\nclass Agent(nn.Module):\n    def __init__(\n        self,\n        state_size,\n        hidden_size=64,\n        lr=1e-4,\n        gamma=0.95,\n        epsilon=1.0,\n        epsilon_min=0.01,\n        epsilon_decay=0.995\n    ):\n        super(Agent, self).__init__()\n        self.gamma = gamma\n        self.epsilon = epsilon\n        self.epsilon_min = epsilon_min\n        self.epsilon_decay = epsilon_decay\n        self.inventory = [] # Adicionado para manter o invent√°rio do agente\n        \n        self.model = nn.Sequential(\n            nn.Linear(state_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, 3)  # Q para 3 a√ß√µes: 0=HOLD, 1=BUY, 2=SELL\n        )\n        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n        self.criterion = nn.MSELoss()\n\n    def act(self, state):\n        if np.random.rand() &lt; self.epsilon:\n            return np.random.choice([0,1,2]) # 0: HOLD, 1: BUY, 2: SELL\n        state_t = torch.from_numpy(state).unsqueeze(0)\n        q_values = self.model(state_t).detach().numpy()[0]\n        return np.argmax(q_values)\n\n    def train_step(self, state, action, reward, next_state, done): # Adicionado 'done'\n        state_t = torch.from_numpy(state).unsqueeze(0)\n        next_t = torch.from_numpy(next_state).unsqueeze(0)\n        \n        q_values = self.model(state_t)\n        \n        with torch.no_grad():\n            q_next = self.model(next_t).max(1)[0]\n            if done: # Se for o estado terminal, o valor do pr√≥ximo estado √© 0\n                 target_q_value = reward\n            else:\n                 target_q_value = reward + self.gamma * q_next\n\n        target = q_values.clone().detach()\n        target[0, action] = target_q_value\n        \n        loss = self.criterion(q_values, target)\n        self.optimizer.zero_grad()\n        loss.backward()\n        self.optimizer.step()\n        \n        if self.epsilon &gt; self.epsilon_min:\n            self.epsilon *= self.epsilon_decay\n\nprint(\"Defini√ß√µes do Agente RL carregadas.\")\n\n\nDefini√ß√µes do Agente RL carregadas.\n\n\n\n\n5.2. Treinamento do Agente RL\nTreinamos o agente para cada ticker da nossa lista.\n\n\nMostrar/Ocultar C√≥digo\nimport numpy as np\nimport torch\nimport torch.nn as nn\n# Par√¢metros de treinamento\nwindow_size = 10  # Deve ser state_size - 1 se getState retorna len(block)-1\nepisodes    = 50 # Reduzido para demonstra√ß√£o r√°pida, pode aumentar para melhor performance\nrl_results  = {}\n\n# Tickers para o treinamento (obtidos do df_pivot)\n# A primeira coluna √© 'date', ent√£o pegamos da segunda em diante\ntrain_tickers = df_pivot.columns[1:].tolist() \n\nfor tk in train_tickers:\n    print(f\"\\\\n=== Treinando para {tk} ===\")\n    \n    # Prepara s√©rie de pre√ßos para o ticker\n    prices = df_prices[df_prices['ticker'] == tk].sort_values(\"date\")['close'].values\n    prices = prices[~np.isnan(prices)] # Remover NaNs dos pre√ßos\n\n    if len(prices) &lt; window_size + 2: # Checagem mais robusta para dados suficientes\n        print(f\"Dados insuficientes para {tk} ap√≥s remover NaNs. Pulando ticker.\")\n        rl_results[tk] = [0] * episodes # Adiciona placeholder para evitar erro no plot\n        continue\n\n    # O state_size √© o tamanho da sa√≠da de getState, que √© window_size\n    agent = Agent(state_size=window_size) \n    total_profits_tk = []\n\n    for e in range(episodes):\n        state = getState(prices, 0, window_size + 1) # getState espera window_size + 1 para gerar 'window_size' retornos\n        agent.inventory = []\n        total_profit   = 0.0 # Inicializar como float\n\n        for t in range(len(prices)-1): # Loop at√© o pen√∫ltimo pre√ßo\n            action     = agent.act(state)\n            # O next_state √© para o tempo t+1, ent√£o o √∫ltimo t+1 ser√° len(prices)-1\n            next_state = getState(prices, t + 1, window_size + 1)\n            reward     = 0.0 # Inicializar como float\n            done = (t == len(prices) - 2) # 'done' √© true no √∫ltimo passo\n\n            # Executa a√ß√£o: BUY, SELL ou HOLD\n            if action == 1:  # BUY\n                agent.inventory.append(prices[t])\n            elif action == 2 and agent.inventory:  # SELL\n                bought_price = agent.inventory.pop(0)\n                profit       = prices[t] - bought_price\n                if bought_price != 0: # Evitar divis√£o por zero\n                    reward = profit / bought_price\n                else:\n                    reward = 0.0\n                total_profit += profit\n            \n            agent.train_step(state, action, reward, next_state, done)\n            state = next_state\n\n        total_profits_tk.append(total_profit)\n        if (e+1) % 10 == 0 or e == episodes -1 : # Imprimir a cada 10 epis√≥dios e no √∫ltimo\n            print(f\"Epis√≥dio {e+1}/{episodes} ‚Äî Lucro: {total_profit:.2f}\")\n    \n    rl_results[tk] = total_profits_tk\n\n\n\\n=== Treinando para BEEF3.SA ===\nEpis√≥dio 10/50 ‚Äî Lucro: 0.89\nEpis√≥dio 20/50 ‚Äî Lucro: 2.68\nEpis√≥dio 30/50 ‚Äî Lucro: 607.59\nEpis√≥dio 40/50 ‚Äî Lucro: -6.41\nEpis√≥dio 50/50 ‚Äî Lucro: -10.22\n\\n=== Treinando para BRFS3.SA ===\nEpis√≥dio 10/50 ‚Äî Lucro: 0.77\nEpis√≥dio 20/50 ‚Äî Lucro: 59.63\nEpis√≥dio 30/50 ‚Äî Lucro: 3.08\nEpis√≥dio 40/50 ‚Äî Lucro: -16.35\nEpis√≥dio 50/50 ‚Äî Lucro: -16.92\n\\n=== Treinando para GIS ===\nEpis√≥dio 10/50 ‚Äî Lucro: 96.41\nEpis√≥dio 20/50 ‚Äî Lucro: 8.61\nEpis√≥dio 30/50 ‚Äî Lucro: -16.59\nEpis√≥dio 40/50 ‚Äî Lucro: 84.06\nEpis√≥dio 50/50 ‚Äî Lucro: 63.60\n\\n=== Treinando para HRL ===\nEpis√≥dio 10/50 ‚Äî Lucro: 33.96\nEpis√≥dio 20/50 ‚Äî Lucro: -12.28\nEpis√≥dio 30/50 ‚Äî Lucro: -10.20\nEpis√≥dio 40/50 ‚Äî Lucro: -9.64\nEpis√≥dio 50/50 ‚Äî Lucro: 76.36\n\\n=== Treinando para JBSS3.SA ===\nEpis√≥dio 10/50 ‚Äî Lucro: 0.27\nEpis√≥dio 20/50 ‚Äî Lucro: 33.14\nEpis√≥dio 30/50 ‚Äî Lucro: 49.65\nEpis√≥dio 40/50 ‚Äî Lucro: 29.81\nEpis√≥dio 50/50 ‚Äî Lucro: 32.77\n\\n=== Treinando para MRFG3.SA ===\nEpis√≥dio 10/50 ‚Äî Lucro: 28.93\nEpis√≥dio 20/50 ‚Äî Lucro: -1.70\nEpis√≥dio 30/50 ‚Äî Lucro: -0.90\nEpis√≥dio 40/50 ‚Äî Lucro: 0.02\nEpis√≥dio 50/50 ‚Äî Lucro: 52.42\n\\n=== Treinando para TSN ===\nEpis√≥dio 10/50 ‚Äî Lucro: 72.40\nEpis√≥dio 20/50 ‚Äî Lucro: 7.64\nEpis√≥dio 30/50 ‚Äî Lucro: 15.12\nEpis√≥dio 40/50 ‚Äî Lucro: -32.55\nEpis√≥dio 50/50 ‚Äî Lucro: -87.95\n\n\nMostrar/Ocultar C√≥digo\n# Plot da evolu√ß√£o do lucro\nif rl_results: # Apenas plotar se houver resultados\n    df_hist_profit = pd.DataFrame(rl_results)\n    # Adicionar coluna 'Epis√≥dio' se o √≠ndice n√£o for usado diretamente\n    if not isinstance(df_hist_profit.index, pd.RangeIndex) or df_hist_profit.index.name != 'Epis√≥dio':\n        df_hist_profit = df_hist_profit.reset_index().rename(columns={'index': 'Epis√≥dio'})\n        # Se o √≠ndice j√° √© RangeIndex (0 a N-1), apenas nomeie-o ou use-o diretamente\n    elif df_hist_profit.index.name != 'Epis√≥dio':\n         df_hist_profit.index.name = 'Epis√≥dio'\n         df_hist_profit = df_hist_profit.reset_index()\n\n    df_melt_profit = df_hist_profit.melt(\n        id_vars='Epis√≥dio',\n        var_name='ticker',\n        value_name='Lucro'\n    )\n\n    fig_profit_evol = px.line(\n        df_melt_profit,\n        x='Epis√≥dio',\n        y='Lucro',\n        color='ticker',\n        title='Evolu√ß√£o do Lucro Total por Epis√≥dio (Treinamento RL)'\n    )\n    fig_profit_evol.update_layout(\n        xaxis_title='Epis√≥dio',\n        yaxis_title='Lucro Total (Moeda Local/USD)'\n    )\n    fig_profit_evol.show()\nelse:\n    print(\"Nenhum resultado de treinamento RL para plotar.\")\n\n\n                        \n                                            \nEvolu√ß√£o do Lucro Total por Epis√≥dio Durante o Treinamento do Agente RL\n\n\n\n\n5.3. Gera√ß√£o de Sinais de Trading e Visualiza√ß√£o\nAp√≥s o treinamento, usamos o agente para gerar sinais de COMPRA/VENDA e os visualizamos.\n\n\nMostrar/Ocultar C√≥digo\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots # Importe make_subplots aqui\nimport torch\nimport torch.nn as nn\n# 1) Gera sinais para cada ticker\nall_signals = {}\n# Usar a √∫ltima inst√¢ncia do agente treinada ou treinar um novo/carregar\n# Para este exemplo, vamos reusar a √∫ltima inst√¢ncia 'agent' do loop de treinamento,\n# que foi treinada no √∫ltimo ticker da lista 'train_tickers'.\n# Idealmente, voc√™ teria um agente treinado por ticker ou um agente geral.\n# Aqui, vamos gerar sinais para todos os tickers usando o agente treinado no √öLTIMO ticker.\n# Isto √© mais para demonstra√ß√£o da plotagem.\n# Para uma an√°lise real, voc√™ deveria ter um agente espec√≠fico por ticker ou um agente treinado em todos.\n\n# Se 'agent' n√£o foi definido (ex: todos os tickers foram pulados no treinamento)\nif 'agent' not in locals() and train_tickers:\n    print(\"Agente n√£o treinado. Treinando um agente no primeiro ticker dispon√≠vel para demonstra√ß√£o de sinais.\")\n    tk_demo = train_tickers[0]\n    prices_demo = df_prices[df_prices['ticker'] == tk_demo].sort_values(\"date\")['close'].values\n    prices_demo = prices_demo[~np.isnan(prices_demo)]\n    if len(prices_demo) &gt;= window_size + 2:\n        agent = Agent(state_size=window_size)\n        # Treinamento r√°pido apenas para ter um agente\n        for e_demo in range(5): # Treino muito curto\n            state_demo = getState(prices_demo, 0, window_size + 1)\n            for t_demo in range(len(prices_demo) -1):\n                action_demo = agent.act(state_demo)\n                next_state_demo = getState(prices_demo, t_demo + 1, window_size + 1)\n                # Recompensa e 'done' simplificados para este agente de demonstra√ß√£o\n                agent.train_step(state_demo, action_demo, 0, next_state_demo, (t_demo == len(prices_demo) - 2))\n                state_demo = next_state_demo\n    else:\n        agent = None # N√£o foi poss√≠vel treinar agente de demonstra√ß√£o\n        print(f\"N√£o foi poss√≠vel treinar agente de demonstra√ß√£o para {tk_demo}\")\n\n\nif agent: # Prossiga apenas se o agente existir\n    for tk_signal in train_tickers: # Usar train_tickers para consist√™ncia\n        agent.epsilon = agent.epsilon_min # Usar pol√≠tica greedy para gera√ß√£o de sinais\n        \n        current_prices_tk = df_prices[df_prices.ticker==tk_signal].sort_values('date')\n        \n        if current_prices_tk.empty or 'close' not in current_prices_tk.columns:\n            print(f\"Aviso: Nenhum dado de pre√ßo para {tk_signal} na gera√ß√£o de sinais. Pulando.\")\n            all_signals[tk_signal] = pd.DataFrame(columns=['date', 'action', 'price'])\n            continue\n\n        dates_signal  = current_prices_tk['date'].values\n        values_signal = current_prices_tk['close'].values\n        values_signal = values_signal[~np.isnan(values_signal)] # Remover NaNs\n\n        if len(values_signal) &lt; window_size + 2:\n            print(f\"Dados insuficientes para {tk_signal} na gera√ß√£o de sinais ap√≥s remover NaNs. Pulando.\")\n            all_signals[tk_signal] = pd.DataFrame(columns=['date', 'action', 'price'])\n            continue\n            \n        state_signal = getState(values_signal, 0, window_size+1)\n        agent.inventory = [] # Resetar invent√°rio para cada ticker\n        signals_current_tk = []\n\n        for t_signal in range(len(values_signal)-1):\n            action_signal = agent.act(state_signal)\n            date_val  = dates_signal[t_signal]\n            price_val = values_signal[t_signal]\n            \n            if action_signal == 1: # BUY\n                signals_current_tk.append({'date': date_val, 'action': 'BUY',  'price': price_val})\n                agent.inventory.append(price_val)\n            elif action_signal == 2 and agent.inventory: # SELL\n                signals_current_tk.append({'date': date_val, 'action': 'SELL', 'price': price_val})\n                agent.inventory.pop(0)\n            \n            next_state_signal = getState(values_signal, t_signal+1, window_size+1)\n            state_signal = next_state_signal\n\n        if signals_current_tk:\n            all_signals[tk_signal] = pd.DataFrame(signals_current_tk)\n        else:\n            all_signals[tk_signal] = pd.DataFrame(columns=['date', 'action', 'price'])\nelse:\n    print(\"Agente RL n√£o est√° definido. Pulando gera√ß√£o e visualiza√ß√£o de sinais.\")\n    all_signals = {tk: pd.DataFrame(columns=['date', 'action', 'price']) for tk in train_tickers}\n\n\nnp.float64(10.5756063461304)\nnp.float64(10.6932888031006)\nnp.float64(11.4229106903076)\nnp.float64(11.3366088867188)\nnp.float64(11.4893159866333)\nnp.float64(13.9750709533691)\nnp.float64(14.4566497802734)\nnp.float64(15.0493640899658)\nnp.float64(16.373706817627)\nnp.float64(16.234790802002)\nnp.float64(44.5136642456055)\nnp.float64(44.9762153625488)\nnp.float64(44.8921089172363)\nnp.float64(42.1858367919922)\nnp.float64(39.0825309753418)\nnp.float64(42.0554466247559)\nnp.float64(41.1774749755859)\nnp.float64(43.8619689941406)\nnp.float64(43.8258438110352)\nnp.float64(43.0248756408691)\nnp.float64(44.7806282043457)\nnp.float64(19.4537944793701)\nnp.float64(20.1444644927979)\nnp.float64(20.1918601989746)\nnp.float64(20.3746871948242)\nnp.float64(14.9306020736694)\nnp.float64(14.6055812835693)\nnp.float64(7.17265319824219)\nnp.float64(7.2646951675415)\nnp.float64(7.46850156784058)\nnp.float64(51.1741600036621)\nnp.float64(50.0667533874512)\nnp.float64(47.8779144287109)\n\n\nMostrar/Ocultar C√≥digo\n# 2) Cria figura com uma linha por ticker\nif train_tickers and all_signals : # Apenas se houver tickers e sinais\n    fig_signals = make_subplots(\n        rows=len(train_tickers), cols=1,\n        shared_xaxes=True,\n        subplot_titles=train_tickers,\n        vertical_spacing=0.02\n    )\n\n    for i, tk_plot in enumerate(train_tickers, start=1):\n        prices_tk_plot = df_prices[df_prices.ticker==tk_plot].sort_values('date')\n        sig_df_plot = all_signals.get(tk_plot, pd.DataFrame(columns=['date', 'action', 'price']))\n\n        if not prices_tk_plot.empty and 'close' in prices_tk_plot.columns:\n            fig_signals.add_trace(\n                go.Scatter(x=prices_tk_plot['date'], y=prices_tk_plot['close'], mode='lines', name=f'Pre√ßo {tk_plot}', legendgroup=f'group{tk_plot}'),\n                row=i, col=1\n            )\n        \n        buy_signals_plot = sig_df_plot.query(\"action=='BUY'\")\n        if not buy_signals_plot.empty:\n            fig_signals.add_trace(\n                go.Scatter(x=buy_signals_plot['date'],\n                           y=buy_signals_plot['price'],\n                           mode='markers', marker_symbol='triangle-up',\n                           marker_size=8, marker_color='green', \n                           name=f'Compra', showlegend=(i==1), legendgroup=f'group_buy'), # Mostrar legenda apenas uma vez\n                row=i, col=1\n            )\n        \n        sell_signals_plot = sig_df_plot.query(\"action=='SELL'\")\n        if not sell_signals_plot.empty:\n            fig_signals.add_trace(\n                go.Scatter(x=sell_signals_plot['date'],\n                           y=sell_signals_plot['price'],\n                           mode='markers', marker_symbol='triangle-down',\n                           marker_size=8, marker_color='red',\n                           name=f'Venda', showlegend=(i==1), legendgroup=f'group_sell'), # Mostrar legenda apenas uma vez\n                row=i, col=1\n            )\n\n    fig_signals.update_layout(\n        height=max(300 * len(train_tickers), 800), # Ajusta altura dinamicamente, m√≠nimo de 800px\n        title_text='Sinais de Compra/Venda por Ticker (Agente RL)',\n        legend_tracegroupgap = 180 # Espa√ßamento entre grupos de legenda\n    )\n    fig_signals.update_yaxes(title_text=\"Pre√ßo\") \n    # Aplicar t√≠tulo do eixo X apenas ao √∫ltimo subplot vis√≠vel\n    # Encontrar o √∫ltimo subplot que realmente tem dados para o eixo X\n    last_row_with_data = 0\n    for r in range(len(train_tickers), 0, -1):\n        if not df_prices[df_prices.ticker==train_tickers[r-1]].empty:\n            last_row_with_data = r\n            break\n    if last_row_with_data &gt; 0:\n      fig_signals.update_xaxes(title_text=\"Data\", row=last_row_with_data, col=1)\n    \n    fig_signals.show()\nelse:\n    print(\"Nenhum ticker ou sinal para plotar.\")\n\n\n                        \n                                            \nSinais de Compra/Venda Gerados pelo Agente RL por Ticker"
  },
  {
    "objectID": "page4.html#conclus√£o",
    "href": "page4.html#conclus√£o",
    "title": "An√°lise de Carteira com Forecasting e Reinforcement Learning",
    "section": "6. Conclus√£o",
    "text": "6. Conclus√£o\nEste documento demonstrou um pipeline para an√°lise de dados financeiros, incluindo coleta de dados, forecasting e a aplica√ß√£o de um agente de Reinforcement Learning para gerar sinais de trading. Os resultados visuais do forecasting e dos sinais do agente RL fornecem insights que podem auxiliar na tomada de decis√µes de investimento, lembrando sempre da import√¢ncia de an√°lises complementares e do gerenciamento de risco.\nOs gr√°ficos de evolu√ß√£o do lucro durante o treinamento do agente RL indicam a capacidade de aprendizado do modelo em diferentes ativos, embora a performance possa variar significativamente. A visualiza√ß√£o final dos sinais de compra e venda sobrepostos aos pre√ßos hist√≥ricos permite uma avalia√ß√£o qualitativa da estrat√©gia do agente."
  },
  {
    "objectID": "page2.html",
    "href": "page2.html",
    "title": "Ci√™ncia de Dados para Neg√≥cios: Big Data for Finance Project",
    "section": "",
    "text": "Resumo\n\n\n\n\n\nAn√°lise de S√©ries de Pre√ßos e Log-Retornos\n\n\n\n\n\nIntro\n\n1Ô∏è‚É£ Convers√£o para Log-Retornos2Ô∏è‚É£ Constru√ß√£o e Avalia√ß√£o das Distribui√ß√µes3Ô∏è‚É£ C√°lculo da Vari√¢ncia\n\n\nConverter a s√©rie de pre√ßos em log-retornos utilizando a seguinte f√≥rmula:\n[ p_t = \\ln(p_t) - \\ln(p_{t-1}) ]\nEssa transforma√ß√£o nos permite analisar os retornos percentuais de forma mais adequada.\n\n\n\n\nConstruir os histogramas de cada s√©rie de retornos transformada.\nAvaliar a assimetria das distribui√ß√µes e identificar se h√° predomin√¢ncia de retornos positivos ou negativos no per√≠odo analisado.\n\n\n\n\nCalcular a vari√¢ncia da s√©rie de retornos logar√≠tmicos utilizando:\n\nüîπ O desvio padr√£o como medida direta (volatilidade hist√≥rica com janela de 5 dias).\nüîπ Ou de maneira mais acurada, modelos econom√©tricos (ex.: GARCH(1,1)) para obter a vari√¢ncia condicional.\n\ndate BEEF3.SA BRFS3.SA GIS HRL JBSS3.SA MRFG3.SA \\ 1238 2025-03-14 0.031093 0.024722 0.024976 0.014724 0.015667 0.024863 1239 2025-03-17 0.031816 0.026581 0.028208 0.015502 0.016132 0.028757 1240 2025-03-18 0.022213 0.040627 0.021501 0.014557 0.073009 0.036127 1241 2025-03-19 0.021905 0.039398 0.015938 0.007907 0.073728 0.035161 1242 2025-03-20 0.033103 0.034645 0.016877 0.007681 0.071088 0.039908\nTSN 1238 0.011254 1239 0.011458 1240 0.011033 1241 0.006089 1242 0.006956\n\n\n\n\n4Ô∏è‚É£ Visualiza√ß√µes\n\n\n\nüìâ Gr√°ficos de s√©ries temporais de pre√ßos:"
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html",
    "href": "fuzzy_topsis_analise_acoes.html",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "",
    "text": "Mostrar/Ocultar C√≥digo\nimport yfinance as yf\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler"
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html#bibliotecas",
    "href": "fuzzy_topsis_analise_acoes.html#bibliotecas",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "",
    "text": "Mostrar/Ocultar C√≥digo\nimport yfinance as yf\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler"
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html#download-dos-dados",
    "href": "fuzzy_topsis_analise_acoes.html#download-dos-dados",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "Download dos Dados",
    "text": "Download dos Dados\n\n\nMostrar/Ocultar C√≥digo\n# Tickers da carteira\ntickers = ['BRFS3.SA', 'JBSS3.SA', 'BEEF3.SA', 'MRFG3.SA', 'TSN', 'HRL', 'GIS']\n\n# Download dos pre√ßos hist√≥ricos\ndados = yf.download(tickers, start=\"2024-10-01\", end=\"2025-04-25\", progress=False)\n\n# Verifica√ß√£o dos dados baixados\nif isinstance(dados.columns, pd.MultiIndex):\n    downloaded_tickers = dados.columns.levels[1].tolist()\n    available_tickers = [ticker for ticker in downloaded_tickers if not dados[('Close', ticker)].isnull().all()]\nelse:\n    if not dados.empty:\n        available_tickers = [ticker for ticker in tickers if not dados[ticker].isnull().all()]\n    else:\n        available_tickers = []\n\nif not available_tickers:\n    raise ValueError(\"‚ùå Nenhum dado foi baixado. Verifique os tickers e o per√≠odo.\")\n\nprint(f\"‚úÖ Dados baixados para: {', '.join(available_tickers)}\")\n\n\nC:\\Users\\kuiav\\AppData\\Local\\Temp\\ipykernel_15988\\1853906305.py:5: FutureWarning:\n\nYF.download() has changed argument auto_adjust default to True\n\n\n\n‚úÖ Dados baixados para: BEEF3.SA, BRFS3.SA, GIS, HRL, JBSS3.SA, MRFG3.SA, TSN"
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html#prepara√ß√£o-dos-dados",
    "href": "fuzzy_topsis_analise_acoes.html#prepara√ß√£o-dos-dados",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "Prepara√ß√£o dos Dados",
    "text": "Prepara√ß√£o dos Dados\n\n\nMostrar/Ocultar C√≥digo\nprecos = pd.DataFrame()\n\nfor ticker in available_tickers:\n    if ('Adj Close', ticker) in dados.columns and (not dados[('Adj Close', ticker)].isnull().all()):\n        precos[ticker] = dados[('Adj Close', ticker)]\n    elif ('Close', ticker) in dados.columns and (not dados[('Close', ticker)].isnull().all()):\n        print(f\"‚ö†Ô∏è Usando 'Close' para {ticker}, pois 'Adj Close' n√£o est√° dispon√≠vel.\")\n        precos[ticker] = dados[('Close', ticker)]\n    else:\n        print(f\"‚ùå Dados insuficientes para {ticker}. Ignorando.\")\n\nif precos.empty:\n    raise ValueError(\"‚ùå Nenhuma coluna v√°lida encontrada para an√°lise.\")\n\nprecos = precos.dropna()\n\nif precos.empty:\n    raise ValueError(\"‚ùå Dados insuficientes ap√≥s remo√ß√£o de valores nulos.\")\n\n\n‚ö†Ô∏è Usando 'Close' para BEEF3.SA, pois 'Adj Close' n√£o est√° dispon√≠vel.\n‚ö†Ô∏è Usando 'Close' para BRFS3.SA, pois 'Adj Close' n√£o est√° dispon√≠vel.\n‚ö†Ô∏è Usando 'Close' para GIS, pois 'Adj Close' n√£o est√° dispon√≠vel.\n‚ö†Ô∏è Usando 'Close' para HRL, pois 'Adj Close' n√£o est√° dispon√≠vel.\n‚ö†Ô∏è Usando 'Close' para JBSS3.SA, pois 'Adj Close' n√£o est√° dispon√≠vel.\n‚ö†Ô∏è Usando 'Close' para MRFG3.SA, pois 'Adj Close' n√£o est√° dispon√≠vel.\n‚ö†Ô∏è Usando 'Close' para TSN, pois 'Adj Close' n√£o est√° dispon√≠vel."
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html#c√°lculo-de-retornos",
    "href": "fuzzy_topsis_analise_acoes.html#c√°lculo-de-retornos",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "C√°lculo de Retornos",
    "text": "C√°lculo de Retornos\n\n\nMostrar/Ocultar C√≥digo\nretornos_diarios = precos.pct_change().dropna()\n\nif retornos_diarios.empty:\n    raise ValueError(\"‚ùå Retornos di√°rios insuficientes.\")\n\nretorno_medio_anual = (retornos_diarios.mean() * 252) * 100\nrisco_anual = (retornos_diarios.std() * np.sqrt(252)) * 100\n\ndf = pd.DataFrame({\n    'Ticker': retorno_medio_anual.index,\n    'Retorno Esperado (%)': retorno_medio_anual.values,\n    'Risco (%)': risco_anual.values\n})\n\ndf\n\n\n\n\n\n\n\n\n\nTicker\nRetorno Esperado (%)\nRisco (%)\n\n\n\n\n0\nBEEF3.SA\n19.952812\n52.777333\n\n\n1\nBRFS3.SA\n-5.995730\n38.618763\n\n\n2\nGIS\n-44.667148\n24.262767\n\n\n3\nHRL\n-1.237448\n21.940254\n\n\n4\nJBSS3.SA\n82.872584\n41.321213\n\n\n5\nMRFG3.SA\n121.350365\n47.075397\n\n\n6\nTSN\n10.791430\n22.756921"
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html#normaliza√ß√£o-e-pesos-fuzzy-topsis",
    "href": "fuzzy_topsis_analise_acoes.html#normaliza√ß√£o-e-pesos-fuzzy-topsis",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "Normaliza√ß√£o e Pesos (Fuzzy TOPSIS)",
    "text": "Normaliza√ß√£o e Pesos (Fuzzy TOPSIS)\n\n\nMostrar/Ocultar C√≥digo\ndf_normalized = df.copy()\n\nscaler_ret = MinMaxScaler()\ndf_normalized['Retorno Normalizado'] = scaler_ret.fit_transform(df[['Retorno Esperado (%)']])\n\nscaler_risk = MinMaxScaler()\ndf_normalized['Risco Normalizado'] = 1 - scaler_risk.fit_transform(df[['Risco (%)']])\n\npeso_retorno = 0.6\npeso_risco = 0.4\n\ndf_normalized['Retorno Ponderado'] = df_normalized['Retorno Normalizado'] * peso_retorno\ndf_normalized['Risco Ponderado'] = df_normalized['Risco Normalizado'] * peso_risco"
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html#c√°lculo-do-topsis",
    "href": "fuzzy_topsis_analise_acoes.html#c√°lculo-do-topsis",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "C√°lculo do TOPSIS",
    "text": "C√°lculo do TOPSIS\n\n\nMostrar/Ocultar C√≥digo\nideal_positivo = [\n    df_normalized['Retorno Ponderado'].max(),\n    df_normalized['Risco Ponderado'].max()\n]\n\nideal_negativo = [\n    df_normalized['Retorno Ponderado'].min(),\n    df_normalized['Risco Ponderado'].min()\n]\n\ndistancia_positiva = np.sqrt(\n    (df_normalized['Retorno Ponderado'] - ideal_positivo[0])**2 +\n    (df_normalized['Risco Ponderado'] - ideal_positivo[1])**2\n)\n\ndistancia_negativa = np.sqrt(\n    (df_normalized['Retorno Ponderado'] - ideal_negativo[0])**2 +\n    (df_normalized['Risco Ponderado'] - ideal_negativo[1])**2\n)\n\ndf_normalized['√çndice Similaridade'] = distancia_negativa / (distancia_positiva + distancia_negativa)\ndf_normalized['Rank'] = df_normalized['√çndice Similaridade'].rank(ascending=False)"
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html#resultado-final",
    "href": "fuzzy_topsis_analise_acoes.html#resultado-final",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "Resultado Final",
    "text": "Resultado Final\n\n\nMostrar/Ocultar C√≥digo\nresultado = df_normalized[['Ticker', 'Retorno Esperado (%)', 'Risco (%)', '√çndice Similaridade', 'Rank']].sort_values(by='Rank')\nresultado\n\n\n\n\n\n\n\n\n\nTicker\nRetorno Esperado (%)\nRisco (%)\n√çndice Similaridade\nRank\n\n\n\n\n5\nMRFG3.SA\n121.350365\n47.075397\n0.649640\n1.0\n\n\n4\nJBSS3.SA\n82.872584\n41.321213\n0.627660\n2.0\n\n\n6\nTSN\n10.791430\n22.756921\n0.522833\n3.0\n\n\n3\nHRL\n-1.237448\n21.940254\n0.492352\n4.0\n\n\n2\nGIS\n-44.667148\n24.262767\n0.381066\n5.0\n\n\n1\nBRFS3.SA\n-5.995730\n38.618763\n0.312154\n6.0\n\n\n0\nBEEF3.SA\n19.952812\n52.777333\n0.300945\n7.0"
  },
  {
    "objectID": "analise_acoes_gerado.html",
    "href": "analise_acoes_gerado.html",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "",
    "text": "Mostrar/Ocultar C√≥digo\n# Instalar as bibliotecas equivalentes no Python\n!pip install pandas numpy matplotlib seaborn scikit-learn yfinance statsmodels openpyxl prophet\n\n\nRequirement already satisfied: pandas in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (2.2.2)\nRequirement already satisfied: numpy in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (1.26.4)\nRequirement already satisfied: matplotlib in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (3.9.2)\nRequirement already satisfied: seaborn in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (0.13.2)\nRequirement already satisfied: scikit-learn in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (1.5.1)\nRequirement already satisfied: yfinance in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (0.2.63)\nRequirement already satisfied: statsmodels in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (0.14.2)\nRequirement already satisfied: openpyxl in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (3.1.5)\nRequirement already satisfied: prophet in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (1.1.7)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: packaging&gt;=20.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\nRequirement already satisfied: pillow&gt;=8 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: scipy&gt;=1.6.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib&gt;=1.2.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: requests&gt;=2.31 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (2.32.3)\nRequirement already satisfied: multitasking&gt;=0.0.7 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (0.0.11)\nRequirement already satisfied: platformdirs&gt;=2.0.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (3.10.0)\nRequirement already satisfied: frozendict&gt;=2.3.4 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (2.4.2)\nRequirement already satisfied: peewee&gt;=3.16.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (3.18.1)\nRequirement already satisfied: beautifulsoup4&gt;=4.11.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (4.12.3)\nRequirement already satisfied: curl_cffi&gt;=0.7 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (0.11.3)\nRequirement already satisfied: protobuf&gt;=3.19.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (4.25.3)\nRequirement already satisfied: websockets&gt;=13.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (15.0.1)\nRequirement already satisfied: patsy&gt;=0.5.6 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from statsmodels) (0.5.6)\nRequirement already satisfied: et-xmlfile in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\nRequirement already satisfied: cmdstanpy&gt;=1.0.4 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (1.2.5)\nRequirement already satisfied: holidays&lt;1,&gt;=0.25 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (0.74)\nRequirement already satisfied: tqdm&gt;=4.36.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (4.66.5)\nRequirement already satisfied: importlib_resources in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (6.5.2)\nRequirement already satisfied: soupsieve&gt;1.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from beautifulsoup4&gt;=4.11.1-&gt;yfinance) (2.5)\nRequirement already satisfied: stanio&lt;2.0.0,&gt;=0.4.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from cmdstanpy&gt;=1.0.4-&gt;prophet) (0.5.1)\nRequirement already satisfied: cffi&gt;=1.12.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from curl_cffi&gt;=0.7-&gt;yfinance) (1.17.1)\nRequirement already satisfied: certifi&gt;=2024.2.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from curl_cffi&gt;=0.7-&gt;yfinance) (2024.12.14)\nRequirement already satisfied: six in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from patsy&gt;=0.5.6-&gt;statsmodels) (1.16.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from requests&gt;=2.31-&gt;yfinance) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from requests&gt;=2.31-&gt;yfinance) (3.7)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from requests&gt;=2.31-&gt;yfinance) (2.2.3)\nRequirement already satisfied: colorama in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from tqdm&gt;=4.36.1-&gt;prophet) (0.4.6)\nRequirement already satisfied: pycparser in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from cffi&gt;=1.12.0-&gt;curl_cffi&gt;=0.7-&gt;yfinance) (2.21)"
  },
  {
    "objectID": "analise_acoes_gerado.html#bibliotecas",
    "href": "analise_acoes_gerado.html#bibliotecas",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "",
    "text": "Mostrar/Ocultar C√≥digo\n# Instalar as bibliotecas equivalentes no Python\n!pip install pandas numpy matplotlib seaborn scikit-learn yfinance statsmodels openpyxl prophet\n\n\nRequirement already satisfied: pandas in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (2.2.2)\nRequirement already satisfied: numpy in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (1.26.4)\nRequirement already satisfied: matplotlib in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (3.9.2)\nRequirement already satisfied: seaborn in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (0.13.2)\nRequirement already satisfied: scikit-learn in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (1.5.1)\nRequirement already satisfied: yfinance in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (0.2.63)\nRequirement already satisfied: statsmodels in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (0.14.2)\nRequirement already satisfied: openpyxl in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (3.1.5)\nRequirement already satisfied: prophet in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (1.1.7)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: packaging&gt;=20.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\nRequirement already satisfied: pillow&gt;=8 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: scipy&gt;=1.6.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib&gt;=1.2.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: requests&gt;=2.31 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (2.32.3)\nRequirement already satisfied: multitasking&gt;=0.0.7 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (0.0.11)\nRequirement already satisfied: platformdirs&gt;=2.0.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (3.10.0)\nRequirement already satisfied: frozendict&gt;=2.3.4 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (2.4.2)\nRequirement already satisfied: peewee&gt;=3.16.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (3.18.1)\nRequirement already satisfied: beautifulsoup4&gt;=4.11.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (4.12.3)\nRequirement already satisfied: curl_cffi&gt;=0.7 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (0.11.3)\nRequirement already satisfied: protobuf&gt;=3.19.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (4.25.3)\nRequirement already satisfied: websockets&gt;=13.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (15.0.1)\nRequirement already satisfied: patsy&gt;=0.5.6 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from statsmodels) (0.5.6)\nRequirement already satisfied: et-xmlfile in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\nRequirement already satisfied: cmdstanpy&gt;=1.0.4 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (1.2.5)\nRequirement already satisfied: holidays&lt;1,&gt;=0.25 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (0.74)\nRequirement already satisfied: tqdm&gt;=4.36.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (4.66.5)\nRequirement already satisfied: importlib_resources in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (6.5.2)\nRequirement already satisfied: soupsieve&gt;1.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from beautifulsoup4&gt;=4.11.1-&gt;yfinance) (2.5)\nRequirement already satisfied: stanio&lt;2.0.0,&gt;=0.4.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from cmdstanpy&gt;=1.0.4-&gt;prophet) (0.5.1)\nRequirement already satisfied: cffi&gt;=1.12.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from curl_cffi&gt;=0.7-&gt;yfinance) (1.17.1)\nRequirement already satisfied: certifi&gt;=2024.2.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from curl_cffi&gt;=0.7-&gt;yfinance) (2024.12.14)\nRequirement already satisfied: six in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from patsy&gt;=0.5.6-&gt;statsmodels) (1.16.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from requests&gt;=2.31-&gt;yfinance) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from requests&gt;=2.31-&gt;yfinance) (3.7)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from requests&gt;=2.31-&gt;yfinance) (2.2.3)\nRequirement already satisfied: colorama in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from tqdm&gt;=4.36.1-&gt;prophet) (0.4.6)\nRequirement already satisfied: pycparser in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from cffi&gt;=1.12.0-&gt;curl_cffi&gt;=0.7-&gt;yfinance) (2.21)"
  },
  {
    "objectID": "analise_acoes_gerado.html#download-dos-dados",
    "href": "analise_acoes_gerado.html#download-dos-dados",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "Download dos Dados",
    "text": "Download dos Dados\n\n\nMostrar/Ocultar C√≥digo\n# Importar as bibliotecas equivalentes no Python\nimport pandas as pd           # Manipula√ß√£o de dados\nimport numpy as np            # Opera√ß√µes matem√°ticas\nimport matplotlib.pyplot as plt  # Gr√°ficos\nimport seaborn as sns         # Gr√°ficos\nimport yfinance as yf         # Dados de a√ß√µes\nfrom statsmodels.tsa.api import ExponentialSmoothing, ARIMA # Modelos de s√©ries temporais\nimport statsmodels.api as sm  # Modelagem estat√≠stica geral\nfrom prophet import Prophet   # Previs√£o de s√©ries temporais\nimport datetime               # Manipula√ß√£o de datas\nimport openpyxl               # Leitura e escrita de arquivos Excel"
  },
  {
    "objectID": "analise_acoes_gerado.html#prepara√ß√£o-dos-dados",
    "href": "analise_acoes_gerado.html#prepara√ß√£o-dos-dados",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "Prepara√ß√£o dos Dados",
    "text": "Prepara√ß√£o dos Dados\n\n\nMostrar/Ocultar C√≥digo\nimport pandas as pd\nfrom openpyxl import Workbook\nfrom openpyxl.utils.dataframe import dataframe_to_rows\nfrom openpyxl.styles import numbers\n\n# 8) Exporta Excel com uma aba por cen√°rio\nwb = Workbook()\nwb.remove(wb.active)  # Remove aba padr√£o\n\nfor sc in ret_all['.rep'].unique():\n    df = ret_all[ret_all['.rep'] == sc].copy()\n\n    # Pivotar como no R\n    df = df[['date', 'asset', 'ret', 'vol']]\n    df_long = df.melt(id_vars=['date', 'asset'], var_name='metric', value_name='value')\n    df_long['col'] = df_long['metric'] + '_' + df_long['asset']\n    df_wide = df_long.pivot_table(index='date', columns='col', values='value').reset_index()\n    df_wide = df_wide.sort_values('date')\n\n    # Criar aba e adicionar dados\n    ws = wb.create_sheet(title=sc)\n    for r in dataframe_to_rows(df_wide, index=False, header=True):\n        ws.append(r)\n\n    # Formatar colunas num√©ricas\n    for col in ws.iter_cols(min_row=2, min_col=2):\n        for cell in col:\n            cell.number_format = '#,##0.00'\n\n# Salvar o arquivo\nwb.save(\"retornos_e_volatilidades.xlsx\")"
  },
  {
    "objectID": "analise_acoes_gerado.html#c√°lculo-de-retornos",
    "href": "analise_acoes_gerado.html#c√°lculo-de-retornos",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "C√°lculo de Retornos",
    "text": "C√°lculo de Retornos\n\n\nMostrar/Ocultar C√≥digo\n# Instala depend√™ncias\n!pip install -q PyPortfolioOpt pandas numpy openpyxl plotly scipy\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import dirichlet\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\n# 1) Par√¢metros Monte Carlo\nN_PORTFOLIOS = 50_000\nRISK_FREE    = 0.0\n\n# 2) Carrega Excel e cen√°rios\nxls    = pd.ExcelFile(\"retornos_e_volatilidades.xlsx\")\nsheets = xls.sheet_names  # [\"hist\",\"sim1\",\"sim2\",\"sim3\"]\n\n# 3) Prepara figura Plotly 2√ó2\nfig = make_subplots(\n    rows=2, cols=2,\n    subplot_titles=[f\"Cen√°rio {sc}\" for sc in sheets],\n    horizontal_spacing=0.1, vertical_spacing=0.15\n)\n\n# 4) Loop: simula√ß√µes, frontier e MaxSharpe\nfor idx, sc in enumerate(sheets):\n    # c√°lculo de linha/col\n    row = idx//2 + 1\n    col = idx%2 + 1\n\n    # 4.1) Retornos do cen√°rio\n    df   = pd.read_excel(xls, sheet_name=sc, index_col=0, parse_dates=True)\n    rets = (\n        df.filter(regex=\"^ret_\")\n          .rename(columns=lambda c:c.replace(\"ret_\",\"\"))\n          .replace([np.inf,-np.inf], np.nan)\n          .dropna(axis=1, how=\"any\")\n    )\n    tickers = rets.columns.tolist()\n    mu  = rets.mean()\n    cov = rets.cov()\n\n    # 4.2) Simula carteiras\n    W = np.random.dirichlet(np.ones(len(tickers)), size=N_PORTFOLIOS)\n    port_rets  = W.dot(mu.values)\n    port_vars  = np.einsum('ij,jk,ik-&gt;i', W, cov.values, W)\n    port_risks = np.sqrt(port_vars)\n\n    # 4.3) Max Sharpe\n    sharpe = (port_rets - RISK_FREE) / port_risks\n    idx_sh  = np.nanargmax(sharpe)\n    opt_ret  = port_rets[idx_sh]\n    opt_risk = port_risks[idx_sh]\n\n    # 4.4) Fronteira eficiente emp√≠rica\n    df_mc   = pd.DataFrame({\"risk\":port_risks, \"ret\":port_rets})\n    df_mc   = df_mc.sort_values(\"ret\")\n    frontier = []\n    min_r = np.inf\n    for r, q in zip(df_mc[\"risk\"], df_mc[\"ret\"]):\n        if r &lt; min_r:\n            frontier.append((r,q))\n            min_r = r\n    frontier = np.array(frontier)\n\n    # 4.5) Adiciona traces a cada subplot\n    fig.add_trace(\n        go.Scatter(\n            x=df_mc[\"risk\"], y=df_mc[\"ret\"],\n            mode=\"markers\",\n            marker=dict(size=2, opacity=0.15, color=\"gray\"),\n            name=\"Simula√ß√µes\",\n            showlegend=(idx==0)\n        ),\n        row, col\n    )\n    fig.add_trace(\n        go.Scatter(\n            x=frontier[:,0], y=frontier[:,1],\n            mode=\"lines\",\n            line=dict(color=\"red\", width=2),\n            name=\"Fronteira\",\n            showlegend=(idx==0)\n        ),\n        row, col\n    )\n    fig.add_trace(\n        go.Scatter(\n            x=[opt_risk], y=[opt_ret],\n            mode=\"markers\",\n            marker=dict(symbol=\"star\", size=14, color=\"gold\"),\n            name=\"M√°x Sharpe\",\n            showlegend=(idx==0)\n        ),\n        row, col\n    )\n\n    # 4.6) Ajusta eixos\n    fig.update_xaxes(title_text=\"Risco œÉ\", row=row, col=col)\n    fig.update_yaxes(title_text=\"Retorno Exp.\", row=row, col=col)\n\n# 5) Layout geral\nfig.update_layout(\n    height=800, width=900,\n    title_text=\"Fronteiras Eficientes (Monte Carlo) e M√°x Sharpe por Cen√°rio\",\n    legend=dict(x=0.85, y=0.05)\n)\n\n# 6) Exibe\nfig.show()"
  },
  {
    "objectID": "analise_acoes_gerado.html#normaliza√ß√£o-e-pesos-fuzzy-topsis",
    "href": "analise_acoes_gerado.html#normaliza√ß√£o-e-pesos-fuzzy-topsis",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "Normaliza√ß√£o e Pesos (Fuzzy TOPSIS)",
    "text": "Normaliza√ß√£o e Pesos (Fuzzy TOPSIS)\n\n\nMostrar/Ocultar C√≥digo\n# 1) Instala depend√™ncias\n!pip install -q scipy pandas numpy openpyxl matplotlib\n\n# 2) Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import differential_evolution\n\n# 3) Carrega os retornos simulados do cen√°rio \"sim1\"\nxls = pd.ExcelFile(\"retornos_e_volatilidades.xlsx\")\ndf  = pd.read_excel(xls, sheet_name=\"sim1\", index_col=0, parse_dates=True)\n\n# 4) Extrai apenas as colunas de retorno\nrets = (df\n        .filter(regex=\"^ret_\")\n        .rename(columns=lambda c: c.replace(\"ret_\",\"\"))\n        .replace([np.inf, -np.inf], np.nan)\n        .dropna(axis=1, how=\"any\"))\n\ntickers = rets.columns.tolist()\nn = len(tickers)\n\n# 5) Estat√≠sticas de Markowitz\nmu    = rets.mean().values        # retornos m√©dios di√°rios\nSigma = rets.cov().values         # covari√¢ncia di√°ria\n\n# 6) Par√¢metros de aloca√ß√£o m√≠nima\nmin_w = 0.05                      # cada ativo tem no m√≠nimo 5%\nscale = 1 - n * min_w             # parte restante para distribuir\n\ngamma = 1.0                       # trade-off risco vs retorno\n\n# 7) Fun√ß√£o‚Äêobjetivo (risk - Œ≥¬∑return)\ndef markowitz_obj(x):\n    # x em [0,1]^n  ‚Üí  w_i ‚â• min_w, soma(w)=1\n    raw = np.abs(x)\n    if raw.sum() == 0:\n        raw = np.ones_like(raw)\n    w = min_w + scale * raw / raw.sum()\n    ret  = mu.dot(w)\n    risk = np.sqrt(w @ Sigma @ w)\n    return risk - gamma * ret\n\n# 8) Bounds para DE em [0,1]\nbounds = [(0,1)] * n\n\n# 9) Executa Differential Evolution\nres = differential_evolution(\n    markowitz_obj,\n    bounds,\n    strategy     = 'best1bin',\n    popsize      = 15,\n    mutation     = (0.5, 1),\n    recombination= 0.7,\n    tol          = 1e-6,\n    maxiter      = 1000,\n    polish       = True,\n    seed         = 42\n)\n\n# 10) Transforma o vetor X em pesos w\nx_opt = np.abs(res.x)\nw_opt = min_w + scale * x_opt / x_opt.sum()\n\n# 11) Calcula m√©tricas finais\nport_ret   = mu.dot(w_opt)\nport_risk  = np.sqrt(w_opt @ Sigma @ w_opt)\nsharpe     = port_ret / port_risk\n\n# 12) Exibe resultados\nprint(f\"\\n=== Aloca√ß√£o √ìtima (Markowitz via DE) ‚Äî cen√°rio sim1 ===\\n\")\nfor tkr, w in zip(tickers, w_opt):\n    print(f\"  {tkr:10s}: {w*100:6.2f}%\")\nprint(f\"\\nRetorno Esperado Di√°rio: {port_ret:.4f}\")\nprint(f\"Risco (œÉ di√°rio)       : {port_risk:.4f}\")\nprint(f\"Sharpe Ratio (Rf=0)    : {sharpe:.4f}\")\n\nimport plotly.express as px\n\n# 1) Monte um DataFrame de pesos\ndf_w = pd.DataFrame({\n    \"Ativo\": tickers,\n    \"Peso\": w_opt\n})\n\n# 2) Gera o gr√°fico de barras interativo\nfig = px.bar(\n    df_w,\n    x=\"Ativo\",\n    y=\"Peso\",\n    title=\"Aloca√ß√£o √ìtima de Ativos ‚Äî sim1\",\n    text=df_w[\"Peso\"].apply(lambda x: f\"{x*100:.2f}%\")\n)\n\n# 3) Ajustes finos\nfig.update_traces(\n    marker_color=\"green\",\n    textposition=\"outside\"\n)\nfig.update_layout(\n    yaxis=dict(title=\"Peso (%)\", tickformat=\".1%\"),\n    xaxis_tickangle=-45,\n    uniformtext_minsize=8,\n    uniformtext_mode=\"hide\"\n)\n\n# 4) Exibe\nfig.show()\n\n\n\n=== Aloca√ß√£o √ìtima (Markowitz via DE) ‚Äî cen√°rio sim1 ===\n\n  BEEF3.SA  :   5.00%\n  BRFS3.SA  :   5.00%\n  GIS       :  30.45%\n  HRL       :  33.92%\n  JBSS3.SA  :   9.47%\n  MRFG3.SA  :  11.15%\n  TSN       :   5.00%\n\nRetorno Esperado Di√°rio: 0.0010\nRisco (œÉ di√°rio)       : 0.0072\nSharpe Ratio (Rf=0)    : 0.1384"
  },
  {
    "objectID": "analise_acoes_gerado.html#c√°lculo-do-topsis",
    "href": "analise_acoes_gerado.html#c√°lculo-do-topsis",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "C√°lculo do TOPSIS",
    "text": "C√°lculo do TOPSIS\n\n\nMostrar/Ocultar C√≥digo\n# 1) Imports (supondo que j√° tenha numpy, pandas, plotly instalados)\n\nimport numpy as np\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\n# 2) Carrega retornos simulados do cen√°rio \"sim1\"\nxls    = pd.ExcelFile(\"retornos_e_volatilidades.xlsx\")\ndf     = pd.read_excel(xls, sheet_name=\"sim1\", index_col=0, parse_dates=True)\nrets   = (df\n           .filter(regex=\"^ret_\")\n           .rename(columns=lambda c: c.replace(\"ret_\",\"\"))\n           .replace([np.inf,-np.inf], np.nan)\n           .dropna(axis=1, how=\"any\"))\n\n# 3) Vetor de pesos 'w_opt' j√° calculado anteriormente\n#    Exemplo: w_opt = np.array([...]) na mesma ordem de rets.columns\nweights = pd.Series(w_opt, index=rets.columns)\n\n# 4) S√©rie de retornos da carteira\nport_ret = rets.dot(weights)\n\n# 5) Performance cumulativa (√≠ndice de riqueza)\n#    W‚ÇÄ = 1, W_t = ‚àè_{i=1}^t (1 + r_i)\nwealth = (1 + port_ret).cumprod()\n\n# 6) Drawdown\n#    DD_t = (W_t - max_{s‚â§t} W_s) / max_{s‚â§t} W_s\nrunning_max = wealth.cummax()\ndrawdown    = (wealth - running_max) / running_max\nmax_dd      = drawdown.min()\n\n# 7) Monta gr√°fico interativo com Plotly\nfig = make_subplots(\n    rows=2, cols=1, shared_xaxes=True,\n    row_heights=[0.6, 0.4],\n    subplot_titles=[\n        \"Performance Cumulativa da Carteira √ìtima (sim1)\",\n        f\"Drawdown Di√°rio (M√°x: {max_dd:.2%})\"\n    ]\n)\n\n# 7.1) Wealth index\nfig.add_trace(\n    go.Scatter(\n        x=wealth.index, y=wealth.values,\n        mode=\"lines\", name=\"Wealth Index\"\n    ),\n    row=1, col=1\n)\n\n# 7.2) Drawdown\nfig.add_trace(\n    go.Scatter(\n        x=drawdown.index, y=drawdown.values,\n        mode=\"lines\", name=\"Drawdown\",\n        fill='tozeroy', line=dict(color='crimson')\n    ),\n    row=2, col=1\n)\n\n# 8) Layout\nfig.update_yaxes(title_text=\"√çndice de Riqueza\", row=1, col=1)\nfig.update_yaxes(title_text=\"Drawdown\", row=2, col=1, tickformat=\".0%\")\nfig.update_xaxes(title_text=\"Data\", row=2, col=1)\n\nfig.update_layout(\n    height=600, width=800,\n    showlegend=False,\n    title_text=\"Performance e Drawdown da Carteira √ìtima ‚Äî sim1\"\n)\n\nfig.show()"
  },
  {
    "objectID": "analise_acoes_gerado.html#resultado-final",
    "href": "analise_acoes_gerado.html#resultado-final",
    "title": "Fuzzy TOPSIS - An√°lise de A√ß√µes",
    "section": "Resultado Final",
    "text": "Resultado Final"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre N√≥s",
    "section": "",
    "text": "Daniel K Junior\nArthur Lauffer\nDavi Kemper\nJo√£o Niquele"
  },
  {
    "objectID": "about.html#sum√°rio",
    "href": "about.html#sum√°rio",
    "title": "Sobre N√≥s",
    "section": "",
    "text": "Daniel K Junior\nArthur Lauffer\nDavi Kemper\nJo√£o Niquele"
  },
  {
    "objectID": "about.html#arthur-lauffer",
    "href": "about.html#arthur-lauffer",
    "title": "Sobre N√≥s",
    "section": "Arthur Lauffer",
    "text": "Arthur Lauffer\n\nCargo: √â analista de BI e estudante de Ci√™ncia de Dados para Neg√≥cios na FAE Business School. Ele administra sua pr√≥pria empresa de BI, prestando servi√ßos para outras empresas, e tamb√©m gerencia uma empresa de SaaS focada em projetos de longo prazo. Com grande experi√™ncia em Power BI, ele desenvolve dashboards e modelos de dados para diversas √°reas, incluindo vendas, RH e faturamento. Al√©m disso, atua como administrador do Workspace do Google da sua empresa. No tempo livre, tem interesse em m√∫sica eletr√¥nica e est√° organizando a¬†festa¬†Synapse. üîó Portfolio"
  },
  {
    "objectID": "about.html#davi-kemper",
    "href": "about.html#davi-kemper",
    "title": "Sobre N√≥s",
    "section": "Daniel K Junior",
    "text": "Daniel K Junior\n\nCargo: Formado na Escola de Sargento das Armas no ano de 2021, decidiu fazer a transi√ß√£o de carreira para a √°rea de Dados j√° no √≠nicio da faculdade, concluindo a transi√ß√£o no final do ano de 2024, hoje atua como Analista de BI na EZ Chart.\nüîó Portfolio"
  },
  {
    "objectID": "about.html#davi-kemper-1",
    "href": "about.html#davi-kemper-1",
    "title": "Sobre N√≥s",
    "section": "Davi Kemper",
    "text": "Davi Kemper\n\nCargo: Estudante de Ci√™ncia de Dados na FAE, atuou como Analista de BI do grupo Metronorte. üîó Portfolio"
  },
  {
    "objectID": "about.html#jo√£o-niquele",
    "href": "about.html#jo√£o-niquele",
    "title": "Sobre N√≥s",
    "section": "Jo√£o Niquele",
    "text": "Jo√£o Niquele\n\nCargo: Estudante de Ci√™ncia de Dados na FAE üîó Portfolio"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Projeto Finan√ßas",
    "section": "",
    "text": "Usaremos seguintes a√ß√µes da bolsa :\n\nBRFS3: A BRF √© uma empresa transnacional brasileira do ramo aliment√≠cio, fruto da fus√£o entre Sadia e Perdig√£o, duas das principais empresas de alimentos do Brasil.\nJBSS3: JBS √© uma empresa brasileira do setor de alimentos fundada em 1953 em Goi√°s. A companhia opera no processamento de carnes bovina, su√≠na, ovina, de frango, de peixe e plant-based, al√©m de atuar no processamento de couros\nBEEF3: Minerva Foods √© uma empresa brasileira de alimentos fundada em 1924 na cidade de Barretos. A companhia tem atua√ß√£o na comercializa√ß√£o de carne in natura, couros, derivados, e na exporta√ß√£o de gado vivo, al√©m de atuar no processamento de carnes.\nMRFG3: Marfrig Global Foods √© uma empresa brasileira de alimentos. Fundada no ano 2000, √© a segunda maior produtora de carne bovina do mundo e l√≠der na produ√ß√£o de hamb√∫rgueres.\nTSN: A Tyson Foods √© uma empresa multinacional americana fundada por John W. Tyson em 1931 e sediada em Springdale, Arkansas, que opera na ind√∫stria aliment√≠cia.\nHRL: A Hormel Foods Corporation √© uma empresa aliment√≠cia estadunidense com sede em Austin, Minnesota, conhecida pela fabrica√ß√£o do Spam. Em 24 de agosto de 2017, a empresa anunciou a compra da empresa brasileira Ceratti.\nGIS: General Mills √© uma multinacional americana produtora de alimentos classificada na Fortune 500 e uma das 10 maiores empresas de alimentos do mundo. √â sediada em Golden Valley, Minnesota, Minneapolis.\n\nUtilizamos a API Yahoo! Finance para conseguir os dados utilizados para as analises a seguir.\nAnalisando os dados em uma tabela:\n\n\nCode\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(timeSeries)\nlibrary(fPortfolio)\nlibrary(quantmod)\nlibrary(cowplot) \nlibrary(lattice)\nlibrary(timetk)\nlibrary(quantmod)\nlibrary(DT) \n\n\nTICKERS &lt;- c(\n  \"BRFS3.SA\",\n  \"JBSS3.SA\",\n  \"BEEF3.SA\",\n  \"MRFG3.SA\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n)\n\n\n\n\n\nportfolioPrices &lt;- NULL\nfor ( Ticker in TICKERS )\n  portfolioPrices &lt;- cbind(\n    portfolioPrices, \n    getSymbols(\n      Ticker,\n      src = \"yahoo\",\n      from = \"2019-01-01\",\n      auto.assign = FALSE\n    )[,4]\n  )\n\nportfolioPrices &lt;- portfolioPrices[apply(portfolioPrices, 1, function(x) all(!is.na(x))),]\n\ncolnames(portfolioPrices) &lt;- c(\n  \"BRFS3\",\n  \"JBSS3\",\n  \"BEEF3\",\n  \"MRFG3\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n)\n\n\n\n\nCode\n# Visualizar com DT\ndatatable(tail(portfolioPrices), options = list(pageLength = 10, scrollX = TRUE)) \n\n\n\n\n\n\nE ent√£o a gente faz uma analise temporal dos dados, tendo o eixo X sendo a vari√°vel tempo, e o eixo Y sendo o pre√ßo:\n\n\nCode\nportfolioPrices |&gt; as.data.frame() |&gt;\n  mutate(\n    time = seq_along(GIS)\n  ) |&gt;\n  pivot_longer(\n    !time,\n    names_to = \"Variables\",\n    values_to = \"Value\"  \n  ) |&gt;\n  group_by(Variables) |&gt;\n  plot_time_series(\n    time,\n    Value,\n    .interactive = F, # Change for TRUE for better visualization\n    .facet_ncol = 2,\n    .smooth = FALSE\n  ) +\n  theme(\n    strip.background = element_rect(fill = \"white\", colour = \"white\")\n  )"
  },
  {
    "objectID": "page3.html",
    "href": "page3.html",
    "title": "Ci√™ncia de Dados para Neg√≥cios: Big Data for Finance Project",
    "section": "",
    "text": "Resumo\n\n\n\n\nteste de futuro para as a√ß√µes\n\n\n\n\nIntro\nescrever\n\nR\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(modeltime)\nlibrary(timetk)\nlibrary(purrr)\nlibrary(tidyquant)\nlibrary(tsibble)\nlibrary(prophet)\nlibrary(feasts)\nlibrary(fable)\nlibrary(fabletools)\nlibrary(lubridate)\nlibrary(tictoc)\n\n\nCarregamos os dados:\n\n\nCode\ntickers &lt;- c(\n         \"BRFS3.SA\",\n  \"JBSS3.SA\",\n  \"BEEF3.SA\",\n  \"MRFG3.SA\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n)\n\n\nEnt√£o baixo os dados via Yahoo!Finance:\n\n\nCode\nportfolioPrices &lt;- NULL\n  for ( Ticker in tickers )\n    portfolioPrices &lt;- cbind(\n      portfolioPrices, \n      quantmod::getSymbols.yahoo(\n        Ticker,\n        from = \"2019-01-01\",\n        auto.assign = FALSE\n      )[,4]\n    )\n\nportfolioPrices &lt;- portfolioPrices[apply(portfolioPrices, 1, function(x) all(!is.na(x))),]\n\ncolnames(portfolioPrices) &lt;- c(\n  \"BRFS3.SA\",\n  \"JBSS3.SA\",\n  \"BEEF3.SA\",\n  \"MRFG3.SA\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n)\n\n# Visualizar com DT\n#DT::datatable(tail(portfolioPrices), options = list(pageLength = 10, scrollX = TRUE)) \n\n\nVisualizando os dados dos nossos √∫ltimos retornos dos pre√ßos, temos:\n\n\nCode\nlog_returns &lt;- log(portfolioPrices) - log(lag(portfolioPrices))\nlog_returns &lt;- na.omit(log_returns)\nlog_returns &lt;- log_returns |&gt; \n  timetk::tk_tbl(preserve_index = TRUE, rename_index = \"date\")\n\ntail(log_returns)\n\n\n\n  \n\n\n\n\n\nCode\nln_returns &lt;- log_returns\n\nln_returns |&gt; as.data.frame() |&gt;\n  dplyr::mutate(\n    time = seq_along( TSN )\n  ) |&gt; select(-date) |&gt;\n  tidyr::pivot_longer(\n    !time,\n    names_to = \"Variables\",\n    values_to = \"Value\"  \n      ) |&gt;\n  dplyr::group_by(Variables) |&gt;\n  timetk::plot_time_series(\n    time,\n    Value,\n    .interactive = F, # Change for TRUE for better visualization\n    .facet_ncol = 2,\n    .smooth = FALSE\n  ) +\n  ggplot2::theme(\n    strip.background = ggplot2::element_rect(fill = \"white\", colour = \"white\")\n  )\n\n\n\n\n\n\n\n\n\n\nModelagem com fpp3 e valida√ß√£o cruzada temporal\nPrecisaremos fazer um forecasting de curto prazo com nossos dados hist√≥ricos de retornos pra formularmos nossas recomenda√ß√µes posteriores de compra, venda e espera:\n\nVamos come√ßar com uma s√©rie por vez \\(\\Rightarrow\\) TSN\n\n\n\nCode\n# Primeiro converto pra tsibble\n\nlnretTSN &lt;- log_returns |&gt; \n  select(date, TSN) |&gt; \n  as_tsibble(index = date)\n\nglimpse(lnretTSN)\n\n\nRows: 1,560\nColumns: 2\n$ date &lt;date&gt; 2019-01-03, 2019-01-04, 2019-01-07, 2019-01-08, 2019-01-09, 2019‚Ä¶\n$ TSN  &lt;dbl&gt; 0.0211432803, 0.0122208208, 0.0160060857, 0.0264099860, -0.017528‚Ä¶\n\n\n\n\nCode\ntreino &lt;- lnretTSN |&gt;\n  filter_index(~\"2025-01-01\")\n\n\nWar models\n\n\nCode\ntic()\n\nModelos &lt;- treino |&gt;\n  model(\n    AjusteExp = ETS(TSN ~ error(\"A\") + trend(\"N\") + season(\"N\")), # Ajuste Exponencial com auto\n    \n    AjExp_aditivo = ETS(TSN ~ error(\"A\") + trend(\"A\") + season(\"A\")), # Ajuste Exponencial Aditivo\n    \n    AjExp_multiplicativo = ETS(TSN ~ error(\"M\") + trend(\"A\") + season(\"M\")), # Ajuste Exponencial Multiplicativo\n    \n    Croston = CROSTON(TSN), # Modelo Croston\n    \n    HoltWinters = ETS(TSN ~ error(\"M\") + trend(\"Ad\") + season(\"M\")), # Holt Winters\n    \n    Holt = ETS(TSN ~ error(\"A\") + trend(\"A\") + season(\"N\")), # Holt\n    \n    HoltAmort = ETS(TSN ~ error(\"A\") + trend(\"Ad\", phi = 0.9) + season(\"N\")), # Holt Amortecida\n    \n    Regr_Comp = TSLM(TSN ~ trend() + season()), # Regressao com tendencia e sazonalidade auto\n    \n    Regr_Harmonica = TSLM(TSN ~ trend() + fourier(K = 2)), # Regressao harmonica\n    \n    Regr_Quebras = TSLM(TSN ~ trend(knots = c(2018, 2019, 2020))), # Regressao com quebras estruturais\n    \n    Snaive = SNAIVE(TSN), # SNAIVE\n    \n    Naive = NAIVE(TSN), #NAIVE\n    \n    Media_Movel = ARIMA(TSN ~ pdq(0,0,1)), # Media Movel Simples\n    \n    autoARIMA = ARIMA(TSN, stepwise = FALSE, approx = FALSE), # Auto ARIMA\n    \n    autoARIMA_saz = ARIMA(TSN, stepwise = FALSE, approx = FALSE, seasonal = TRUE), # AutoARIMA Sazonal\n    \n    #    Regr_erros_ARIMA = auto.arima(TSN, xreg = fourier(K = 3), seasonal = FALSE), # Regressao com erros ARIMA\n    \n    ARIMA_saz_012011 = ARIMA(TSN ~ pdq(0,1,2) + PDQ(0,1,1)), # ARIMA Sazonal ordem 012011\n    \n    ARIMA_saz_210011 = ARIMA(TSN ~ pdq(2,1,0) + PDQ(0,1,1)), # ARIMA Sazonal ordem 210011\n    \n    ARIMA_saz_0301012 = ARIMA(TSN ~ 0 + pdq(3,0,1) + PDQ(0,1,2)), # ARIMA sazonal\n    \n    ARIMA_quad = ARIMA(TSN ~ I(trend()^2)), # ARIMA com tendencia temporal quadratica\n    \n    ARIMA_determ = ARIMA(TSN ~ 1 + trend() + pdq(d = 0)), # ARIMA com tendencia deterministica\n    \n    ARIMA_estocastico = ARIMA(TSN ~ pdq(d = 1)), # ARIMA com tend√™ncia estocastica\n    \n    Regr_Harm_dinamica = ARIMA(TSN ~ fourier(K=2) + PDQ(0,0,0)), # Regressao Harmonica Dinamica\n    \n    Regr_Harm_Din_MultSaz = ARIMA(TSN ~ PDQ(0, 0, 0) + pdq(d = 0) + fourier(period = 7*30, K = 10) + fourier(period = 7*30, K = 5)), \n    \n    Regr_Harm_Din_Saz = ARIMA(TSN ~ PDQ(0, 0, 0) + pdq(d = 0) + fourier(period = \"month\", K = 10) +\n                                fourier(period = \"year\", K = 2) ), # Rgr Harm Mult Saz Complexa\n    \n#    Auto_Prophet = prophet(TSN), # Auto prophet\n    \n#    Prophet_mult = prophet(TSN ~ season(period = \"month\", order = 2, type = \"multiplicative\")),\n    \n#    Prophet_aditivo = prophet(TSN ~ season(period = \"month\", order = 2, type = \"additive\")),\n    \n#    Prophet_geom = prophet(TSN ~ growth(\"geometric\") + season(period = \"month\", order = 2, type = \"multiplicative\")),\n    \n#    Prophet_memo = prophet(TSN ~ growth(\"geometric\") + season(period = \"month\", order = 5) +\n#                             season(period = \"year\", order = 2, type = \"multiplicative\")),\n    \n    Modelo_VAR = VAR(TSN, ic = \"bic\"), # Vetor Autoregressivo \n    \n    Random_Walk = RW(TSN ~ drift()), # Random Walk com drift\n    \n    Rede_Neural_AR = NNETAR(TSN, bootstrap =  TRUE)#, # Rede Neural com auto AR e bootstraping nos erros\n    \n    #    x11 = X_13ARIMA_SEATS(TSN ~ x11()) # X11 ARIMA Seats\n    \n  ) |&gt;\n  \n  forecast(h = \"24 months\") # Horizonte de projecao para os proximos 30 dias apos corte no treino\n\ntoc()  \n\n\n1.47 sec elapsed\n\n\nSelecionamos o melhor modelo (1 fold de valida√ß√£o cruzada somente):\n\n\nCode\nModelos |&gt;\n  accuracy(lnretTSN) |&gt;\n  arrange(RMSE) # Sele√ß√£o da acuracia pelo menor RMSE para o conjunto de modelos\n\n\n\n  \n\n\n\nGero um cen√°rio com o modelo:\n\n\nCode\nfit &lt;- lnretTSN |&gt;\n  model(\n    Regr_Quebras = TSLM(TSN ~ trend(knots = c(2018, 2019, 2020))), # Regressao com quebras estruturais\n  )\n\nsim &lt;- fit |&gt; generate(h = 30, times = 5, bootstrap = TRUE)\n\n\nPlotamos os forecasts com esse modelo pra tr√™s cen√°rios distintos no futuro:\n\n\nCode\nlnretTSN |&gt;\n  filter_index(\"2025-01-01\"~.) |&gt;\n  ggplot(aes(x = date)) +\n  geom_line(aes(y = TSN)) +\n  geom_line(aes(y = .sim, colour = as.factor(.rep)),\n    data = sim) +\n  labs(title=\"Valores projetados de retornos de pre√ßos de contratos futuros da TSN\", y=\"$US\" ) +\n  guides(colour = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Primeiro converto pra tsibble\n\nlnretGIS &lt;- log_returns |&gt; \n  select(date, GIS) |&gt; \n  as_tsibble(index = date)\n\nglimpse(lnretGIS)\n\n\nRows: 1,560\nColumns: 2\n$ date &lt;date&gt; 2019-01-03, 2019-01-04, 2019-01-07, 2019-01-08, 2019-01-09, 2019‚Ä¶\n$ GIS  &lt;dbl&gt; 0.0154921374, 0.0200387411, 0.0164387227, 0.0149567729, -0.016440‚Ä¶\n\n\n\n\nCode\ntreino &lt;- lnretGIS |&gt;\n  filter_index(~\"2025-01-01\")\n\n\n\n\nCode\ntic()\n\nModelos &lt;- treino |&gt;\n  model(\n    AjusteExp = ETS(GIS ~ error(\"A\") + trend(\"N\") + season(\"N\")), # Ajuste Exponencial com auto\n    \n    AjExp_aditivo = ETS(GIS ~ error(\"A\") + trend(\"A\") + season(\"A\")), # Ajuste Exponencial Aditivo\n    \n    AjExp_multiplicativo = ETS(GIS ~ error(\"M\") + trend(\"A\") + season(\"M\")), # Ajuste Exponencial Multiplicativo\n    \n    Croston = CROSTON(GIS), # Modelo Croston\n    \n    HoltWinters = ETS(GIS ~ error(\"M\") + trend(\"Ad\") + season(\"M\")), # Holt Winters\n    \n    Holt = ETS(GIS ~ error(\"A\") + trend(\"A\") + season(\"N\")), # Holt\n    \n    HoltAmort = ETS(GIS ~ error(\"A\") + trend(\"Ad\", phi = 0.9) + season(\"N\")), # Holt Amortecida\n    \n    Regr_Comp = TSLM(GIS ~ trend() + season()), # Regressao com tendencia e sazonalidade auto\n    \n    Regr_Harmonica = TSLM(GIS ~ trend() + fourier(K = 2)), # Regressao harmonica\n    \n    Regr_Quebras = TSLM(GIS ~ trend(knots = c(2018, 2019, 2020))), # Regressao com quebras estruturais\n    \n    Snaive = SNAIVE(GIS), # SNAIVE\n    \n    Naive = NAIVE(GIS), #NAIVE\n    \n    Media_Movel = ARIMA(GIS ~ pdq(0,0,1)), # Media Movel Simples\n    \n    autoARIMA = ARIMA(GIS, stepwise = FALSE, approx = FALSE), # Auto ARIMA\n    \n    autoARIMA_saz = ARIMA(GIS, stepwise = FALSE, approx = FALSE, seasonal = TRUE), # AutoARIMA Sazonal\n    \n    #    Regr_erros_ARIMA = auto.arima(TSN, xreg = fourier(K = 3), seasonal = FALSE), # Regressao com erros ARIMA\n    \n    ARIMA_saz_012011 = ARIMA(GIS ~ pdq(0,1,2) + PDQ(0,1,1)), # ARIMA Sazonal ordem 012011\n    \n    ARIMA_saz_210011 = ARIMA(GIS ~ pdq(2,1,0) + PDQ(0,1,1)), # ARIMA Sazonal ordem 210011\n    \n    ARIMA_saz_0301012 = ARIMA(GIS ~ 0 + pdq(3,0,1) + PDQ(0,1,2)), # ARIMA sazonal\n    \n    ARIMA_quad = ARIMA(GIS ~ I(trend()^2)), # ARIMA com tendencia temporal quadratica\n    \n    ARIMA_determ = ARIMA(GIS ~ 1 + trend() + pdq(d = 0)), # ARIMA com tendencia deterministica\n    \n    ARIMA_estocastico = ARIMA(GIS ~ pdq(d = 1)), # ARIMA com tend√™ncia estocastica\n    \n    Regr_Harm_dinamica = ARIMA(GIS ~ fourier(K=2) + PDQ(0,0,0)), # Regressao Harmonica Dinamica\n    \n    Regr_Harm_Din_MultSaz = ARIMA(GIS ~ PDQ(0, 0, 0) + pdq(d = 0) + fourier(period = 7*30, K = 10) + fourier(period = 7*30, K = 5)), \n    \n    Regr_Harm_Din_Saz = ARIMA(GIS ~ PDQ(0, 0, 0) + pdq(d = 0) + fourier(period = \"month\", K = 10) +\n                                fourier(period = \"year\", K = 2) ), # Rgr Harm Mult Saz Complexa\n    \n#    Auto_Prophet = prophet(TSN), # Auto prophet\n    \n#    Prophet_mult = prophet(TSN ~ season(period = \"month\", order = 2, type = \"multiplicative\")),\n    \n#    Prophet_aditivo = prophet(TSN ~ season(period = \"month\", order = 2, type = \"additive\")),\n    \n#    Prophet_geom = prophet(TSN ~ growth(\"geometric\") + season(period = \"month\", order = 2, type = \"multiplicative\")),\n    \n#    Prophet_memo = prophet(TSN ~ growth(\"geometric\") + season(period = \"month\", order = 5) +\n#                             season(period = \"year\", order = 2, type = \"multiplicative\")),\n    \n    Modelo_VAR = VAR(GIS, ic = \"bic\"), # Vetor Autoregressivo \n    \n    Random_Walk = RW(GIS ~ drift()), # Random Walk com drift\n    \n    Rede_Neural_AR = NNETAR(GIS, bootstrap =  TRUE)#, # Rede Neural com auto AR e bootstraping nos erros\n    \n    #    x11 = X_13ARIMA_SEATS(TSN ~ x11()) # X11 ARIMA Seats\n    \n  ) |&gt;\n  \n  forecast(h = \"24 months\") # Horizonte de projecao para os proximos 30 dias apos corte no treino\n\ntoc()  \n\n\n1.22 sec elapsed\n\n\n\n\nCode\nfit &lt;- lnretGIS |&gt;\n  model(\n    Regr_Quebras = TSLM(GIS ~ trend(knots = c(2018, 2019, 2020))), # Regressao com quebras estruturais\n  )\n\nsim &lt;- fit |&gt; generate(h = 30, times = 5, bootstrap = TRUE)\n\n\n\n\nCode\nlnretTSN |&gt;\n  filter_index(\"2025-01-01\"~.) |&gt;\n  ggplot(aes(x = date)) +\n  geom_line(aes(y = TSN)) +\n  geom_line(aes(y = .sim, colour = as.factor(.rep)),\n    data = sim) +\n  labs(title=\"Valores projetados de retornos de pre√ßos de contratos futuros da SALESFORCE\", y=\"$US\" ) +\n  guides(colour = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\n¬†\n\n\n\nReferences\n\nMarkowitz, H. (1952). Portfolio Selection. The Journal of Finance, 7(1), 77‚Äì91.\nLink\nSharpe, W. F. (1966). Mutual Fund Performance. The Journal of Business, 39(1), 119‚Äì138.\nLink\nElton, E. J., Gruber, M. J., Brown, S. J., & Goetzmann, W. N. (2007). Modern Portfolio Theory and Investment Analysis (9th ed.). Wiley.\nHilpisch, Y. (2018). Python for Finance: Mastering Data-Driven Finance. O‚ÄôReilly Media."
  }
]