[
  {
    "objectID": "page4.html",
    "href": "page4.html",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "",
    "text": "Esta análise tem como objetivo demonstrar um fluxo de trabalho para buscar dados de mercado de ações, realizar previsões de preços (forecasting) e treinar um agente de Reinforcement Learning (RL) para gerar sinais de compra e venda. Utilizaremos R para a coleta inicial de dados e Python (via reticulate) para a modelagem e visualização.\nNota: As previsões e sinais gerados são para fins demonstrativos e educacionais, não constituindo recomendação financeira."
  },
  {
    "objectID": "page4.html#introdução",
    "href": "page4.html#introdução",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "",
    "text": "Esta análise tem como objetivo demonstrar um fluxo de trabalho para buscar dados de mercado de ações, realizar previsões de preços (forecasting) e treinar um agente de Reinforcement Learning (RL) para gerar sinais de compra e venda. Utilizaremos R para a coleta inicial de dados e Python (via reticulate) para a modelagem e visualização.\nNota: As previsões e sinais gerados são para fins demonstrativos e educacionais, não constituindo recomendação financeira."
  },
  {
    "objectID": "page4.html#configuração-do-ambiente",
    "href": "page4.html#configuração-do-ambiente",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "1. Configuração do Ambiente",
    "text": "1. Configuração do Ambiente\nPrimeiro, vamos carregar as bibliotecas R necessárias e configurar o reticulate para usar nosso ambiente Python.\n\n\nMostrar/Ocultar Código\n# Bibliotecas R\nlibrary(tidyverse) # Para manipulação de dados e ggplot2\nlibrary(plotly)    # Para gráficos interativos (se for recriar em R)\nlibrary(reticulate)  # Para executar código Python\nlibrary(dplyr)     # Especificamente para a função de busca de dados\nlibrary(quantmod)  # Para buscar dados financeiros\n\n\nConfiguração do Python com reticulate\nCertifique-se de que o ambiente Python que você especificar abaixo tenha todas as bibliotecas Python necessárias instaladas: yahooquery, gymnasium, torch, numpy, pandas, matplotlib, yfinance, plotly.\n\n\nMostrar/Ocultar Código\n# Exemplo de como especificar um ambiente conda:\n# use_condaenv(\"meu_ambiente_python\", required = TRUE)\n\n# Ou um ambiente virtual:\n# use_virtualenv(\"caminho/para/meu_ambiente_virtual\", required = TRUE)\n\n# Ou especificar o executável Python diretamente:\n# use_python(\"/usr/bin/python3\", required = TRUE)\n\n# Se as bibliotecas não estiverem instaladas, você pode tentar instalá-las via reticulate:\n# py_install(c(\"yahooquery\", \"gymnasium\", \"torch\", \"numpy\", \"pandas\", \"matplotlib\", \"yfinance\", \"plotly\"), pip = TRUE)\n\nE o bloco de importações de bibliotecas também precisa estar dentro de um bloco de código delimitado corretamente:\n\n#| label: python-library-imports\n#| message: false\n#| warning: false\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom yahooquery import Ticker\nimport yfinance as yf\nfrom collections import deque\n\nimport gymnasium as gym\nfrom gymnasium import spaces\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"Bibliotecas Python importadas com sucesso.\")"
  },
  {
    "objectID": "page4.html#aquisição-de-dados-de-preços",
    "href": "page4.html#aquisição-de-dados-de-preços",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "2. Aquisição de Dados de Preços",
    "text": "2. Aquisição de Dados de Preços\nUtilizaremos um script R para buscar os preços de fechamento ajustados para os tickers selecionados e salvá-los em um arquivo CSV.\n\n\nMostrar/Ocultar Código\nfetch_close_prices_qm &lt;- function(tickers, start, end, cache_path = \"prices_qm.csv\") {\n  # Se já existe CSV em cache, carrega e retorna\n  if (file.exists(cache_path)) {\n    df &lt;- read.csv(cache_path, stringsAsFactors = FALSE) %&gt;%\n      mutate(date = as.Date(date))\n    message(\"Dados carregados do cache: \", cache_path)\n    return(df)\n  }\n\n  # Senão, faz o download para cada ticker\n  all_data &lt;- lapply(tickers, function(tk) {\n    # getSymbols retorna um objeto xts com colunas Open, High, Low, Close, Volume, Adjusted\n    xts_data &lt;- tryCatch({\n        getSymbols(tk, src = \"yahoo\", from = start, to = end, auto.assign = FALSE)\n    }, error = function(e) {\n        message(paste(\"Erro ao buscar dados para\", tk, \":\", e$message))\n        return(NULL)\n    })\n\n    if (is.null(xts_data)) return(NULL)\n\n    close_prices &lt;- Ad(xts_data)  # usa Preço Ajustado (Adjusted Close)\n    data.frame(\n      date   = index(close_prices),\n      ticker = tk,\n      close  = as.numeric(close_prices),\n      row.names = NULL\n    )\n  })\n\n  # Remove NULLs (tickers com erro) e combina\n  all_data &lt;- all_data[!sapply(all_data, is.null)]\n  if (length(all_data) == 0) {\n    stop(\"Nenhum dado foi baixado para os tickers especificados.\")\n  }\n  df &lt;- bind_rows(all_data)\n\n  # Salva em CSV para próximas execuções\n  write.csv(df, cache_path, row.names = FALSE)\n  message(\"Dados salvos no cache: \", cache_path)\n\n  return(df)\n}\n\n\n\n\nMostrar/Ocultar Código\ntickers &lt;- c(\"BRFS3.SA\", \"JBSS3.SA\", \"BEEF3.SA\", \"MRFG3.SA\", \"TSN\", \"HRL\", \"GIS\")\nstart_date &lt;- \"2020-01-01\" \nend_date &lt;- format(Sys.Date(), \"%Y-%m-%d\") # Usar data atual para 'to'\n\ndf_prices_r &lt;- fetch_close_prices_qm(tickers, start_date, end_date, cache_path = \"prices_analise.csv\") \n\n\nDados carregados do cache: prices_analise.csv\n\n\nMostrar/Ocultar Código\ntail(df_prices_r)\n\n\n           date ticker close\n9385 2025-05-08    GIS 54.71\n9386 2025-05-09    GIS 54.50\n9387 2025-05-12    GIS 54.84\n9388 2025-05-13    GIS 53.77\n9389 2025-05-14    GIS 53.28\n9390 2025-05-15    GIS 54.40"
  },
  {
    "objectID": "page4.html#preparação-e-análise-exploratória-dos-dados-python",
    "href": "page4.html#preparação-e-análise-exploratória-dos-dados-python",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "3. Preparação e Análise Exploratória dos Dados (Python)",
    "text": "3. Preparação e Análise Exploratória dos Dados (Python)\nCarregamos os dados do CSV em um DataFrame pandas e o pivotamos para facilitar a análise por ticker.\n\n\nMostrar/Ocultar Código\nimport pandas as pd\n# Carregar dados do CSV salvo pelo R\ndf_prices = pd.read_csv('prices_analise.csv', parse_dates=['date'])\nprint(\"Tail do df_prices carregado:\")\n\n\nTail do df_prices carregado:\n\n\nMostrar/Ocultar Código\nprint(df_prices.tail())\n\n\n           date ticker      close\n9385 2025-05-09    GIS  54.500000\n9386 2025-05-12    GIS  54.840000\n9387 2025-05-13    GIS  53.770000\n9388 2025-05-14    GIS  53.279999\n9389 2025-05-15    GIS  54.400002\n\n\nMostrar/Ocultar Código\n# Pivotear somente as colunas 'ticker' e 'close'\ndf_pivot = df_prices.pivot(index='date', columns='ticker', values='close')\ndf_pivot = df_pivot.reset_index() # Manter 'date' como coluna\n\nprint(\"\\\\nTail do df_pivot:\")\n\n\n\\nTail do df_pivot:\n\n\nMostrar/Ocultar Código\nprint(df_pivot.tail())\n\n\nticker       date  BEEF3.SA   BRFS3.SA  ...   JBSS3.SA   MRFG3.SA        TSN\n1380   2025-05-09      4.96  19.200001  ...  42.360001  19.850000  55.299999\n1381   2025-05-12      5.07  19.709999  ...  41.889999  19.820000  55.990002\n1382   2025-05-13      5.11  20.200001  ...  40.849998  20.090000  55.360001\n1383   2025-05-14      5.15  19.680000  ...  39.349998  19.799999  54.500000\n1384   2025-05-15      5.14  20.620001  ...  39.180000  20.660000  55.650002\n\n[5 rows x 8 columns]"
  },
  {
    "objectID": "page4.html#forecasting-de-preços-python-com-plotly",
    "href": "page4.html#forecasting-de-preços-python-com-plotly",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "4. Forecasting de Preços (Python com Plotly)",
    "text": "4. Forecasting de Preços (Python com Plotly)\nRealizamos uma simulação simples de forecasting baseada na média e desvio padrão dos retornos logarítmicos históricos.\n\n\nMostrar/Ocultar Código\nimport numpy as np\nimport pandas as pd \nimport plotly.express as px\n# Defina a data de corte e o período do forecast\n# Usar a data mais recente do df_pivot como CUT\nCUT = df_pivot[\"date\"].max()\nforecast_days = 30\nfuture_dates = pd.date_range(CUT + pd.Timedelta(days=1), periods=forecast_days, freq=\"D\")\n\n# Lista de ativos (tickers)\nassets = df_pivot.columns[1:]  # Ignorando a coluna 'date'\n\n# Lista para armazenar os dados de forecast\nforecast_data = []\n\n# Gera previsões para cada ativo (simulação simples)\nfor asset in assets:\n    # Pega os dados históricos até a data de corte\n    df_asset_hist = df_pivot[[\"date\", asset]].copy() # Usar .copy() para evitar SettingWithCopyWarning\n    df_asset_hist = df_asset_hist[df_asset_hist[\"date\"] &lt;= CUT]\n    df_asset_hist.dropna(subset=[asset], inplace=True) # Remover NaNs que podem atrapalhar pct_change\n\n    if len(df_asset_hist) &lt; 2: # Precisa de pelo menos 2 pontos para pct_change\n        print(f\"Dados insuficientes para forecasting do ativo: {asset}\")\n        continue\n\n    # Calcula a média e desvio padrão dos retornos históricos\n    df_asset_hist[\"logret\"] = df_asset_hist[asset].pct_change()\n    # Remover o primeiro NaN de logret e quaisquer outros NaNs/infs\n    df_asset_hist.replace([np.inf, -np.inf], np.nan, inplace=True)\n    df_asset_hist.dropna(subset=['logret'], inplace=True)\n\n    if df_asset_hist[\"logret\"].empty:\n        print(f\"Não foi possível calcular retornos para o ativo: {asset}\")\n        mu = 0 # Default mu\n        sigma = 0.01 # Default sigma para evitar erro com scale=0\n    else:\n        mu = df_asset_hist[\"logret\"].mean()\n        sigma = df_asset_hist[\"logret\"].std()\n        if pd.isna(sigma) or sigma == 0: # Adiciona uma pequena volatilidade se std for 0 ou NaN\n            sigma = 0.01 \n\n    # Simula os retornos futuros\n    simulated_logrets = np.random.normal(loc=mu, scale=sigma, size=forecast_days)\n    last_price = df_asset_hist[asset].iloc[-1]\n    if pd.isna(last_price): # Se o último preço for NaN, use um preço padrão ou pule\n        print(f\"Último preço é NaN para o ativo: {asset}. Pulando forecast.\")\n        continue\n        \n    simulated_prices = last_price * (1 + simulated_logrets).cumprod()\n\n    # Adiciona os dados de forecast\n    for date_val, value in zip(future_dates, simulated_prices):\n        forecast_data.append({\n            \"date\": date_val,\n            \"asset\": asset,\n            \"price\": value,\n            \"rep\": \"Forecast\"\n        })\n\ndf_forecast = pd.DataFrame(forecast_data)\n\n# Prepara o histórico para plotar junto, filtrando até a data de corte\nhist_data = df_pivot[df_pivot[\"date\"] &lt;= CUT].copy()\nhist_data = hist_data.melt(id_vars=\"date\", var_name=\"asset\", value_name=\"price\")\nhist_data[\"rep\"] = \"Histórico\"\n\n# Junta histórico e forecast\ndf_plot = pd.concat([hist_data, df_forecast], ignore_index=True)\n\n# Filtra os dados para mostrar apenas o período relevante (últimos N dias de histórico + forecast)\n# Por exemplo, últimos 60 dias de histórico + 30 dias de forecast\nstart_plot_date = CUT - pd.Timedelta(days=60)\nend_plot_date = CUT + pd.Timedelta(days=forecast_days)\n\ndf_plot_filtered = df_plot[(df_plot[\"date\"] &gt;= start_plot_date) & (df_plot[\"date\"] &lt;= end_plot_date)]\n\nif not df_plot_filtered.empty:\n    fig_forecast = px.line(\n        df_plot_filtered,\n        x=\"date\",\n        y=\"price\",\n        color=\"rep\",\n        facet_col=\"asset\",\n        facet_col_wrap=2, # Ajuste conforme o número de tickers\n        labels={\"date\": \"Data\", \"price\": \"Preço (Moeda Local/USD)\", \"rep\": \"Série\"},\n        title=f\"Forecasting de Preços ({forecast_days} dias) a partir de {CUT.strftime('%Y-%m-%d')}\"\n    )\n    fig_forecast.update_layout(width=1000, height=300 * (len(assets)//2 + len(assets)%2)) # Ajusta altura\n    fig_forecast.update_xaxes(matches=None, nticks=5)\n    fig_forecast.show()\nelse:\n    print(\"Nenhum dado para plotar no gráfico de forecast.\")\n\n\n                        \n                                            \nForecasting de Preços para os Tickers da Carteira (Próximos 30 dias)"
  },
  {
    "objectID": "page4.html#reinforcement-learning-para-sinais-de-trading",
    "href": "page4.html#reinforcement-learning-para-sinais-de-trading",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "5. Reinforcement Learning para Sinais de Trading",
    "text": "5. Reinforcement Learning para Sinais de Trading\n\n5.1. Definição do Agente e Funções Auxiliares\nDefinimos a função getState e a classe Agent que representa nosso agente de RL.\n\n\nMostrar/Ocultar Código\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\ndef getState(data, t, window_size):\n    \"\"\"\n    Converte uma janela de preços em vetor de retornos normalizados.\n    \"\"\"\n    d = t - window_size + 1\n    block = data[d:t+1] if d &gt;= 0 else -d * [data[0]] + list(data[0:t+1])\n    # Evitar divisão por zero se block[i] for 0\n    res = []\n    for i in range(len(block)-1):\n        if block[i] != 0:\n            res.append((block[i+1] - block[i]) / block[i])\n        else:\n            res.append(0) # Retorno zero se o preço base for zero\n    return np.array(res, dtype=np.float32)\n\nclass Agent(nn.Module):\n    def __init__(\n        self,\n        state_size,\n        hidden_size=64,\n        lr=1e-4,\n        gamma=0.95,\n        epsilon=1.0,\n        epsilon_min=0.01,\n        epsilon_decay=0.995\n    ):\n        super(Agent, self).__init__()\n        self.gamma = gamma\n        self.epsilon = epsilon\n        self.epsilon_min = epsilon_min\n        self.epsilon_decay = epsilon_decay\n        self.inventory = [] # Adicionado para manter o inventário do agente\n        \n        self.model = nn.Sequential(\n            nn.Linear(state_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, 3)  # Q para 3 ações: 0=HOLD, 1=BUY, 2=SELL\n        )\n        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n        self.criterion = nn.MSELoss()\n\n    def act(self, state):\n        if np.random.rand() &lt; self.epsilon:\n            return np.random.choice([0,1,2]) # 0: HOLD, 1: BUY, 2: SELL\n        state_t = torch.from_numpy(state).unsqueeze(0)\n        q_values = self.model(state_t).detach().numpy()[0]\n        return np.argmax(q_values)\n\n    def train_step(self, state, action, reward, next_state, done): # Adicionado 'done'\n        state_t = torch.from_numpy(state).unsqueeze(0)\n        next_t = torch.from_numpy(next_state).unsqueeze(0)\n        \n        q_values = self.model(state_t)\n        \n        with torch.no_grad():\n            q_next = self.model(next_t).max(1)[0]\n            if done: # Se for o estado terminal, o valor do próximo estado é 0\n                 target_q_value = reward\n            else:\n                 target_q_value = reward + self.gamma * q_next\n\n        target = q_values.clone().detach()\n        target[0, action] = target_q_value\n        \n        loss = self.criterion(q_values, target)\n        self.optimizer.zero_grad()\n        loss.backward()\n        self.optimizer.step()\n        \n        if self.epsilon &gt; self.epsilon_min:\n            self.epsilon *= self.epsilon_decay\n\nprint(\"Definições do Agente RL carregadas.\")\n\n\nDefinições do Agente RL carregadas.\n\n\n\n\n5.2. Treinamento do Agente RL\nTreinamos o agente para cada ticker da nossa lista.\n\n\nMostrar/Ocultar Código\nimport numpy as np\nimport torch\nimport torch.nn as nn\n# Parâmetros de treinamento\nwindow_size = 10  # Deve ser state_size - 1 se getState retorna len(block)-1\nepisodes    = 50 # Reduzido para demonstração rápida, pode aumentar para melhor performance\nrl_results  = {}\n\n# Tickers para o treinamento (obtidos do df_pivot)\n# A primeira coluna é 'date', então pegamos da segunda em diante\ntrain_tickers = df_pivot.columns[1:].tolist() \n\nfor tk in train_tickers:\n    print(f\"\\\\n=== Treinando para {tk} ===\")\n    \n    # Prepara série de preços para o ticker\n    prices = df_prices[df_prices['ticker'] == tk].sort_values(\"date\")['close'].values\n    prices = prices[~np.isnan(prices)] # Remover NaNs dos preços\n\n    if len(prices) &lt; window_size + 2: # Checagem mais robusta para dados suficientes\n        print(f\"Dados insuficientes para {tk} após remover NaNs. Pulando ticker.\")\n        rl_results[tk] = [0] * episodes # Adiciona placeholder para evitar erro no plot\n        continue\n\n    # O state_size é o tamanho da saída de getState, que é window_size\n    agent = Agent(state_size=window_size) \n    total_profits_tk = []\n\n    for e in range(episodes):\n        state = getState(prices, 0, window_size + 1) # getState espera window_size + 1 para gerar 'window_size' retornos\n        agent.inventory = []\n        total_profit   = 0.0 # Inicializar como float\n\n        for t in range(len(prices)-1): # Loop até o penúltimo preço\n            action     = agent.act(state)\n            # O next_state é para o tempo t+1, então o último t+1 será len(prices)-1\n            next_state = getState(prices, t + 1, window_size + 1)\n            reward     = 0.0 # Inicializar como float\n            done = (t == len(prices) - 2) # 'done' é true no último passo\n\n            # Executa ação: BUY, SELL ou HOLD\n            if action == 1:  # BUY\n                agent.inventory.append(prices[t])\n            elif action == 2 and agent.inventory:  # SELL\n                bought_price = agent.inventory.pop(0)\n                profit       = prices[t] - bought_price\n                if bought_price != 0: # Evitar divisão por zero\n                    reward = profit / bought_price\n                else:\n                    reward = 0.0\n                total_profit += profit\n            \n            agent.train_step(state, action, reward, next_state, done)\n            state = next_state\n\n        total_profits_tk.append(total_profit)\n        if (e+1) % 10 == 0 or e == episodes -1 : # Imprimir a cada 10 episódios e no último\n            print(f\"Episódio {e+1}/{episodes} — Lucro: {total_profit:.2f}\")\n    \n    rl_results[tk] = total_profits_tk\n\n\n\\n=== Treinando para BEEF3.SA ===\nEpisódio 10/50 — Lucro: 0.89\nEpisódio 20/50 — Lucro: 2.68\nEpisódio 30/50 — Lucro: 607.59\nEpisódio 40/50 — Lucro: -6.41\nEpisódio 50/50 — Lucro: -10.22\n\\n=== Treinando para BRFS3.SA ===\nEpisódio 10/50 — Lucro: 0.77\nEpisódio 20/50 — Lucro: 59.63\nEpisódio 30/50 — Lucro: 3.08\nEpisódio 40/50 — Lucro: -16.35\nEpisódio 50/50 — Lucro: -16.92\n\\n=== Treinando para GIS ===\nEpisódio 10/50 — Lucro: 96.41\nEpisódio 20/50 — Lucro: 8.61\nEpisódio 30/50 — Lucro: -16.59\nEpisódio 40/50 — Lucro: 84.06\nEpisódio 50/50 — Lucro: 63.60\n\\n=== Treinando para HRL ===\nEpisódio 10/50 — Lucro: 33.96\nEpisódio 20/50 — Lucro: -12.28\nEpisódio 30/50 — Lucro: -10.20\nEpisódio 40/50 — Lucro: -9.64\nEpisódio 50/50 — Lucro: 76.36\n\\n=== Treinando para JBSS3.SA ===\nEpisódio 10/50 — Lucro: 0.27\nEpisódio 20/50 — Lucro: 33.14\nEpisódio 30/50 — Lucro: 49.65\nEpisódio 40/50 — Lucro: 29.81\nEpisódio 50/50 — Lucro: 32.77\n\\n=== Treinando para MRFG3.SA ===\nEpisódio 10/50 — Lucro: 28.93\nEpisódio 20/50 — Lucro: -1.70\nEpisódio 30/50 — Lucro: -0.90\nEpisódio 40/50 — Lucro: 0.02\nEpisódio 50/50 — Lucro: 52.42\n\\n=== Treinando para TSN ===\nEpisódio 10/50 — Lucro: 72.40\nEpisódio 20/50 — Lucro: 7.64\nEpisódio 30/50 — Lucro: 15.12\nEpisódio 40/50 — Lucro: -32.55\nEpisódio 50/50 — Lucro: -87.95\n\n\nMostrar/Ocultar Código\n# Plot da evolução do lucro\nif rl_results: # Apenas plotar se houver resultados\n    df_hist_profit = pd.DataFrame(rl_results)\n    # Adicionar coluna 'Episódio' se o índice não for usado diretamente\n    if not isinstance(df_hist_profit.index, pd.RangeIndex) or df_hist_profit.index.name != 'Episódio':\n        df_hist_profit = df_hist_profit.reset_index().rename(columns={'index': 'Episódio'})\n        # Se o índice já é RangeIndex (0 a N-1), apenas nomeie-o ou use-o diretamente\n    elif df_hist_profit.index.name != 'Episódio':\n         df_hist_profit.index.name = 'Episódio'\n         df_hist_profit = df_hist_profit.reset_index()\n\n    df_melt_profit = df_hist_profit.melt(\n        id_vars='Episódio',\n        var_name='ticker',\n        value_name='Lucro'\n    )\n\n    fig_profit_evol = px.line(\n        df_melt_profit,\n        x='Episódio',\n        y='Lucro',\n        color='ticker',\n        title='Evolução do Lucro Total por Episódio (Treinamento RL)'\n    )\n    fig_profit_evol.update_layout(\n        xaxis_title='Episódio',\n        yaxis_title='Lucro Total (Moeda Local/USD)'\n    )\n    fig_profit_evol.show()\nelse:\n    print(\"Nenhum resultado de treinamento RL para plotar.\")\n\n\n                        \n                                            \nEvolução do Lucro Total por Episódio Durante o Treinamento do Agente RL\n\n\n\n\n5.3. Geração de Sinais de Trading e Visualização\nApós o treinamento, usamos o agente para gerar sinais de COMPRA/VENDA e os visualizamos.\n\n\nMostrar/Ocultar Código\nimport numpy as np\nimport pandas as pd\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots # Importe make_subplots aqui\nimport torch\nimport torch.nn as nn\n# 1) Gera sinais para cada ticker\nall_signals = {}\n# Usar a última instância do agente treinada ou treinar um novo/carregar\n# Para este exemplo, vamos reusar a última instância 'agent' do loop de treinamento,\n# que foi treinada no último ticker da lista 'train_tickers'.\n# Idealmente, você teria um agente treinado por ticker ou um agente geral.\n# Aqui, vamos gerar sinais para todos os tickers usando o agente treinado no ÚLTIMO ticker.\n# Isto é mais para demonstração da plotagem.\n# Para uma análise real, você deveria ter um agente específico por ticker ou um agente treinado em todos.\n\n# Se 'agent' não foi definido (ex: todos os tickers foram pulados no treinamento)\nif 'agent' not in locals() and train_tickers:\n    print(\"Agente não treinado. Treinando um agente no primeiro ticker disponível para demonstração de sinais.\")\n    tk_demo = train_tickers[0]\n    prices_demo = df_prices[df_prices['ticker'] == tk_demo].sort_values(\"date\")['close'].values\n    prices_demo = prices_demo[~np.isnan(prices_demo)]\n    if len(prices_demo) &gt;= window_size + 2:\n        agent = Agent(state_size=window_size)\n        # Treinamento rápido apenas para ter um agente\n        for e_demo in range(5): # Treino muito curto\n            state_demo = getState(prices_demo, 0, window_size + 1)\n            for t_demo in range(len(prices_demo) -1):\n                action_demo = agent.act(state_demo)\n                next_state_demo = getState(prices_demo, t_demo + 1, window_size + 1)\n                # Recompensa e 'done' simplificados para este agente de demonstração\n                agent.train_step(state_demo, action_demo, 0, next_state_demo, (t_demo == len(prices_demo) - 2))\n                state_demo = next_state_demo\n    else:\n        agent = None # Não foi possível treinar agente de demonstração\n        print(f\"Não foi possível treinar agente de demonstração para {tk_demo}\")\n\n\nif agent: # Prossiga apenas se o agente existir\n    for tk_signal in train_tickers: # Usar train_tickers para consistência\n        agent.epsilon = agent.epsilon_min # Usar política greedy para geração de sinais\n        \n        current_prices_tk = df_prices[df_prices.ticker==tk_signal].sort_values('date')\n        \n        if current_prices_tk.empty or 'close' not in current_prices_tk.columns:\n            print(f\"Aviso: Nenhum dado de preço para {tk_signal} na geração de sinais. Pulando.\")\n            all_signals[tk_signal] = pd.DataFrame(columns=['date', 'action', 'price'])\n            continue\n\n        dates_signal  = current_prices_tk['date'].values\n        values_signal = current_prices_tk['close'].values\n        values_signal = values_signal[~np.isnan(values_signal)] # Remover NaNs\n\n        if len(values_signal) &lt; window_size + 2:\n            print(f\"Dados insuficientes para {tk_signal} na geração de sinais após remover NaNs. Pulando.\")\n            all_signals[tk_signal] = pd.DataFrame(columns=['date', 'action', 'price'])\n            continue\n            \n        state_signal = getState(values_signal, 0, window_size+1)\n        agent.inventory = [] # Resetar inventário para cada ticker\n        signals_current_tk = []\n\n        for t_signal in range(len(values_signal)-1):\n            action_signal = agent.act(state_signal)\n            date_val  = dates_signal[t_signal]\n            price_val = values_signal[t_signal]\n            \n            if action_signal == 1: # BUY\n                signals_current_tk.append({'date': date_val, 'action': 'BUY',  'price': price_val})\n                agent.inventory.append(price_val)\n            elif action_signal == 2 and agent.inventory: # SELL\n                signals_current_tk.append({'date': date_val, 'action': 'SELL', 'price': price_val})\n                agent.inventory.pop(0)\n            \n            next_state_signal = getState(values_signal, t_signal+1, window_size+1)\n            state_signal = next_state_signal\n\n        if signals_current_tk:\n            all_signals[tk_signal] = pd.DataFrame(signals_current_tk)\n        else:\n            all_signals[tk_signal] = pd.DataFrame(columns=['date', 'action', 'price'])\nelse:\n    print(\"Agente RL não está definido. Pulando geração e visualização de sinais.\")\n    all_signals = {tk: pd.DataFrame(columns=['date', 'action', 'price']) for tk in train_tickers}\n\n\nnp.float64(10.5756063461304)\nnp.float64(10.6932888031006)\nnp.float64(11.4229106903076)\nnp.float64(11.3366088867188)\nnp.float64(11.4893159866333)\nnp.float64(13.9750709533691)\nnp.float64(14.4566497802734)\nnp.float64(15.0493640899658)\nnp.float64(16.373706817627)\nnp.float64(16.234790802002)\nnp.float64(44.5136642456055)\nnp.float64(44.9762153625488)\nnp.float64(44.8921089172363)\nnp.float64(42.1858367919922)\nnp.float64(39.0825309753418)\nnp.float64(42.0554466247559)\nnp.float64(41.1774749755859)\nnp.float64(43.8619689941406)\nnp.float64(43.8258438110352)\nnp.float64(43.0248756408691)\nnp.float64(44.7806282043457)\nnp.float64(19.4537944793701)\nnp.float64(20.1444644927979)\nnp.float64(20.1918601989746)\nnp.float64(20.3746871948242)\nnp.float64(14.9306020736694)\nnp.float64(14.6055812835693)\nnp.float64(7.17265319824219)\nnp.float64(7.2646951675415)\nnp.float64(7.46850156784058)\nnp.float64(51.1741600036621)\nnp.float64(50.0667533874512)\nnp.float64(47.8779144287109)\n\n\nMostrar/Ocultar Código\n# 2) Cria figura com uma linha por ticker\nif train_tickers and all_signals : # Apenas se houver tickers e sinais\n    fig_signals = make_subplots(\n        rows=len(train_tickers), cols=1,\n        shared_xaxes=True,\n        subplot_titles=train_tickers,\n        vertical_spacing=0.02\n    )\n\n    for i, tk_plot in enumerate(train_tickers, start=1):\n        prices_tk_plot = df_prices[df_prices.ticker==tk_plot].sort_values('date')\n        sig_df_plot = all_signals.get(tk_plot, pd.DataFrame(columns=['date', 'action', 'price']))\n\n        if not prices_tk_plot.empty and 'close' in prices_tk_plot.columns:\n            fig_signals.add_trace(\n                go.Scatter(x=prices_tk_plot['date'], y=prices_tk_plot['close'], mode='lines', name=f'Preço {tk_plot}', legendgroup=f'group{tk_plot}'),\n                row=i, col=1\n            )\n        \n        buy_signals_plot = sig_df_plot.query(\"action=='BUY'\")\n        if not buy_signals_plot.empty:\n            fig_signals.add_trace(\n                go.Scatter(x=buy_signals_plot['date'],\n                           y=buy_signals_plot['price'],\n                           mode='markers', marker_symbol='triangle-up',\n                           marker_size=8, marker_color='green', \n                           name=f'Compra', showlegend=(i==1), legendgroup=f'group_buy'), # Mostrar legenda apenas uma vez\n                row=i, col=1\n            )\n        \n        sell_signals_plot = sig_df_plot.query(\"action=='SELL'\")\n        if not sell_signals_plot.empty:\n            fig_signals.add_trace(\n                go.Scatter(x=sell_signals_plot['date'],\n                           y=sell_signals_plot['price'],\n                           mode='markers', marker_symbol='triangle-down',\n                           marker_size=8, marker_color='red',\n                           name=f'Venda', showlegend=(i==1), legendgroup=f'group_sell'), # Mostrar legenda apenas uma vez\n                row=i, col=1\n            )\n\n    fig_signals.update_layout(\n        height=max(300 * len(train_tickers), 800), # Ajusta altura dinamicamente, mínimo de 800px\n        title_text='Sinais de Compra/Venda por Ticker (Agente RL)',\n        legend_tracegroupgap = 180 # Espaçamento entre grupos de legenda\n    )\n    fig_signals.update_yaxes(title_text=\"Preço\") \n    # Aplicar título do eixo X apenas ao último subplot visível\n    # Encontrar o último subplot que realmente tem dados para o eixo X\n    last_row_with_data = 0\n    for r in range(len(train_tickers), 0, -1):\n        if not df_prices[df_prices.ticker==train_tickers[r-1]].empty:\n            last_row_with_data = r\n            break\n    if last_row_with_data &gt; 0:\n      fig_signals.update_xaxes(title_text=\"Data\", row=last_row_with_data, col=1)\n    \n    fig_signals.show()\nelse:\n    print(\"Nenhum ticker ou sinal para plotar.\")\n\n\n                        \n                                            \nSinais de Compra/Venda Gerados pelo Agente RL por Ticker"
  },
  {
    "objectID": "page4.html#conclusão",
    "href": "page4.html#conclusão",
    "title": "Análise de Carteira com Forecasting e Reinforcement Learning",
    "section": "6. Conclusão",
    "text": "6. Conclusão\nEste documento demonstrou um pipeline para análise de dados financeiros, incluindo coleta de dados, forecasting e a aplicação de um agente de Reinforcement Learning para gerar sinais de trading. Os resultados visuais do forecasting e dos sinais do agente RL fornecem insights que podem auxiliar na tomada de decisões de investimento, lembrando sempre da importância de análises complementares e do gerenciamento de risco.\nOs gráficos de evolução do lucro durante o treinamento do agente RL indicam a capacidade de aprendizado do modelo em diferentes ativos, embora a performance possa variar significativamente. A visualização final dos sinais de compra e venda sobrepostos aos preços históricos permite uma avaliação qualitativa da estratégia do agente."
  },
  {
    "objectID": "page2.html",
    "href": "page2.html",
    "title": "Ciência de Dados para Negócios: Big Data for Finance Project",
    "section": "",
    "text": "Resumo\n\n\n\n\n\nAnálise de Séries de Preços e Log-Retornos\n\n\n\n\n\nIntro\n\n1️⃣ Conversão para Log-Retornos2️⃣ Construção e Avaliação das Distribuições3️⃣ Cálculo da Variância\n\n\nConverter a série de preços em log-retornos utilizando a seguinte fórmula:\n[ p_t = \\ln(p_t) - \\ln(p_{t-1}) ]\nEssa transformação nos permite analisar os retornos percentuais de forma mais adequada.\n\n\n\n\nConstruir os histogramas de cada série de retornos transformada.\nAvaliar a assimetria das distribuições e identificar se há predominância de retornos positivos ou negativos no período analisado.\n\n\n\n\nCalcular a variância da série de retornos logarítmicos utilizando:\n\n🔹 O desvio padrão como medida direta (volatilidade histórica com janela de 5 dias).\n🔹 Ou de maneira mais acurada, modelos econométricos (ex.: GARCH(1,1)) para obter a variância condicional.\n\ndate BEEF3.SA BRFS3.SA GIS HRL JBSS3.SA MRFG3.SA \\ 1238 2025-03-14 0.031093 0.024722 0.024976 0.014724 0.015667 0.024863 1239 2025-03-17 0.031816 0.026581 0.028208 0.015502 0.016132 0.028757 1240 2025-03-18 0.022213 0.040627 0.021501 0.014557 0.073009 0.036127 1241 2025-03-19 0.021905 0.039398 0.015938 0.007907 0.073728 0.035161 1242 2025-03-20 0.033103 0.034645 0.016877 0.007681 0.071088 0.039908\nTSN 1238 0.011254 1239 0.011458 1240 0.011033 1241 0.006089 1242 0.006956\n\n\n\n\n4️⃣ Visualizações\n\n\n\n📉 Gráficos de séries temporais de preços:"
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html",
    "href": "fuzzy_topsis_analise_acoes.html",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "",
    "text": "Mostrar/Ocultar Código\nimport yfinance as yf\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler"
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html#bibliotecas",
    "href": "fuzzy_topsis_analise_acoes.html#bibliotecas",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "",
    "text": "Mostrar/Ocultar Código\nimport yfinance as yf\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler"
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html#download-dos-dados",
    "href": "fuzzy_topsis_analise_acoes.html#download-dos-dados",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "Download dos Dados",
    "text": "Download dos Dados\n\n\nMostrar/Ocultar Código\n# Tickers da carteira\ntickers = ['BRFS3.SA', 'JBSS3.SA', 'BEEF3.SA', 'MRFG3.SA', 'TSN', 'HRL', 'GIS']\n\n# Download dos preços históricos\ndados = yf.download(tickers, start=\"2024-10-01\", end=\"2025-04-25\", progress=False)\n\n# Verificação dos dados baixados\nif isinstance(dados.columns, pd.MultiIndex):\n    downloaded_tickers = dados.columns.levels[1].tolist()\n    available_tickers = [ticker for ticker in downloaded_tickers if not dados[('Close', ticker)].isnull().all()]\nelse:\n    if not dados.empty:\n        available_tickers = [ticker for ticker in tickers if not dados[ticker].isnull().all()]\n    else:\n        available_tickers = []\n\nif not available_tickers:\n    raise ValueError(\"❌ Nenhum dado foi baixado. Verifique os tickers e o período.\")\n\nprint(f\"✅ Dados baixados para: {', '.join(available_tickers)}\")\n\n\nC:\\Users\\kuiav\\AppData\\Local\\Temp\\ipykernel_15988\\1853906305.py:5: FutureWarning:\n\nYF.download() has changed argument auto_adjust default to True\n\n\n\n✅ Dados baixados para: BEEF3.SA, BRFS3.SA, GIS, HRL, JBSS3.SA, MRFG3.SA, TSN"
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html#preparação-dos-dados",
    "href": "fuzzy_topsis_analise_acoes.html#preparação-dos-dados",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "Preparação dos Dados",
    "text": "Preparação dos Dados\n\n\nMostrar/Ocultar Código\nprecos = pd.DataFrame()\n\nfor ticker in available_tickers:\n    if ('Adj Close', ticker) in dados.columns and (not dados[('Adj Close', ticker)].isnull().all()):\n        precos[ticker] = dados[('Adj Close', ticker)]\n    elif ('Close', ticker) in dados.columns and (not dados[('Close', ticker)].isnull().all()):\n        print(f\"⚠️ Usando 'Close' para {ticker}, pois 'Adj Close' não está disponível.\")\n        precos[ticker] = dados[('Close', ticker)]\n    else:\n        print(f\"❌ Dados insuficientes para {ticker}. Ignorando.\")\n\nif precos.empty:\n    raise ValueError(\"❌ Nenhuma coluna válida encontrada para análise.\")\n\nprecos = precos.dropna()\n\nif precos.empty:\n    raise ValueError(\"❌ Dados insuficientes após remoção de valores nulos.\")\n\n\n⚠️ Usando 'Close' para BEEF3.SA, pois 'Adj Close' não está disponível.\n⚠️ Usando 'Close' para BRFS3.SA, pois 'Adj Close' não está disponível.\n⚠️ Usando 'Close' para GIS, pois 'Adj Close' não está disponível.\n⚠️ Usando 'Close' para HRL, pois 'Adj Close' não está disponível.\n⚠️ Usando 'Close' para JBSS3.SA, pois 'Adj Close' não está disponível.\n⚠️ Usando 'Close' para MRFG3.SA, pois 'Adj Close' não está disponível.\n⚠️ Usando 'Close' para TSN, pois 'Adj Close' não está disponível."
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html#cálculo-de-retornos",
    "href": "fuzzy_topsis_analise_acoes.html#cálculo-de-retornos",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "Cálculo de Retornos",
    "text": "Cálculo de Retornos\n\n\nMostrar/Ocultar Código\nretornos_diarios = precos.pct_change().dropna()\n\nif retornos_diarios.empty:\n    raise ValueError(\"❌ Retornos diários insuficientes.\")\n\nretorno_medio_anual = (retornos_diarios.mean() * 252) * 100\nrisco_anual = (retornos_diarios.std() * np.sqrt(252)) * 100\n\ndf = pd.DataFrame({\n    'Ticker': retorno_medio_anual.index,\n    'Retorno Esperado (%)': retorno_medio_anual.values,\n    'Risco (%)': risco_anual.values\n})\n\ndf\n\n\n\n\n\n\n\n\n\nTicker\nRetorno Esperado (%)\nRisco (%)\n\n\n\n\n0\nBEEF3.SA\n19.952812\n52.777333\n\n\n1\nBRFS3.SA\n-5.995730\n38.618763\n\n\n2\nGIS\n-44.667148\n24.262767\n\n\n3\nHRL\n-1.237448\n21.940254\n\n\n4\nJBSS3.SA\n82.872584\n41.321213\n\n\n5\nMRFG3.SA\n121.350365\n47.075397\n\n\n6\nTSN\n10.791430\n22.756921"
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html#normalização-e-pesos-fuzzy-topsis",
    "href": "fuzzy_topsis_analise_acoes.html#normalização-e-pesos-fuzzy-topsis",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "Normalização e Pesos (Fuzzy TOPSIS)",
    "text": "Normalização e Pesos (Fuzzy TOPSIS)\n\n\nMostrar/Ocultar Código\ndf_normalized = df.copy()\n\nscaler_ret = MinMaxScaler()\ndf_normalized['Retorno Normalizado'] = scaler_ret.fit_transform(df[['Retorno Esperado (%)']])\n\nscaler_risk = MinMaxScaler()\ndf_normalized['Risco Normalizado'] = 1 - scaler_risk.fit_transform(df[['Risco (%)']])\n\npeso_retorno = 0.6\npeso_risco = 0.4\n\ndf_normalized['Retorno Ponderado'] = df_normalized['Retorno Normalizado'] * peso_retorno\ndf_normalized['Risco Ponderado'] = df_normalized['Risco Normalizado'] * peso_risco"
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html#cálculo-do-topsis",
    "href": "fuzzy_topsis_analise_acoes.html#cálculo-do-topsis",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "Cálculo do TOPSIS",
    "text": "Cálculo do TOPSIS\n\n\nMostrar/Ocultar Código\nideal_positivo = [\n    df_normalized['Retorno Ponderado'].max(),\n    df_normalized['Risco Ponderado'].max()\n]\n\nideal_negativo = [\n    df_normalized['Retorno Ponderado'].min(),\n    df_normalized['Risco Ponderado'].min()\n]\n\ndistancia_positiva = np.sqrt(\n    (df_normalized['Retorno Ponderado'] - ideal_positivo[0])**2 +\n    (df_normalized['Risco Ponderado'] - ideal_positivo[1])**2\n)\n\ndistancia_negativa = np.sqrt(\n    (df_normalized['Retorno Ponderado'] - ideal_negativo[0])**2 +\n    (df_normalized['Risco Ponderado'] - ideal_negativo[1])**2\n)\n\ndf_normalized['Índice Similaridade'] = distancia_negativa / (distancia_positiva + distancia_negativa)\ndf_normalized['Rank'] = df_normalized['Índice Similaridade'].rank(ascending=False)"
  },
  {
    "objectID": "fuzzy_topsis_analise_acoes.html#resultado-final",
    "href": "fuzzy_topsis_analise_acoes.html#resultado-final",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "Resultado Final",
    "text": "Resultado Final\n\n\nMostrar/Ocultar Código\nresultado = df_normalized[['Ticker', 'Retorno Esperado (%)', 'Risco (%)', 'Índice Similaridade', 'Rank']].sort_values(by='Rank')\nresultado\n\n\n\n\n\n\n\n\n\nTicker\nRetorno Esperado (%)\nRisco (%)\nÍndice Similaridade\nRank\n\n\n\n\n5\nMRFG3.SA\n121.350365\n47.075397\n0.649640\n1.0\n\n\n4\nJBSS3.SA\n82.872584\n41.321213\n0.627660\n2.0\n\n\n6\nTSN\n10.791430\n22.756921\n0.522833\n3.0\n\n\n3\nHRL\n-1.237448\n21.940254\n0.492352\n4.0\n\n\n2\nGIS\n-44.667148\n24.262767\n0.381066\n5.0\n\n\n1\nBRFS3.SA\n-5.995730\n38.618763\n0.312154\n6.0\n\n\n0\nBEEF3.SA\n19.952812\n52.777333\n0.300945\n7.0"
  },
  {
    "objectID": "analise_acoes_gerado.html",
    "href": "analise_acoes_gerado.html",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "",
    "text": "Mostrar/Ocultar Código\n# Instalar as bibliotecas equivalentes no Python\n!pip install pandas numpy matplotlib seaborn scikit-learn yfinance statsmodels openpyxl prophet\n\n\nRequirement already satisfied: pandas in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (2.2.2)\nRequirement already satisfied: numpy in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (1.26.4)\nRequirement already satisfied: matplotlib in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (3.9.2)\nRequirement already satisfied: seaborn in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (0.13.2)\nRequirement already satisfied: scikit-learn in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (1.5.1)\nRequirement already satisfied: yfinance in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (0.2.63)\nRequirement already satisfied: statsmodels in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (0.14.2)\nRequirement already satisfied: openpyxl in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (3.1.5)\nRequirement already satisfied: prophet in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (1.1.7)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: packaging&gt;=20.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\nRequirement already satisfied: pillow&gt;=8 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: scipy&gt;=1.6.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib&gt;=1.2.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: requests&gt;=2.31 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (2.32.3)\nRequirement already satisfied: multitasking&gt;=0.0.7 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (0.0.11)\nRequirement already satisfied: platformdirs&gt;=2.0.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (3.10.0)\nRequirement already satisfied: frozendict&gt;=2.3.4 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (2.4.2)\nRequirement already satisfied: peewee&gt;=3.16.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (3.18.1)\nRequirement already satisfied: beautifulsoup4&gt;=4.11.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (4.12.3)\nRequirement already satisfied: curl_cffi&gt;=0.7 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (0.11.3)\nRequirement already satisfied: protobuf&gt;=3.19.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (4.25.3)\nRequirement already satisfied: websockets&gt;=13.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (15.0.1)\nRequirement already satisfied: patsy&gt;=0.5.6 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from statsmodels) (0.5.6)\nRequirement already satisfied: et-xmlfile in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\nRequirement already satisfied: cmdstanpy&gt;=1.0.4 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (1.2.5)\nRequirement already satisfied: holidays&lt;1,&gt;=0.25 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (0.74)\nRequirement already satisfied: tqdm&gt;=4.36.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (4.66.5)\nRequirement already satisfied: importlib_resources in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (6.5.2)\nRequirement already satisfied: soupsieve&gt;1.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from beautifulsoup4&gt;=4.11.1-&gt;yfinance) (2.5)\nRequirement already satisfied: stanio&lt;2.0.0,&gt;=0.4.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from cmdstanpy&gt;=1.0.4-&gt;prophet) (0.5.1)\nRequirement already satisfied: cffi&gt;=1.12.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from curl_cffi&gt;=0.7-&gt;yfinance) (1.17.1)\nRequirement already satisfied: certifi&gt;=2024.2.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from curl_cffi&gt;=0.7-&gt;yfinance) (2024.12.14)\nRequirement already satisfied: six in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from patsy&gt;=0.5.6-&gt;statsmodels) (1.16.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from requests&gt;=2.31-&gt;yfinance) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from requests&gt;=2.31-&gt;yfinance) (3.7)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from requests&gt;=2.31-&gt;yfinance) (2.2.3)\nRequirement already satisfied: colorama in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from tqdm&gt;=4.36.1-&gt;prophet) (0.4.6)\nRequirement already satisfied: pycparser in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from cffi&gt;=1.12.0-&gt;curl_cffi&gt;=0.7-&gt;yfinance) (2.21)"
  },
  {
    "objectID": "analise_acoes_gerado.html#bibliotecas",
    "href": "analise_acoes_gerado.html#bibliotecas",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "",
    "text": "Mostrar/Ocultar Código\n# Instalar as bibliotecas equivalentes no Python\n!pip install pandas numpy matplotlib seaborn scikit-learn yfinance statsmodels openpyxl prophet\n\n\nRequirement already satisfied: pandas in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (2.2.2)\nRequirement already satisfied: numpy in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (1.26.4)\nRequirement already satisfied: matplotlib in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (3.9.2)\nRequirement already satisfied: seaborn in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (0.13.2)\nRequirement already satisfied: scikit-learn in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (1.5.1)\nRequirement already satisfied: yfinance in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (0.2.63)\nRequirement already satisfied: statsmodels in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (0.14.2)\nRequirement already satisfied: openpyxl in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (3.1.5)\nRequirement already satisfied: prophet in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (1.1.7)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata&gt;=2022.7 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\nRequirement already satisfied: contourpy&gt;=1.0.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler&gt;=0.10 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools&gt;=4.22.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: packaging&gt;=20.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\nRequirement already satisfied: pillow&gt;=8 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: scipy&gt;=1.6.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib&gt;=1.2.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: requests&gt;=2.31 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (2.32.3)\nRequirement already satisfied: multitasking&gt;=0.0.7 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (0.0.11)\nRequirement already satisfied: platformdirs&gt;=2.0.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (3.10.0)\nRequirement already satisfied: frozendict&gt;=2.3.4 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (2.4.2)\nRequirement already satisfied: peewee&gt;=3.16.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (3.18.1)\nRequirement already satisfied: beautifulsoup4&gt;=4.11.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (4.12.3)\nRequirement already satisfied: curl_cffi&gt;=0.7 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (0.11.3)\nRequirement already satisfied: protobuf&gt;=3.19.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (4.25.3)\nRequirement already satisfied: websockets&gt;=13.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from yfinance) (15.0.1)\nRequirement already satisfied: patsy&gt;=0.5.6 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from statsmodels) (0.5.6)\nRequirement already satisfied: et-xmlfile in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\nRequirement already satisfied: cmdstanpy&gt;=1.0.4 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (1.2.5)\nRequirement already satisfied: holidays&lt;1,&gt;=0.25 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (0.74)\nRequirement already satisfied: tqdm&gt;=4.36.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (4.66.5)\nRequirement already satisfied: importlib_resources in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from prophet) (6.5.2)\nRequirement already satisfied: soupsieve&gt;1.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from beautifulsoup4&gt;=4.11.1-&gt;yfinance) (2.5)\nRequirement already satisfied: stanio&lt;2.0.0,&gt;=0.4.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from cmdstanpy&gt;=1.0.4-&gt;prophet) (0.5.1)\nRequirement already satisfied: cffi&gt;=1.12.0 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from curl_cffi&gt;=0.7-&gt;yfinance) (1.17.1)\nRequirement already satisfied: certifi&gt;=2024.2.2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from curl_cffi&gt;=0.7-&gt;yfinance) (2024.12.14)\nRequirement already satisfied: six in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from patsy&gt;=0.5.6-&gt;statsmodels) (1.16.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from requests&gt;=2.31-&gt;yfinance) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from requests&gt;=2.31-&gt;yfinance) (3.7)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from requests&gt;=2.31-&gt;yfinance) (2.2.3)\nRequirement already satisfied: colorama in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from tqdm&gt;=4.36.1-&gt;prophet) (0.4.6)\nRequirement already satisfied: pycparser in c:\\users\\kuiav\\anaconda3\\lib\\site-packages (from cffi&gt;=1.12.0-&gt;curl_cffi&gt;=0.7-&gt;yfinance) (2.21)"
  },
  {
    "objectID": "analise_acoes_gerado.html#download-dos-dados",
    "href": "analise_acoes_gerado.html#download-dos-dados",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "Download dos Dados",
    "text": "Download dos Dados\n\n\nMostrar/Ocultar Código\n# Importar as bibliotecas equivalentes no Python\nimport pandas as pd           # Manipulação de dados\nimport numpy as np            # Operações matemáticas\nimport matplotlib.pyplot as plt  # Gráficos\nimport seaborn as sns         # Gráficos\nimport yfinance as yf         # Dados de ações\nfrom statsmodels.tsa.api import ExponentialSmoothing, ARIMA # Modelos de séries temporais\nimport statsmodels.api as sm  # Modelagem estatística geral\nfrom prophet import Prophet   # Previsão de séries temporais\nimport datetime               # Manipulação de datas\nimport openpyxl               # Leitura e escrita de arquivos Excel"
  },
  {
    "objectID": "analise_acoes_gerado.html#preparação-dos-dados",
    "href": "analise_acoes_gerado.html#preparação-dos-dados",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "Preparação dos Dados",
    "text": "Preparação dos Dados\n\n\nMostrar/Ocultar Código\nimport pandas as pd\nfrom openpyxl import Workbook\nfrom openpyxl.utils.dataframe import dataframe_to_rows\nfrom openpyxl.styles import numbers\n\n# 8) Exporta Excel com uma aba por cenário\nwb = Workbook()\nwb.remove(wb.active)  # Remove aba padrão\n\nfor sc in ret_all['.rep'].unique():\n    df = ret_all[ret_all['.rep'] == sc].copy()\n\n    # Pivotar como no R\n    df = df[['date', 'asset', 'ret', 'vol']]\n    df_long = df.melt(id_vars=['date', 'asset'], var_name='metric', value_name='value')\n    df_long['col'] = df_long['metric'] + '_' + df_long['asset']\n    df_wide = df_long.pivot_table(index='date', columns='col', values='value').reset_index()\n    df_wide = df_wide.sort_values('date')\n\n    # Criar aba e adicionar dados\n    ws = wb.create_sheet(title=sc)\n    for r in dataframe_to_rows(df_wide, index=False, header=True):\n        ws.append(r)\n\n    # Formatar colunas numéricas\n    for col in ws.iter_cols(min_row=2, min_col=2):\n        for cell in col:\n            cell.number_format = '#,##0.00'\n\n# Salvar o arquivo\nwb.save(\"retornos_e_volatilidades.xlsx\")"
  },
  {
    "objectID": "analise_acoes_gerado.html#cálculo-de-retornos",
    "href": "analise_acoes_gerado.html#cálculo-de-retornos",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "Cálculo de Retornos",
    "text": "Cálculo de Retornos\n\n\nMostrar/Ocultar Código\n# Instala dependências\n!pip install -q PyPortfolioOpt pandas numpy openpyxl plotly scipy\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import dirichlet\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\n# 1) Parâmetros Monte Carlo\nN_PORTFOLIOS = 50_000\nRISK_FREE    = 0.0\n\n# 2) Carrega Excel e cenários\nxls    = pd.ExcelFile(\"retornos_e_volatilidades.xlsx\")\nsheets = xls.sheet_names  # [\"hist\",\"sim1\",\"sim2\",\"sim3\"]\n\n# 3) Prepara figura Plotly 2×2\nfig = make_subplots(\n    rows=2, cols=2,\n    subplot_titles=[f\"Cenário {sc}\" for sc in sheets],\n    horizontal_spacing=0.1, vertical_spacing=0.15\n)\n\n# 4) Loop: simulações, frontier e MaxSharpe\nfor idx, sc in enumerate(sheets):\n    # cálculo de linha/col\n    row = idx//2 + 1\n    col = idx%2 + 1\n\n    # 4.1) Retornos do cenário\n    df   = pd.read_excel(xls, sheet_name=sc, index_col=0, parse_dates=True)\n    rets = (\n        df.filter(regex=\"^ret_\")\n          .rename(columns=lambda c:c.replace(\"ret_\",\"\"))\n          .replace([np.inf,-np.inf], np.nan)\n          .dropna(axis=1, how=\"any\")\n    )\n    tickers = rets.columns.tolist()\n    mu  = rets.mean()\n    cov = rets.cov()\n\n    # 4.2) Simula carteiras\n    W = np.random.dirichlet(np.ones(len(tickers)), size=N_PORTFOLIOS)\n    port_rets  = W.dot(mu.values)\n    port_vars  = np.einsum('ij,jk,ik-&gt;i', W, cov.values, W)\n    port_risks = np.sqrt(port_vars)\n\n    # 4.3) Max Sharpe\n    sharpe = (port_rets - RISK_FREE) / port_risks\n    idx_sh  = np.nanargmax(sharpe)\n    opt_ret  = port_rets[idx_sh]\n    opt_risk = port_risks[idx_sh]\n\n    # 4.4) Fronteira eficiente empírica\n    df_mc   = pd.DataFrame({\"risk\":port_risks, \"ret\":port_rets})\n    df_mc   = df_mc.sort_values(\"ret\")\n    frontier = []\n    min_r = np.inf\n    for r, q in zip(df_mc[\"risk\"], df_mc[\"ret\"]):\n        if r &lt; min_r:\n            frontier.append((r,q))\n            min_r = r\n    frontier = np.array(frontier)\n\n    # 4.5) Adiciona traces a cada subplot\n    fig.add_trace(\n        go.Scatter(\n            x=df_mc[\"risk\"], y=df_mc[\"ret\"],\n            mode=\"markers\",\n            marker=dict(size=2, opacity=0.15, color=\"gray\"),\n            name=\"Simulações\",\n            showlegend=(idx==0)\n        ),\n        row, col\n    )\n    fig.add_trace(\n        go.Scatter(\n            x=frontier[:,0], y=frontier[:,1],\n            mode=\"lines\",\n            line=dict(color=\"red\", width=2),\n            name=\"Fronteira\",\n            showlegend=(idx==0)\n        ),\n        row, col\n    )\n    fig.add_trace(\n        go.Scatter(\n            x=[opt_risk], y=[opt_ret],\n            mode=\"markers\",\n            marker=dict(symbol=\"star\", size=14, color=\"gold\"),\n            name=\"Máx Sharpe\",\n            showlegend=(idx==0)\n        ),\n        row, col\n    )\n\n    # 4.6) Ajusta eixos\n    fig.update_xaxes(title_text=\"Risco σ\", row=row, col=col)\n    fig.update_yaxes(title_text=\"Retorno Exp.\", row=row, col=col)\n\n# 5) Layout geral\nfig.update_layout(\n    height=800, width=900,\n    title_text=\"Fronteiras Eficientes (Monte Carlo) e Máx Sharpe por Cenário\",\n    legend=dict(x=0.85, y=0.05)\n)\n\n# 6) Exibe\nfig.show()"
  },
  {
    "objectID": "analise_acoes_gerado.html#normalização-e-pesos-fuzzy-topsis",
    "href": "analise_acoes_gerado.html#normalização-e-pesos-fuzzy-topsis",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "Normalização e Pesos (Fuzzy TOPSIS)",
    "text": "Normalização e Pesos (Fuzzy TOPSIS)\n\n\nMostrar/Ocultar Código\n# 1) Instala dependências\n!pip install -q scipy pandas numpy openpyxl matplotlib\n\n# 2) Imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import differential_evolution\n\n# 3) Carrega os retornos simulados do cenário \"sim1\"\nxls = pd.ExcelFile(\"retornos_e_volatilidades.xlsx\")\ndf  = pd.read_excel(xls, sheet_name=\"sim1\", index_col=0, parse_dates=True)\n\n# 4) Extrai apenas as colunas de retorno\nrets = (df\n        .filter(regex=\"^ret_\")\n        .rename(columns=lambda c: c.replace(\"ret_\",\"\"))\n        .replace([np.inf, -np.inf], np.nan)\n        .dropna(axis=1, how=\"any\"))\n\ntickers = rets.columns.tolist()\nn = len(tickers)\n\n# 5) Estatísticas de Markowitz\nmu    = rets.mean().values        # retornos médios diários\nSigma = rets.cov().values         # covariância diária\n\n# 6) Parâmetros de alocação mínima\nmin_w = 0.05                      # cada ativo tem no mínimo 5%\nscale = 1 - n * min_w             # parte restante para distribuir\n\ngamma = 1.0                       # trade-off risco vs retorno\n\n# 7) Função‐objetivo (risk - γ·return)\ndef markowitz_obj(x):\n    # x em [0,1]^n  →  w_i ≥ min_w, soma(w)=1\n    raw = np.abs(x)\n    if raw.sum() == 0:\n        raw = np.ones_like(raw)\n    w = min_w + scale * raw / raw.sum()\n    ret  = mu.dot(w)\n    risk = np.sqrt(w @ Sigma @ w)\n    return risk - gamma * ret\n\n# 8) Bounds para DE em [0,1]\nbounds = [(0,1)] * n\n\n# 9) Executa Differential Evolution\nres = differential_evolution(\n    markowitz_obj,\n    bounds,\n    strategy     = 'best1bin',\n    popsize      = 15,\n    mutation     = (0.5, 1),\n    recombination= 0.7,\n    tol          = 1e-6,\n    maxiter      = 1000,\n    polish       = True,\n    seed         = 42\n)\n\n# 10) Transforma o vetor X em pesos w\nx_opt = np.abs(res.x)\nw_opt = min_w + scale * x_opt / x_opt.sum()\n\n# 11) Calcula métricas finais\nport_ret   = mu.dot(w_opt)\nport_risk  = np.sqrt(w_opt @ Sigma @ w_opt)\nsharpe     = port_ret / port_risk\n\n# 12) Exibe resultados\nprint(f\"\\n=== Alocação Ótima (Markowitz via DE) — cenário sim1 ===\\n\")\nfor tkr, w in zip(tickers, w_opt):\n    print(f\"  {tkr:10s}: {w*100:6.2f}%\")\nprint(f\"\\nRetorno Esperado Diário: {port_ret:.4f}\")\nprint(f\"Risco (σ diário)       : {port_risk:.4f}\")\nprint(f\"Sharpe Ratio (Rf=0)    : {sharpe:.4f}\")\n\nimport plotly.express as px\n\n# 1) Monte um DataFrame de pesos\ndf_w = pd.DataFrame({\n    \"Ativo\": tickers,\n    \"Peso\": w_opt\n})\n\n# 2) Gera o gráfico de barras interativo\nfig = px.bar(\n    df_w,\n    x=\"Ativo\",\n    y=\"Peso\",\n    title=\"Alocação Ótima de Ativos — sim1\",\n    text=df_w[\"Peso\"].apply(lambda x: f\"{x*100:.2f}%\")\n)\n\n# 3) Ajustes finos\nfig.update_traces(\n    marker_color=\"green\",\n    textposition=\"outside\"\n)\nfig.update_layout(\n    yaxis=dict(title=\"Peso (%)\", tickformat=\".1%\"),\n    xaxis_tickangle=-45,\n    uniformtext_minsize=8,\n    uniformtext_mode=\"hide\"\n)\n\n# 4) Exibe\nfig.show()\n\n\n\n=== Alocação Ótima (Markowitz via DE) — cenário sim1 ===\n\n  BEEF3.SA  :   5.00%\n  BRFS3.SA  :   5.00%\n  GIS       :  30.45%\n  HRL       :  33.92%\n  JBSS3.SA  :   9.47%\n  MRFG3.SA  :  11.15%\n  TSN       :   5.00%\n\nRetorno Esperado Diário: 0.0010\nRisco (σ diário)       : 0.0072\nSharpe Ratio (Rf=0)    : 0.1384"
  },
  {
    "objectID": "analise_acoes_gerado.html#cálculo-do-topsis",
    "href": "analise_acoes_gerado.html#cálculo-do-topsis",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "Cálculo do TOPSIS",
    "text": "Cálculo do TOPSIS\n\n\nMostrar/Ocultar Código\n# 1) Imports (supondo que já tenha numpy, pandas, plotly instalados)\n\nimport numpy as np\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\n\n# 2) Carrega retornos simulados do cenário \"sim1\"\nxls    = pd.ExcelFile(\"retornos_e_volatilidades.xlsx\")\ndf     = pd.read_excel(xls, sheet_name=\"sim1\", index_col=0, parse_dates=True)\nrets   = (df\n           .filter(regex=\"^ret_\")\n           .rename(columns=lambda c: c.replace(\"ret_\",\"\"))\n           .replace([np.inf,-np.inf], np.nan)\n           .dropna(axis=1, how=\"any\"))\n\n# 3) Vetor de pesos 'w_opt' já calculado anteriormente\n#    Exemplo: w_opt = np.array([...]) na mesma ordem de rets.columns\nweights = pd.Series(w_opt, index=rets.columns)\n\n# 4) Série de retornos da carteira\nport_ret = rets.dot(weights)\n\n# 5) Performance cumulativa (índice de riqueza)\n#    W₀ = 1, W_t = ∏_{i=1}^t (1 + r_i)\nwealth = (1 + port_ret).cumprod()\n\n# 6) Drawdown\n#    DD_t = (W_t - max_{s≤t} W_s) / max_{s≤t} W_s\nrunning_max = wealth.cummax()\ndrawdown    = (wealth - running_max) / running_max\nmax_dd      = drawdown.min()\n\n# 7) Monta gráfico interativo com Plotly\nfig = make_subplots(\n    rows=2, cols=1, shared_xaxes=True,\n    row_heights=[0.6, 0.4],\n    subplot_titles=[\n        \"Performance Cumulativa da Carteira Ótima (sim1)\",\n        f\"Drawdown Diário (Máx: {max_dd:.2%})\"\n    ]\n)\n\n# 7.1) Wealth index\nfig.add_trace(\n    go.Scatter(\n        x=wealth.index, y=wealth.values,\n        mode=\"lines\", name=\"Wealth Index\"\n    ),\n    row=1, col=1\n)\n\n# 7.2) Drawdown\nfig.add_trace(\n    go.Scatter(\n        x=drawdown.index, y=drawdown.values,\n        mode=\"lines\", name=\"Drawdown\",\n        fill='tozeroy', line=dict(color='crimson')\n    ),\n    row=2, col=1\n)\n\n# 8) Layout\nfig.update_yaxes(title_text=\"Índice de Riqueza\", row=1, col=1)\nfig.update_yaxes(title_text=\"Drawdown\", row=2, col=1, tickformat=\".0%\")\nfig.update_xaxes(title_text=\"Data\", row=2, col=1)\n\nfig.update_layout(\n    height=600, width=800,\n    showlegend=False,\n    title_text=\"Performance e Drawdown da Carteira Ótima — sim1\"\n)\n\nfig.show()"
  },
  {
    "objectID": "analise_acoes_gerado.html#resultado-final",
    "href": "analise_acoes_gerado.html#resultado-final",
    "title": "Fuzzy TOPSIS - Análise de Ações",
    "section": "Resultado Final",
    "text": "Resultado Final"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre Nós",
    "section": "",
    "text": "Daniel K Junior\nArthur Lauffer\nDavi Kemper\nJoão Niquele"
  },
  {
    "objectID": "about.html#sumário",
    "href": "about.html#sumário",
    "title": "Sobre Nós",
    "section": "",
    "text": "Daniel K Junior\nArthur Lauffer\nDavi Kemper\nJoão Niquele"
  },
  {
    "objectID": "about.html#arthur-lauffer",
    "href": "about.html#arthur-lauffer",
    "title": "Sobre Nós",
    "section": "Arthur Lauffer",
    "text": "Arthur Lauffer\n\nCargo: É analista de BI e estudante de Ciência de Dados para Negócios na FAE Business School. Ele administra sua própria empresa de BI, prestando serviços para outras empresas, e também gerencia uma empresa de SaaS focada em projetos de longo prazo. Com grande experiência em Power BI, ele desenvolve dashboards e modelos de dados para diversas áreas, incluindo vendas, RH e faturamento. Além disso, atua como administrador do Workspace do Google da sua empresa. No tempo livre, tem interesse em música eletrônica e está organizando a festa Synapse. 🔗 Portfolio"
  },
  {
    "objectID": "about.html#davi-kemper",
    "href": "about.html#davi-kemper",
    "title": "Sobre Nós",
    "section": "Daniel K Junior",
    "text": "Daniel K Junior\n\nCargo: Formado na Escola de Sargento das Armas no ano de 2021, decidiu fazer a transição de carreira para a área de Dados já no ínicio da faculdade, concluindo a transição no final do ano de 2024, hoje atua como Analista de BI na EZ Chart.\n🔗 Portfolio"
  },
  {
    "objectID": "about.html#davi-kemper-1",
    "href": "about.html#davi-kemper-1",
    "title": "Sobre Nós",
    "section": "Davi Kemper",
    "text": "Davi Kemper\n\nCargo: Estudante de Ciência de Dados na FAE, atuou como Analista de BI do grupo Metronorte. 🔗 Portfolio"
  },
  {
    "objectID": "about.html#joão-niquele",
    "href": "about.html#joão-niquele",
    "title": "Sobre Nós",
    "section": "João Niquele",
    "text": "João Niquele\n\nCargo: Estudante de Ciência de Dados na FAE 🔗 Portfolio"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Projeto Finanças",
    "section": "",
    "text": "Usaremos seguintes ações da bolsa :\n\nBRFS3: A BRF é uma empresa transnacional brasileira do ramo alimentício, fruto da fusão entre Sadia e Perdigão, duas das principais empresas de alimentos do Brasil.\nJBSS3: JBS é uma empresa brasileira do setor de alimentos fundada em 1953 em Goiás. A companhia opera no processamento de carnes bovina, suína, ovina, de frango, de peixe e plant-based, além de atuar no processamento de couros\nBEEF3: Minerva Foods é uma empresa brasileira de alimentos fundada em 1924 na cidade de Barretos. A companhia tem atuação na comercialização de carne in natura, couros, derivados, e na exportação de gado vivo, além de atuar no processamento de carnes.\nMRFG3: Marfrig Global Foods é uma empresa brasileira de alimentos. Fundada no ano 2000, é a segunda maior produtora de carne bovina do mundo e líder na produção de hambúrgueres.\nTSN: A Tyson Foods é uma empresa multinacional americana fundada por John W. Tyson em 1931 e sediada em Springdale, Arkansas, que opera na indústria alimentícia.\nHRL: A Hormel Foods Corporation é uma empresa alimentícia estadunidense com sede em Austin, Minnesota, conhecida pela fabricação do Spam. Em 24 de agosto de 2017, a empresa anunciou a compra da empresa brasileira Ceratti.\nGIS: General Mills é uma multinacional americana produtora de alimentos classificada na Fortune 500 e uma das 10 maiores empresas de alimentos do mundo. É sediada em Golden Valley, Minnesota, Minneapolis.\n\nUtilizamos a API Yahoo! Finance para conseguir os dados utilizados para as analises a seguir.\nAnalisando os dados em uma tabela:\n\n\nCode\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(timeSeries)\nlibrary(fPortfolio)\nlibrary(quantmod)\nlibrary(cowplot) \nlibrary(lattice)\nlibrary(timetk)\nlibrary(quantmod)\nlibrary(DT) \n\n\nTICKERS &lt;- c(\n  \"BRFS3.SA\",\n  \"JBSS3.SA\",\n  \"BEEF3.SA\",\n  \"MRFG3.SA\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n)\n\n\n\n\n\nportfolioPrices &lt;- NULL\nfor ( Ticker in TICKERS )\n  portfolioPrices &lt;- cbind(\n    portfolioPrices, \n    getSymbols(\n      Ticker,\n      src = \"yahoo\",\n      from = \"2019-01-01\",\n      auto.assign = FALSE\n    )[,4]\n  )\n\nportfolioPrices &lt;- portfolioPrices[apply(portfolioPrices, 1, function(x) all(!is.na(x))),]\n\ncolnames(portfolioPrices) &lt;- c(\n  \"BRFS3\",\n  \"JBSS3\",\n  \"BEEF3\",\n  \"MRFG3\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n)\n\n\n\n\nCode\n# Visualizar com DT\ndatatable(tail(portfolioPrices), options = list(pageLength = 10, scrollX = TRUE)) \n\n\n\n\n\n\nE então a gente faz uma analise temporal dos dados, tendo o eixo X sendo a variável tempo, e o eixo Y sendo o preço:\n\n\nCode\nportfolioPrices |&gt; as.data.frame() |&gt;\n  mutate(\n    time = seq_along(GIS)\n  ) |&gt;\n  pivot_longer(\n    !time,\n    names_to = \"Variables\",\n    values_to = \"Value\"  \n  ) |&gt;\n  group_by(Variables) |&gt;\n  plot_time_series(\n    time,\n    Value,\n    .interactive = F, # Change for TRUE for better visualization\n    .facet_ncol = 2,\n    .smooth = FALSE\n  ) +\n  theme(\n    strip.background = element_rect(fill = \"white\", colour = \"white\")\n  )"
  },
  {
    "objectID": "page3.html",
    "href": "page3.html",
    "title": "Ciência de Dados para Negócios: Big Data for Finance Project",
    "section": "",
    "text": "Resumo\n\n\n\n\nteste de futuro para as ações\n\n\n\n\nIntro\nescrever\n\nR\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(modeltime)\nlibrary(timetk)\nlibrary(purrr)\nlibrary(tidyquant)\nlibrary(tsibble)\nlibrary(prophet)\nlibrary(feasts)\nlibrary(fable)\nlibrary(fabletools)\nlibrary(lubridate)\nlibrary(tictoc)\n\n\nCarregamos os dados:\n\n\nCode\ntickers &lt;- c(\n         \"BRFS3.SA\",\n  \"JBSS3.SA\",\n  \"BEEF3.SA\",\n  \"MRFG3.SA\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n)\n\n\nEntão baixo os dados via Yahoo!Finance:\n\n\nCode\nportfolioPrices &lt;- NULL\n  for ( Ticker in tickers )\n    portfolioPrices &lt;- cbind(\n      portfolioPrices, \n      quantmod::getSymbols.yahoo(\n        Ticker,\n        from = \"2019-01-01\",\n        auto.assign = FALSE\n      )[,4]\n    )\n\nportfolioPrices &lt;- portfolioPrices[apply(portfolioPrices, 1, function(x) all(!is.na(x))),]\n\ncolnames(portfolioPrices) &lt;- c(\n  \"BRFS3.SA\",\n  \"JBSS3.SA\",\n  \"BEEF3.SA\",\n  \"MRFG3.SA\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n)\n\n# Visualizar com DT\n#DT::datatable(tail(portfolioPrices), options = list(pageLength = 10, scrollX = TRUE)) \n\n\nVisualizando os dados dos nossos últimos retornos dos preços, temos:\n\n\nCode\nlog_returns &lt;- log(portfolioPrices) - log(lag(portfolioPrices))\nlog_returns &lt;- na.omit(log_returns)\nlog_returns &lt;- log_returns |&gt; \n  timetk::tk_tbl(preserve_index = TRUE, rename_index = \"date\")\n\ntail(log_returns)\n\n\n\n  \n\n\n\n\n\nCode\nln_returns &lt;- log_returns\n\nln_returns |&gt; as.data.frame() |&gt;\n  dplyr::mutate(\n    time = seq_along( TSN )\n  ) |&gt; select(-date) |&gt;\n  tidyr::pivot_longer(\n    !time,\n    names_to = \"Variables\",\n    values_to = \"Value\"  \n      ) |&gt;\n  dplyr::group_by(Variables) |&gt;\n  timetk::plot_time_series(\n    time,\n    Value,\n    .interactive = F, # Change for TRUE for better visualization\n    .facet_ncol = 2,\n    .smooth = FALSE\n  ) +\n  ggplot2::theme(\n    strip.background = ggplot2::element_rect(fill = \"white\", colour = \"white\")\n  )\n\n\n\n\n\n\n\n\n\n\nModelagem com fpp3 e validação cruzada temporal\nPrecisaremos fazer um forecasting de curto prazo com nossos dados históricos de retornos pra formularmos nossas recomendações posteriores de compra, venda e espera:\n\nVamos começar com uma série por vez \\(\\Rightarrow\\) TSN\n\n\n\nCode\n# Primeiro converto pra tsibble\n\nlnretTSN &lt;- log_returns |&gt; \n  select(date, TSN) |&gt; \n  as_tsibble(index = date)\n\nglimpse(lnretTSN)\n\n\nRows: 1,560\nColumns: 2\n$ date &lt;date&gt; 2019-01-03, 2019-01-04, 2019-01-07, 2019-01-08, 2019-01-09, 2019…\n$ TSN  &lt;dbl&gt; 0.0211432803, 0.0122208208, 0.0160060857, 0.0264099860, -0.017528…\n\n\n\n\nCode\ntreino &lt;- lnretTSN |&gt;\n  filter_index(~\"2025-01-01\")\n\n\nWar models\n\n\nCode\ntic()\n\nModelos &lt;- treino |&gt;\n  model(\n    AjusteExp = ETS(TSN ~ error(\"A\") + trend(\"N\") + season(\"N\")), # Ajuste Exponencial com auto\n    \n    AjExp_aditivo = ETS(TSN ~ error(\"A\") + trend(\"A\") + season(\"A\")), # Ajuste Exponencial Aditivo\n    \n    AjExp_multiplicativo = ETS(TSN ~ error(\"M\") + trend(\"A\") + season(\"M\")), # Ajuste Exponencial Multiplicativo\n    \n    Croston = CROSTON(TSN), # Modelo Croston\n    \n    HoltWinters = ETS(TSN ~ error(\"M\") + trend(\"Ad\") + season(\"M\")), # Holt Winters\n    \n    Holt = ETS(TSN ~ error(\"A\") + trend(\"A\") + season(\"N\")), # Holt\n    \n    HoltAmort = ETS(TSN ~ error(\"A\") + trend(\"Ad\", phi = 0.9) + season(\"N\")), # Holt Amortecida\n    \n    Regr_Comp = TSLM(TSN ~ trend() + season()), # Regressao com tendencia e sazonalidade auto\n    \n    Regr_Harmonica = TSLM(TSN ~ trend() + fourier(K = 2)), # Regressao harmonica\n    \n    Regr_Quebras = TSLM(TSN ~ trend(knots = c(2018, 2019, 2020))), # Regressao com quebras estruturais\n    \n    Snaive = SNAIVE(TSN), # SNAIVE\n    \n    Naive = NAIVE(TSN), #NAIVE\n    \n    Media_Movel = ARIMA(TSN ~ pdq(0,0,1)), # Media Movel Simples\n    \n    autoARIMA = ARIMA(TSN, stepwise = FALSE, approx = FALSE), # Auto ARIMA\n    \n    autoARIMA_saz = ARIMA(TSN, stepwise = FALSE, approx = FALSE, seasonal = TRUE), # AutoARIMA Sazonal\n    \n    #    Regr_erros_ARIMA = auto.arima(TSN, xreg = fourier(K = 3), seasonal = FALSE), # Regressao com erros ARIMA\n    \n    ARIMA_saz_012011 = ARIMA(TSN ~ pdq(0,1,2) + PDQ(0,1,1)), # ARIMA Sazonal ordem 012011\n    \n    ARIMA_saz_210011 = ARIMA(TSN ~ pdq(2,1,0) + PDQ(0,1,1)), # ARIMA Sazonal ordem 210011\n    \n    ARIMA_saz_0301012 = ARIMA(TSN ~ 0 + pdq(3,0,1) + PDQ(0,1,2)), # ARIMA sazonal\n    \n    ARIMA_quad = ARIMA(TSN ~ I(trend()^2)), # ARIMA com tendencia temporal quadratica\n    \n    ARIMA_determ = ARIMA(TSN ~ 1 + trend() + pdq(d = 0)), # ARIMA com tendencia deterministica\n    \n    ARIMA_estocastico = ARIMA(TSN ~ pdq(d = 1)), # ARIMA com tendência estocastica\n    \n    Regr_Harm_dinamica = ARIMA(TSN ~ fourier(K=2) + PDQ(0,0,0)), # Regressao Harmonica Dinamica\n    \n    Regr_Harm_Din_MultSaz = ARIMA(TSN ~ PDQ(0, 0, 0) + pdq(d = 0) + fourier(period = 7*30, K = 10) + fourier(period = 7*30, K = 5)), \n    \n    Regr_Harm_Din_Saz = ARIMA(TSN ~ PDQ(0, 0, 0) + pdq(d = 0) + fourier(period = \"month\", K = 10) +\n                                fourier(period = \"year\", K = 2) ), # Rgr Harm Mult Saz Complexa\n    \n#    Auto_Prophet = prophet(TSN), # Auto prophet\n    \n#    Prophet_mult = prophet(TSN ~ season(period = \"month\", order = 2, type = \"multiplicative\")),\n    \n#    Prophet_aditivo = prophet(TSN ~ season(period = \"month\", order = 2, type = \"additive\")),\n    \n#    Prophet_geom = prophet(TSN ~ growth(\"geometric\") + season(period = \"month\", order = 2, type = \"multiplicative\")),\n    \n#    Prophet_memo = prophet(TSN ~ growth(\"geometric\") + season(period = \"month\", order = 5) +\n#                             season(period = \"year\", order = 2, type = \"multiplicative\")),\n    \n    Modelo_VAR = VAR(TSN, ic = \"bic\"), # Vetor Autoregressivo \n    \n    Random_Walk = RW(TSN ~ drift()), # Random Walk com drift\n    \n    Rede_Neural_AR = NNETAR(TSN, bootstrap =  TRUE)#, # Rede Neural com auto AR e bootstraping nos erros\n    \n    #    x11 = X_13ARIMA_SEATS(TSN ~ x11()) # X11 ARIMA Seats\n    \n  ) |&gt;\n  \n  forecast(h = \"24 months\") # Horizonte de projecao para os proximos 30 dias apos corte no treino\n\ntoc()  \n\n\n1.47 sec elapsed\n\n\nSelecionamos o melhor modelo (1 fold de validação cruzada somente):\n\n\nCode\nModelos |&gt;\n  accuracy(lnretTSN) |&gt;\n  arrange(RMSE) # Seleção da acuracia pelo menor RMSE para o conjunto de modelos\n\n\n\n  \n\n\n\nGero um cenário com o modelo:\n\n\nCode\nfit &lt;- lnretTSN |&gt;\n  model(\n    Regr_Quebras = TSLM(TSN ~ trend(knots = c(2018, 2019, 2020))), # Regressao com quebras estruturais\n  )\n\nsim &lt;- fit |&gt; generate(h = 30, times = 5, bootstrap = TRUE)\n\n\nPlotamos os forecasts com esse modelo pra três cenários distintos no futuro:\n\n\nCode\nlnretTSN |&gt;\n  filter_index(\"2025-01-01\"~.) |&gt;\n  ggplot(aes(x = date)) +\n  geom_line(aes(y = TSN)) +\n  geom_line(aes(y = .sim, colour = as.factor(.rep)),\n    data = sim) +\n  labs(title=\"Valores projetados de retornos de preços de contratos futuros da TSN\", y=\"$US\" ) +\n  guides(colour = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Primeiro converto pra tsibble\n\nlnretGIS &lt;- log_returns |&gt; \n  select(date, GIS) |&gt; \n  as_tsibble(index = date)\n\nglimpse(lnretGIS)\n\n\nRows: 1,560\nColumns: 2\n$ date &lt;date&gt; 2019-01-03, 2019-01-04, 2019-01-07, 2019-01-08, 2019-01-09, 2019…\n$ GIS  &lt;dbl&gt; 0.0154921374, 0.0200387411, 0.0164387227, 0.0149567729, -0.016440…\n\n\n\n\nCode\ntreino &lt;- lnretGIS |&gt;\n  filter_index(~\"2025-01-01\")\n\n\n\n\nCode\ntic()\n\nModelos &lt;- treino |&gt;\n  model(\n    AjusteExp = ETS(GIS ~ error(\"A\") + trend(\"N\") + season(\"N\")), # Ajuste Exponencial com auto\n    \n    AjExp_aditivo = ETS(GIS ~ error(\"A\") + trend(\"A\") + season(\"A\")), # Ajuste Exponencial Aditivo\n    \n    AjExp_multiplicativo = ETS(GIS ~ error(\"M\") + trend(\"A\") + season(\"M\")), # Ajuste Exponencial Multiplicativo\n    \n    Croston = CROSTON(GIS), # Modelo Croston\n    \n    HoltWinters = ETS(GIS ~ error(\"M\") + trend(\"Ad\") + season(\"M\")), # Holt Winters\n    \n    Holt = ETS(GIS ~ error(\"A\") + trend(\"A\") + season(\"N\")), # Holt\n    \n    HoltAmort = ETS(GIS ~ error(\"A\") + trend(\"Ad\", phi = 0.9) + season(\"N\")), # Holt Amortecida\n    \n    Regr_Comp = TSLM(GIS ~ trend() + season()), # Regressao com tendencia e sazonalidade auto\n    \n    Regr_Harmonica = TSLM(GIS ~ trend() + fourier(K = 2)), # Regressao harmonica\n    \n    Regr_Quebras = TSLM(GIS ~ trend(knots = c(2018, 2019, 2020))), # Regressao com quebras estruturais\n    \n    Snaive = SNAIVE(GIS), # SNAIVE\n    \n    Naive = NAIVE(GIS), #NAIVE\n    \n    Media_Movel = ARIMA(GIS ~ pdq(0,0,1)), # Media Movel Simples\n    \n    autoARIMA = ARIMA(GIS, stepwise = FALSE, approx = FALSE), # Auto ARIMA\n    \n    autoARIMA_saz = ARIMA(GIS, stepwise = FALSE, approx = FALSE, seasonal = TRUE), # AutoARIMA Sazonal\n    \n    #    Regr_erros_ARIMA = auto.arima(TSN, xreg = fourier(K = 3), seasonal = FALSE), # Regressao com erros ARIMA\n    \n    ARIMA_saz_012011 = ARIMA(GIS ~ pdq(0,1,2) + PDQ(0,1,1)), # ARIMA Sazonal ordem 012011\n    \n    ARIMA_saz_210011 = ARIMA(GIS ~ pdq(2,1,0) + PDQ(0,1,1)), # ARIMA Sazonal ordem 210011\n    \n    ARIMA_saz_0301012 = ARIMA(GIS ~ 0 + pdq(3,0,1) + PDQ(0,1,2)), # ARIMA sazonal\n    \n    ARIMA_quad = ARIMA(GIS ~ I(trend()^2)), # ARIMA com tendencia temporal quadratica\n    \n    ARIMA_determ = ARIMA(GIS ~ 1 + trend() + pdq(d = 0)), # ARIMA com tendencia deterministica\n    \n    ARIMA_estocastico = ARIMA(GIS ~ pdq(d = 1)), # ARIMA com tendência estocastica\n    \n    Regr_Harm_dinamica = ARIMA(GIS ~ fourier(K=2) + PDQ(0,0,0)), # Regressao Harmonica Dinamica\n    \n    Regr_Harm_Din_MultSaz = ARIMA(GIS ~ PDQ(0, 0, 0) + pdq(d = 0) + fourier(period = 7*30, K = 10) + fourier(period = 7*30, K = 5)), \n    \n    Regr_Harm_Din_Saz = ARIMA(GIS ~ PDQ(0, 0, 0) + pdq(d = 0) + fourier(period = \"month\", K = 10) +\n                                fourier(period = \"year\", K = 2) ), # Rgr Harm Mult Saz Complexa\n    \n#    Auto_Prophet = prophet(TSN), # Auto prophet\n    \n#    Prophet_mult = prophet(TSN ~ season(period = \"month\", order = 2, type = \"multiplicative\")),\n    \n#    Prophet_aditivo = prophet(TSN ~ season(period = \"month\", order = 2, type = \"additive\")),\n    \n#    Prophet_geom = prophet(TSN ~ growth(\"geometric\") + season(period = \"month\", order = 2, type = \"multiplicative\")),\n    \n#    Prophet_memo = prophet(TSN ~ growth(\"geometric\") + season(period = \"month\", order = 5) +\n#                             season(period = \"year\", order = 2, type = \"multiplicative\")),\n    \n    Modelo_VAR = VAR(GIS, ic = \"bic\"), # Vetor Autoregressivo \n    \n    Random_Walk = RW(GIS ~ drift()), # Random Walk com drift\n    \n    Rede_Neural_AR = NNETAR(GIS, bootstrap =  TRUE)#, # Rede Neural com auto AR e bootstraping nos erros\n    \n    #    x11 = X_13ARIMA_SEATS(TSN ~ x11()) # X11 ARIMA Seats\n    \n  ) |&gt;\n  \n  forecast(h = \"24 months\") # Horizonte de projecao para os proximos 30 dias apos corte no treino\n\ntoc()  \n\n\n1.22 sec elapsed\n\n\n\n\nCode\nfit &lt;- lnretGIS |&gt;\n  model(\n    Regr_Quebras = TSLM(GIS ~ trend(knots = c(2018, 2019, 2020))), # Regressao com quebras estruturais\n  )\n\nsim &lt;- fit |&gt; generate(h = 30, times = 5, bootstrap = TRUE)\n\n\n\n\nCode\nlnretTSN |&gt;\n  filter_index(\"2025-01-01\"~.) |&gt;\n  ggplot(aes(x = date)) +\n  geom_line(aes(y = TSN)) +\n  geom_line(aes(y = .sim, colour = as.factor(.rep)),\n    data = sim) +\n  labs(title=\"Valores projetados de retornos de preços de contratos futuros da SALESFORCE\", y=\"$US\" ) +\n  guides(colour = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n \n\n\n\nReferences\n\nMarkowitz, H. (1952). Portfolio Selection. The Journal of Finance, 7(1), 77–91.\nLink\nSharpe, W. F. (1966). Mutual Fund Performance. The Journal of Business, 39(1), 119–138.\nLink\nElton, E. J., Gruber, M. J., Brown, S. J., & Goetzmann, W. N. (2007). Modern Portfolio Theory and Investment Analysis (9th ed.). Wiley.\nHilpisch, Y. (2018). Python for Finance: Mastering Data-Driven Finance. O’Reilly Media."
  }
]