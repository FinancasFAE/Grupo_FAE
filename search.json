[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Projeto Finan√ßas",
    "section": "",
    "text": "Usaremos seguintes a√ß√µes da bolsa :\n\nBRFS3: A BRF √© uma empresa transnacional brasileira do ramo aliment√≠cio, fruto da fus√£o entre Sadia e Perdig√£o, duas das principais empresas de alimentos do Brasil.\nJBSS3: JBS √© uma empresa brasileira do setor de alimentos fundada em 1953 em Goi√°s. A companhia opera no processamento de carnes bovina, su√≠na, ovina, de frango, de peixe e plant-based, al√©m de atuar no processamento de couros\nBEEF3: Minerva Foods √© uma empresa brasileira de alimentos fundada em 1924 na cidade de Barretos. A companhia tem atua√ß√£o na comercializa√ß√£o de carne in natura, couros, derivados, e na exporta√ß√£o de gado vivo, al√©m de atuar no processamento de carnes.\nMRFG3: Marfrig Global Foods √© uma empresa brasileira de alimentos. Fundada no ano 2000, √© a segunda maior produtora de carne bovina do mundo e l√≠der na produ√ß√£o de hamb√∫rgueres.\nTSN: A Tyson Foods √© uma empresa multinacional americana fundada por John W. Tyson em 1931 e sediada em Springdale, Arkansas, que opera na ind√∫stria aliment√≠cia.\nHRL: A Hormel Foods Corporation √© uma empresa aliment√≠cia estadunidense com sede em Austin, Minnesota, conhecida pela fabrica√ß√£o do Spam. Em 24 de agosto de 2017, a empresa anunciou a compra da empresa brasileira Ceratti.\nGIS: General Mills √© uma multinacional americana produtora de alimentos classificada na Fortune 500 e uma das 10 maiores empresas de alimentos do mundo. √â sediada em Golden Valley, Minnesota, Minneapolis.\n\nUtilizamos a API Yahoo! Finance para conseguir os dados utilizados para as analises a seguir.\nAnalisando os dados em uma tabela:\n\n\nCode\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(timeSeries)\nlibrary(fPortfolio)\nlibrary(quantmod)\nlibrary(cowplot) \nlibrary(lattice)\nlibrary(timetk)\nlibrary(quantmod)\nlibrary(DT) \n\n\nTICKERS &lt;- c(\n  \"BRFS3.SA\",\n  \"JBSS3.SA\",\n  \"BEEF3.SA\",\n  \"MRFG3.SA\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n)\n\n\n\n\n\nportfolioPrices &lt;- NULL\nfor ( Ticker in TICKERS )\n  portfolioPrices &lt;- cbind(\n    portfolioPrices, \n    getSymbols(\n      Ticker,\n      src = \"yahoo\",\n      from = \"2019-01-01\",\n      auto.assign = FALSE\n    )[,4]\n  )\n\nportfolioPrices &lt;- portfolioPrices[apply(portfolioPrices, 1, function(x) all(!is.na(x))),]\n\ncolnames(portfolioPrices) &lt;- c(\n  \"BRFS3\",\n  \"JBSS3\",\n  \"BEEF3\",\n  \"MRFG3\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n)\n\n\n\n\nCode\n# Visualizar com DT\ndatatable(tail(portfolioPrices), options = list(pageLength = 10, scrollX = TRUE)) \n\n\n\n\n\n\nE ent√£o a gente faz uma analise temporal dos dados, tendo o eixo X sendo a vari√°vel tempo, e o eixo Y sendo o pre√ßo:\n\n\nCode\nportfolioPrices |&gt; as.data.frame() |&gt;\n  mutate(\n    time = seq_along(GIS)\n  ) |&gt;\n  pivot_longer(\n    !time,\n    names_to = \"Variables\",\n    values_to = \"Value\"  \n  ) |&gt;\n  group_by(Variables) |&gt;\n  plot_time_series(\n    time,\n    Value,\n    .interactive = F, # Change for TRUE for better visualization\n    .facet_ncol = 2,\n    .smooth = FALSE\n  ) +\n  theme(\n    strip.background = element_rect(fill = \"white\", colour = \"white\")\n  )"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre N√≥s",
    "section": "",
    "text": "Daniel K Junior\nArthur Lauffer\nDavi Kemper\nJo√£o Niquele"
  },
  {
    "objectID": "about.html#sum√°rio",
    "href": "about.html#sum√°rio",
    "title": "Sobre N√≥s",
    "section": "",
    "text": "Daniel K Junior\nArthur Lauffer\nDavi Kemper\nJo√£o Niquele"
  },
  {
    "objectID": "about.html#arthur-lauffer",
    "href": "about.html#arthur-lauffer",
    "title": "Sobre N√≥s",
    "section": "Arthur Lauffer",
    "text": "Arthur Lauffer\n\nCargo: √â analista de BI e estudante de Ci√™ncia de Dados para Neg√≥cios na FAE Business School. Ele administra sua pr√≥pria empresa de BI, prestando servi√ßos para outras empresas, e tamb√©m gerencia uma empresa de SaaS focada em projetos de longo prazo. Com grande experi√™ncia em Power BI, ele desenvolve dashboards e modelos de dados para diversas √°reas, incluindo vendas, RH e faturamento. Al√©m disso, atua como administrador do Workspace do Google da sua empresa. No tempo livre, tem interesse em m√∫sica eletr√¥nica e est√° organizando a¬†festa¬†Synapse. üîó Portfolio"
  },
  {
    "objectID": "about.html#davi-kemper",
    "href": "about.html#davi-kemper",
    "title": "Sobre N√≥s",
    "section": "Daniel K Junior",
    "text": "Daniel K Junior\n\nCargo: Formado na Escola de Sargento das Armas no ano de 2021, decidiu fazer a transi√ß√£o de carreira para a √°rea de Dados j√° no √≠nicio da faculdade, concluindo a transi√ß√£o no final do ano de 2024, hoje atua como Analista de BI na EZ Chart.\nüîó Portfolio"
  },
  {
    "objectID": "about.html#davi-kemper-1",
    "href": "about.html#davi-kemper-1",
    "title": "Sobre N√≥s",
    "section": "Davi Kemper",
    "text": "Davi Kemper\n\nCargo: Estudante de Ci√™ncia de Dados na FAE, atuou como Analista de BI do grupo Metronorte. üîó Portfolio"
  },
  {
    "objectID": "about.html#jo√£o-niquele",
    "href": "about.html#jo√£o-niquele",
    "title": "Sobre N√≥s",
    "section": "Jo√£o Niquele",
    "text": "Jo√£o Niquele\n\nCargo: Estudante de Ci√™ncia de Dados na FAE üîó Portfolio"
  },
  {
    "objectID": "Terceiro_Encontro.html#introdu√ß√£o-feature-engineering-em-dados-de-s√©ries-financeiras",
    "href": "Terceiro_Encontro.html#introdu√ß√£o-feature-engineering-em-dados-de-s√©ries-financeiras",
    "title": "Feature Engineering com s√©ries de pre√ßos de ativos financeiros",
    "section": "üìå Introdu√ß√£o: Feature Engineering em dados de s√©ries financeiras",
    "text": "üìå Introdu√ß√£o: Feature Engineering em dados de s√©ries financeiras\n\n\nMedindo a Volatilidade: Com e Sem GARCH\nA abordagem tradicional calcula a volatilidade como o desvio padr√£o dos retornos hist√≥ricos em uma janela m√≥vel de tamanho \\(N\\): (dias de negocia√ß√£o)\n\\[\n\\sigma_{\\text{hist}} = \\sqrt{\\frac{1}{N-1}\\sum_{i=1}^{N}(r_i - \\bar{r})^2}\n\\]\nVantagens:\n\nSimplicidade e facilidade de implementa√ß√£o.\n\nDesvantagens:\n\nAssume volatilidade constante durante a janela. (ou seja precisa de um range dias e n√£o √© capaz de medir o desvio ou o risco/volatilidade de um dia pro outro.)\nN√£o capta a persist√™ncia dos choques (efeito de clustering).\nN√£o reage dinamicamente a choques recentes.\n\n\n\nVolatilidade com o GARCH\nO modelo GARCH(1,1) estima a vari√¢ncia condicional de forma din√¢mica:\n\\[\n\\sigma_t^2 = \\omega + \\alpha \\epsilon_{t-1}^2 + \\beta \\sigma_{t-1}^2.\n\\]\nOnde: - \\(\\epsilon_{t-1}^2\\) reflete o impacto dos choques recentes. - \\(\\sigma_{t-1}^2\\) reflete a persist√™ncia da volatilidade do per√≠odo anterior. - \\(\\omega &gt; 0\\), \\(\\alpha \\geq 0\\) e \\(\\beta \\geq 0\\) s√£o par√¢metros estimados.\nA soma \\(\\alpha + \\beta\\) mede a persist√™ncia total da volatilidade:\n\nPr√≥ximo de 1: Choques t√™m efeitos duradouros; a volatilidade permanece alta por v√°rios per√≠odos.\nMenor que 1: Os choques se dissipam mais rapidamente; a volatilidade retorna ao seu n√≠vel m√©dio mais r√°pido.\n\nVantagens do GARCH:\n\nModela a volatilidade de forma din√¢mica.\nCaptura o efeito de ‚Äúclustering‚Äù dos choques.\nPermite previs√µes mais precisas da volatilidade futura.\n\nDesvantagens do GARCH:\n\nRequer estima√ß√£o de par√¢metros e pressup√µe uma estrutura espec√≠fica para a volatilidade.\nPode ser sens√≠vel √† escolha da distribui√ß√£o dos res√≠duos (por exemplo, normal vs.¬†\\(t\\) de Student).\n\n\nPython\n\n\n\n\nCode\n#import yfinance as yf\nfrom yahooquery import Ticker\nimport pandas as pd\nimport numpy as np\n#import matplotlib.pyplot as plt\n#import seaborn as sns\nfrom datetime import datetime\nfrom arch import arch_model # Lib do Python pra estimar as volatilidades (ARCH/GARCH)\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom plotnine import ggplot, aes, geom_line, facet_wrap, labs, theme, element_text, theme_minimal\n\n\n\n\nCode\n# Tickers for portfolio\nTICKERS = [\n  \"BRFS3.SA\",\n  \"JBSS3.SA\",\n  \"BEEF3.SA\",\n  \"MRFG3.SA\",\n  \"TSN\",\n  \"HRL\",\n  \"GIS\"\n]\n\n# Baixar os dados hist√≥ricos com yahooquery\ntickers = Ticker(TICKERS)\ndata = tickers.history(period=\"5y\")\n\n# Resetar o √≠ndice corretamente\ndata = data.reset_index()\n\n# O yahooquery retorna um MultiIndex, ent√£o √© preciso garantir que a coluna \"date\" exista corretamente\nif \"date\" not in data.columns:\n    raise ValueError(\"A coluna 'date' n√£o foi encontrada no dataset! Verifique a estrutura do DataFrame.\")\n\n# Selecionar apenas as colunas de interesse e reformatar\nportfolio_prices = data.pivot(index=\"date\", columns=\"symbol\", values=\"close\").reset_index()\n\n# Garantir que n√£o h√° valores ausentes\nportfolio_prices.dropna(inplace=True)\n\nportfolio_prices.head()\n\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\yahooquery\\utils\\__init__.py:1470: FutureWarning: 'S' is deprecated and will be removed in a future version. Please use 's' instead of 'S'.\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\yahooquery\\utils\\__init__.py:1470: FutureWarning: 'S' is deprecated and will be removed in a future version. Please use 's' instead of 'S'.\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\yahooquery\\utils\\__init__.py:1470: FutureWarning: 'S' is deprecated and will be removed in a future version. Please use 's' instead of 'S'.\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\yahooquery\\utils\\__init__.py:1470: FutureWarning: 'S' is deprecated and will be removed in a future version. Please use 's' instead of 'S'.\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\yahooquery\\utils\\__init__.py:1470: FutureWarning: 'S' is deprecated and will be removed in a future version. Please use 's' instead of 'S'.\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\yahooquery\\utils\\__init__.py:1470: FutureWarning: 'S' is deprecated and will be removed in a future version. Please use 's' instead of 'S'.\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\yahooquery\\utils\\__init__.py:1470: FutureWarning: 'S' is deprecated and will be removed in a future version. Please use 's' instead of 'S'.\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\yahooquery\\ticker.py:1333: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n\n\n\n\n\n\n\n\nsymbol\ndate\nBEEF3.SA\nBRFS3.SA\nGIS\nHRL\nJBSS3.SA\nMRFG3.SA\nTSN\n\n\n\n\n0\n2020-03-23\n8.20\n13.355227\n47.279999\n42.310001\n19.340000\n7.387873\n57.599998\n\n\n1\n2020-03-24\n8.40\n14.316651\n48.230000\n44.849998\n21.219999\n7.855208\n59.990002\n\n\n2\n2020-03-25\n8.19\n15.144808\n47.650002\n41.939999\n22.049999\n8.242997\n63.189999\n\n\n3\n2020-03-26\n7.70\n15.201922\n50.000000\n44.849998\n21.870001\n8.352373\n61.230000\n\n\n4\n2020-03-27\n7.80\n14.154827\n51.820000\n44.959999\n20.889999\n8.471693\n58.590000\n\n\n\n\n\n\n\nPlotamos os gr√°ficos das s√©ries temporais de pre√ßos\n\n\n\nCode\n# Retire o comando #| eval: false pra conseguir executar essa celula dentro do Quarto\nimport plotly.express as px\n\n# Certifique-se de que a coluna \"date\" est√° em formato datetime\nportfolio_prices['date'] = pd.to_datetime(portfolio_prices['date'])\n\n# Transformar os pre√ßos para o formato longo (melt) para facilitar o plot\nprices_long = portfolio_prices.melt(id_vars='date', var_name='Ativo', value_name='Valor')\n\nfig = px.line(prices_long, x='date', y='Valor', color='Ativo',\n              title='S√©ries Temporais de Pre√ßos')\nfig.show()\n\n\nmas essas s√©ries temporais tem um problema‚Ä¶.os pre√ßos est√£o em seus ‚Äún√≠veis‚Äù, e isso em an√°lise de s√©ries temporais n√£o √© o ideal. Precisamos trabalhar com as s√©ries estacion√°rias e analisar os retornos dos pre√ßos.\nA stationary time series is one whose statistical properties do not depend on the time at which the series is observed.18 Thus, time series with trends, or with seasonality, are not stationary ‚Äî the trend and seasonality will affect the value of the time series at different times. On the other hand, a white noise series is stationary ‚Äî it does not matter when you observe it, it should look much the same at any point in time.\nSome cases can be confusing ‚Äî a time series with cyclic behaviour (but with no trend or seasonality) is stationary. This is because the cycles are not of a fixed length, so before we observe the series we cannot be sure where the peaks and troughs of the cycles will be.\nIn general, a stationary time series will have no predictable patterns in the long-term. Time plots will show the series to be roughly horizontal (although some cyclic behaviour is possible), with constant variance.\n(Hyndman, R.J., & Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition, OTexts: Melbourne, Australia. https://otexts.com/fpp3/stationarity.html. Accessed on 2025/march.)\nEstacionar uma s√©rie temporal econ√¥mica √© importante pois:\n‚ÄúUma s√©rie temporal √© dita estacion√°ria se suas propriedades estat√≠sticas, como a m√©dia e a vari√¢ncia, permanecem constantes ao longo do tempo. Em outras palavras, n√£o h√° uma tend√™ncia determin√≠stica na s√©rie, e as flutua√ß√µes ao redor da m√©dia s√£o est√°veis. Se a s√©rie n√£o for estacion√°ria, suas previs√µes podem ser pouco confi√°veis, pois os padr√µes passados podem n√£o ser representativos do futuro.‚Äù (Gujarati & Porter, 2009, p.¬†753).\n\n\nCode\n# Calcular os log-retornos\nlog_returns = portfolio_prices.copy()\nlog_returns.iloc[:, 1:] = np.log(portfolio_prices.iloc[:, 1:]).diff()\n\n# Remover a primeira linha que cont√©m NaN ap√≥s a diferencia√ß√£o\nlog_returns = log_returns.dropna()\n\n\n\n\n\nCode\n# Retire o comando #| eval: false pra conseguir executar essa celula dentro do Quarto\n# Garantir que a coluna \"date\" esteja em formato datetime\nlog_returns['date'] = pd.to_datetime(log_returns['date'])\n\n# Transformar para formato longo\nlog_returns_long = log_returns.melt(id_vars='date', var_name='Ativo', value_name='Log_Retorno')\n\nfig = px.line(log_returns_long, x='date', y='Log_Retorno', color='Ativo',\n              title='S√©ries Temporais de Log-Retornos')\nfig.show()\n\n\nAnalisar as distribui√ß√µes dos retornos √© fundamental para entender o comportamento estat√≠stico dos ativos financeiros. Essa an√°lise nos permite identificar caracter√≠sticas importantes, como a presen√ßa de assimetria e caudas pesadas. Por exemplo, uma assimetria negativa indica que os retornos tendem a oscilar mais para valores baixos, sugerindo um risco maior de perdas acentuadas, enquanto uma assimetria positiva indica uma tend√™ncia para oscila√ß√µes para valores mais altos. Al√©m disso, observar a forma da distribui√ß√£o ajuda a avaliar se a hip√≥tese de normalidade √© v√°lida ou se √© necess√°rio adotar distribui√ß√µes alternativas, como a distribui√ß√£o \\(t\\) de Student, que captura melhor a ocorr√™ncia de eventos extremos. Essa compreens√£o √© crucial para a modelagem de riscos, desenvolvimento de estrat√©gias de investimento e aprimoramento dos modelos econom√©tricos utilizados na previs√£o dos pre√ßos.\n\n\nCode\n# Seleciona apenas as colunas dos ativos (excluindo a coluna \"date\")\nativos = log_returns.columns[1:]\n\n# Calcula a assimetria para cada ativo\nskewness = log_returns[ativos].skew()\n\n# Cria um DataFrame para visualizar os resultados\nskew_table = pd.DataFrame({\n    'Ativo': skewness.index,\n    'Skewness': skewness.values\n})\n\n# Adiciona a coluna que indica a dire√ß√£o da assimetria\nskew_table['Direcao'] = skew_table['Skewness'].apply(\n    lambda x: '√Ä direita' if x &gt; 0 else ('√Ä esquerda' if x &lt; 0 else 'Sim√©trica')\n)\n\n# Exibe a tabela atualizada\nskew_table\n\n\n\n\n\n\n\n\n\nAtivo\nSkewness\nDirecao\n\n\n\n\n0\nBEEF3.SA\n-0.322431\n√Ä esquerda\n\n\n1\nBRFS3.SA\n0.334181\n√Ä direita\n\n\n2\nGIS\n-0.307135\n√Ä esquerda\n\n\n3\nHRL\n-0.358598\n√Ä esquerda\n\n\n4\nJBSS3.SA\n0.526435\n√Ä direita\n\n\n5\nMRFG3.SA\n-0.079424\n√Ä esquerda\n\n\n6\nTSN\n-0.945498\n√Ä esquerda\n\n\n\n\n\n\n\nAgora teremos que ver se o range de nossa sele√ß√£o de an√°lise ter√° mais retornos positivos do que negativos, olhando os histogramas:\n\n\n\nCode\n# Retire o comando #| eval: false caso queira executar essa celula\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Transformar os log-retornos para formato longo (melt)\nlog_returns_long = log_returns.melt(id_vars=[\"date\"], var_name=\"Ativo\", value_name=\"Log_Retorno\")\n\n# Criar gr√°fico com Seaborn\nplt.figure(figsize=(12, 8))\ng = sns.FacetGrid(log_returns_long, col=\"Ativo\", col_wrap=2, sharex=False, sharey=False)\ng.map_dataframe(sns.histplot, x=\"Log_Retorno\", kde=True, bins=30, color=\"black\", alpha=0.5)\n\n# Ajustar t√≠tulo dos gr√°ficos\ng.set_titles(col_template=\"{col_name}\")\n\n# Melhorar layout\nplt.tight_layout()\nplt.show()\n\n\nComo medida de risco, utilizamos as vari√¢ncias condicionais (volatilidades) para lidar melhor com a varia√ß√£o di√°ria dos log-retornos dos pre√ßos.\n\nVolatilidade com desvio-padr√£o\nA volatilidade hist√≥rica pode ser medida como o desvio-padr√£o dos log-retornos calculado em uma janela m√≥vel de \\(N\\) dias de negocia√ß√£o.\nNeste exemplo, adotamos uma janela m√≥vel de 5 dias (aproximadamente uma semana de negocia√ß√£o. Para um m√™s de negocia√ß√£o, utilizar 22 e um ano 252) para capturar a volatilidade di√°ria dos ativos.\nVantagens:\n\nSimplicidade e facilidade de implementa√ß√£o.\n\nDesvantagens:\n\nAssume volatilidade constante durante a janela.\nN√£o capta a persist√™ncia dos choques.\nN√£o reage dinamicamente a choques recentes.\n\n\n\nCode\n# Calcular a volatilidade hist√≥rica com uma janela m√≥vel de 5 dias\n\n# Supondo que 'log_returns' j√° foi calculado e possui a coluna 'date' e os log-retornos dos ativos\nwindow = 5\n\n# Cria um DataFrame para armazenar a volatilidade hist√≥rica\nvol_hist = pd.DataFrame({'date': log_returns[\"date\"]})\n\n# Calcula o desvio-padr√£o m√≥vel (volatilidade) para cada ativo\nfor col in log_returns.columns[1:]:\n    vol_hist[col] = log_returns[col].rolling(window=window).std()\n\n# Exibe as ultimas linhas do DataFrame de volatilidade hist√≥rica\n#print(vol_hist.head()) # 5 primeiros ser√£o NaN\nprint(vol_hist.tail())\n\n\n            date  BEEF3.SA  BRFS3.SA       GIS       HRL  JBSS3.SA  MRFG3.SA  \\\n1238  2025-03-14  0.031093  0.024722  0.024976  0.014724  0.015667  0.024863   \n1239  2025-03-17  0.031816  0.026581  0.028208  0.015502  0.016132  0.028757   \n1240  2025-03-18  0.022213  0.040627  0.021501  0.014557  0.073009  0.036127   \n1241  2025-03-19  0.021905  0.039398  0.015938  0.007907  0.073728  0.035161   \n1242  2025-03-20  0.033103  0.034645  0.016877  0.007681  0.071088  0.039908   \n\n           TSN  \n1238  0.011254  \n1239  0.011458  \n1240  0.011033  \n1241  0.006089  \n1242  0.006956  \n\n\nPlotando temos:\n\n\n\nCode\n# Retire o comando #| eval: false pra conseguir executar essa celula dentro do Quarto\n# Certificar que \"date\" √© datetime (j√° feito)\nvol_hist['date'] = pd.to_datetime(vol_hist['date'])\n\n# Transformar para formato longo\nvol_hist_long = vol_hist.melt(id_vars='date', var_name='Ativo', value_name='Volatilidade_Hist')\n\nfig = px.line(vol_hist_long, x='date', y='Volatilidade_Hist', color='Ativo',\n              title='Volatilidade Hist√≥rica (Desvio-Padr√£o) com janela de 5 dias')\nfig.show()\n\n\n\n\nVolatilidade com GARCH(1,1)\nO desvio-padr√£o assume que precisaremos de um range maior do que 2 pontos no tempo, o que limita nossa an√°lise pois a incompatibiliza, uma vez que precisaremos comparar os riscos di√°rios x retornos di√°rios (como feito anteriormente). Ou seja, n√£o podemos comparar retornos dia-a-dia x volatilidades (risco) de 5 em 5 dias p.¬†ex.\nOs modelos heteroced√°sticos (da fam√≠lia ARCH) estimam a vari√¢ncia condicional dos nossos dados, ou seja, em linguagem de finan√ßas, eles s√£o capazes de capturar as volatilidades ou risco dos retornos dos pre√ßos de ativos financeiros ponto a ponto no tempo, ou seja, dia a dia.\nO modelo GARCH(1,1) com distribui√ß√£o \\(t\\) assim√©trica n√£o est√° dispon√≠vel diretamente na maioria das bibliotecas Python. No entanto, podemos utilizar um GARCH(1,1) com uma distribui√ß√£o \\(t\\) padr√£o para estimar a vari√¢ncia condicional. O modelo √© representado por:\n\\[\nr_t = \\mu + \\epsilon_t\n\\]\n\\[\n\\epsilon_t = \\sigma_t z_t, \\quad z_t \\sim t_{\\nu}(0, 1)\n\\]\n\\[\n\\sigma_t^2 = \\omega + \\alpha \\epsilon_{t-1}^2 + \\beta \\sigma_{t-1}^2\n\\]\nOnde:\n\n\\(r_t\\) √© o log-retorno no tempo \\(t\\).\n\\(\\mu\\) √© a m√©dia dos retornos.\n\\(\\epsilon_t\\) √© o termo de erro, condicionado √†s informa√ß√µes passadas.\n\\(\\sigma_t^2\\) √© a vari√¢ncia condicional no tempo \\(t\\).\n\\(\\omega, \\alpha, \\beta\\) s√£o os par√¢metros a serem estimados, com \\(\\omega &gt; 0, \\alpha \\geq 0, \\beta \\geq 0\\).\n\\(z_t\\) segue uma distribui√ß√£o \\(t\\) de Student com \\(ŒΩ\\) graus de liberdade para capturar as caudas pesadas observadas em retornos financeiros.\n\nA soma \\(\\alpha + \\beta\\) √© frequentemente utilizada para medir a persist√™ncia da volatilidade: quanto mais pr√≥ximos de 1, maior a persist√™ncia dos choques na volatilidade.\nVamos estimar a vari√¢ncia condicional (\\(\\sigma^2_{t}\\) ) para cada ativo:\n\n\nCode\n# Estimar o modelo GARCH(1,1) e salvar vari√¢ncia condicional\nvar_condicional = pd.DataFrame({\"date\": log_returns[\"date\"]})\n\nfor col in log_returns.columns[1:]:\n    am = arch_model(log_returns[col], vol=\"Garch\", p=1, q=1, dist=\"t\")\n    res = am.fit(disp=\"off\")\n    var_condicional[col] = res.conditional_volatility ** 2\n\nvar_condicional.head()\n\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\nestimating the model parameters. The scale of y is 0.0007185. Parameter\nestimation work better when this value is between 1 and 1000. The recommended\nrescaling is 100 * y.\n\nThis warning can be disabled by either rescaling y before initializing the\nmodel or by setting rescale=False.\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\nestimating the model parameters. The scale of y is 0.0009805. Parameter\nestimation work better when this value is between 1 and 1000. The recommended\nrescaling is 100 * y.\n\nThis warning can be disabled by either rescaling y before initializing the\nmodel or by setting rescale=False.\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\nPositive directional derivative for linesearch\nSee scipy.optimize.fmin_slsqp for code meaning.\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\nestimating the model parameters. The scale of y is 0.0001789. Parameter\nestimation work better when this value is between 1 and 1000. The recommended\nrescaling is 100 * y.\n\nThis warning can be disabled by either rescaling y before initializing the\nmodel or by setting rescale=False.\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\nestimating the model parameters. The scale of y is 0.0002188. Parameter\nestimation work better when this value is between 1 and 1000. The recommended\nrescaling is 100 * y.\n\nThis warning can be disabled by either rescaling y before initializing the\nmodel or by setting rescale=False.\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\nestimating the model parameters. The scale of y is 0.000497. Parameter\nestimation work better when this value is between 1 and 1000. The recommended\nrescaling is 100 * y.\n\nThis warning can be disabled by either rescaling y before initializing the\nmodel or by setting rescale=False.\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\nestimating the model parameters. The scale of y is 0.000827. Parameter\nestimation work better when this value is between 1 and 1000. The recommended\nrescaling is 100 * y.\n\nThis warning can be disabled by either rescaling y before initializing the\nmodel or by setting rescale=False.\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\nestimating the model parameters. The scale of y is 0.000305. Parameter\nestimation work better when this value is between 1 and 1000. The recommended\nrescaling is 100 * y.\n\nThis warning can be disabled by either rescaling y before initializing the\nmodel or by setting rescale=False.\n\n\n\n\n\n\n\n\n\n\ndate\nBEEF3.SA\nBRFS3.SA\nGIS\nHRL\nJBSS3.SA\nMRFG3.SA\nTSN\n\n\n\n\n1\n2020-03-24\n0.001096\n0.012336\n0.001097\n0.001420\n0.005637\n0.001305\n0.001633\n\n\n2\n2020-03-25\n0.000934\n0.029594\n0.001012\n0.006134\n0.011258\n0.001398\n0.002033\n\n\n3\n2020-03-26\n0.000837\n0.046902\n0.000876\n0.002925\n0.005405\n0.001291\n0.002510\n\n\n4\n2020-03-27\n0.001090\n0.065082\n0.002087\n0.007534\n0.004224\n0.001003\n0.002688\n\n\n5\n2020-03-30\n0.000888\n0.084714\n0.001521\n0.000928\n0.005940\n0.000853\n0.002965\n\n\n\n\n\n\n\nVamos avaliar os par√¢metros estimados do modelo:\n\n\nCode\n# Inferir sobre os par√¢metros do modelo GARCH(1,1) para cada ativo do portf√≥lio\n\nparams_list = []\n\n# Iterar sobre cada ativo (exceto a coluna 'date')\nfor col in log_returns.columns[1:]:\n    am = arch_model(log_returns[col], vol=\"Garch\", p=1, q=1, dist=\"t\")\n    res = am.fit(disp=\"off\")\n    \n    par = res.params\n    alpha_val = par.get(\"alpha[1]\", None)\n    beta_val  = par.get(\"beta[1]\", None)\n    alpha_beta_sum = (alpha_val if alpha_val is not None else 0) + (beta_val if beta_val is not None else 0)\n    \n    # Interpreta√ß√£o curta\n    if alpha_beta_sum &gt;= 0.9:\n        interp = f\"Alta persist√™ncia (Œ±+Œ≤ = {alpha_beta_sum:.4f}).\"\n    else:\n        interp = f\"Baixa/moderada persist√™ncia (Œ±+Œ≤ = {alpha_beta_sum:.4f}).\"\n    \n    params_list.append({\n         \"Ativo\": col,\n         \"mu\": par.get(\"mu\", None),\n         \"omega\": par.get(\"omega\", None),\n         \"alpha\": alpha_val,\n         \"beta\": beta_val,\n         \"alpha+beta\": alpha_beta_sum,\n         \"nu\": par.get(\"nu\", None),\n         \"Interpretacao\": interp\n    })\n\ngarch_params = pd.DataFrame(params_list)\n\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\nestimating the model parameters. The scale of y is 0.0007185. Parameter\nestimation work better when this value is between 1 and 1000. The recommended\nrescaling is 100 * y.\n\nThis warning can be disabled by either rescaling y before initializing the\nmodel or by setting rescale=False.\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\nestimating the model parameters. The scale of y is 0.0009805. Parameter\nestimation work better when this value is between 1 and 1000. The recommended\nrescaling is 100 * y.\n\nThis warning can be disabled by either rescaling y before initializing the\nmodel or by setting rescale=False.\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:768: ConvergenceWarning: The optimizer returned code 8. The message is:\nPositive directional derivative for linesearch\nSee scipy.optimize.fmin_slsqp for code meaning.\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\nestimating the model parameters. The scale of y is 0.0001789. Parameter\nestimation work better when this value is between 1 and 1000. The recommended\nrescaling is 100 * y.\n\nThis warning can be disabled by either rescaling y before initializing the\nmodel or by setting rescale=False.\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\nestimating the model parameters. The scale of y is 0.0002188. Parameter\nestimation work better when this value is between 1 and 1000. The recommended\nrescaling is 100 * y.\n\nThis warning can be disabled by either rescaling y before initializing the\nmodel or by setting rescale=False.\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\nestimating the model parameters. The scale of y is 0.000497. Parameter\nestimation work better when this value is between 1 and 1000. The recommended\nrescaling is 100 * y.\n\nThis warning can be disabled by either rescaling y before initializing the\nmodel or by setting rescale=False.\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\nestimating the model parameters. The scale of y is 0.000827. Parameter\nestimation work better when this value is between 1 and 1000. The recommended\nrescaling is 100 * y.\n\nThis warning can be disabled by either rescaling y before initializing the\nmodel or by setting rescale=False.\n\nC:\\Users\\kuiav\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\nestimating the model parameters. The scale of y is 0.000305. Parameter\nestimation work better when this value is between 1 and 1000. The recommended\nrescaling is 100 * y.\n\nThis warning can be disabled by either rescaling y before initializing the\nmodel or by setting rescale=False.\n\n\n\nA soma \\(\\alpha + \\beta\\) √© um indicador crucial na modelagem GARCH para avaliar a persist√™ncia da volatilidade. Em termos pr√°ticos, os par√¢metros \\(\\alpha\\) e \\(\\beta\\) t√™m fun√ß√µes distintas:\n\n\\(\\alpha\\): Representa o impacto dos choques recentes (a inova√ß√£o ou termo de erro \\(\\epsilon_{t-1}^2\\) na volatilidade atual. Um valor mais alto de \\(\\alpha\\) indica que choques recentes t√™m um efeito maior em aumentar a volatilidade.\n\\(\\beta\\): Captura a persist√™ncia da volatilidade ao longo do tempo, ou seja, o efeito da volatilidade passada (\\(\\sigma_{t-1}^2)\\) sobre a volatilidade presente. Valores maiores de \\(\\beta\\) sugerem que a volatilidade tende a se manter elevada por um per√≠odo mais longo.\n\nQuando somamos esses dois par√¢metros, ou seja, quando calculamos \\(\\alpha + \\beta\\), obtemos uma medida da persist√™ncia total da volatilidade:\n\nSe \\(\\alpha + \\beta\\) estiver pr√≥ximo de 1, isso indica que os choques que afetam a volatilidade t√™m efeitos de longa dura√ß√£o. Em outras palavras, um choque na volatilidade tem um impacto que se dissipa muito lentamente, mantendo a volatilidade elevada por v√°rios per√≠odos.\nSe \\(\\alpha + \\beta\\) for significativamente menor que 1, os efeitos dos choques s√£o de curta dura√ß√£o e a volatilidade retorna rapidamente ao seu n√≠vel m√©dio ap√≥s um impacto.\n\nEm alguns casos, quando \\(\\alpha + \\beta = 1\\), o modelo √© denominado IGARCH (Integrated GARCH), o que implica que os choques t√™m efeitos persistentes permanentemente, ou seja, a volatilidade n√£o reverte para um valor m√©dio fixo.\nEsta caracter√≠stica √© particularmente importante na an√°lise de s√©ries financeiras, pois a persist√™ncia alta da volatilidade pode implicar maior risco de mercado e desafios na previs√£o dos retornos futuros. Assim, a soma \\(\\alpha + \\beta\\) serve como uma medida de ‚Äúmem√≥ria‚Äù dos choques, indicando se a volatilidade reage de forma passageira ou duradoura a eventos inesperados.\nGraficamente temos:\n\n\n\nCode\n# Retire o comando #| eval: false pra conseguir executar essa celula dentro do Quarto\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Para o ativo \"ZC=F\"\nreturns_zc = log_returns[['date', 'BEEF3.SA']].copy()\nvol_zc = var_condicional[['date', 'BEEF3.SA']].copy()\n\n# Converter \"date\" para datetime, se necess√°rio\nreturns_zc['date'] = pd.to_datetime(returns_zc['date'])\nvol_zc['date'] = pd.to_datetime(vol_zc['date'])\n\n# Criar figura com dois subplots compartilhando o eixo x\nfig = make_subplots(\n    rows=2, cols=1,\n    shared_xaxes=True,\n    vertical_spacing=0.05,\n    subplot_titles=(\"Retornos Di√°rios - BEEF3.SA\", \"Volatilidade Condicional (GARCH) - BEEF3.SA\")\n)\n\n# Adicionar o gr√°fico de retornos\nfig.add_trace(\n    go.Scatter(x=returns_zc['date'], y=returns_zc['ZC=F'], mode='lines', name='Retornos'),\n    row=1, col=1\n)\n\n# Adicionar o gr√°fico de volatilidade condicional\nfig.add_trace(\n    go.Scatter(x=vol_zc['date'], y=vol_zc['ZC=F'], mode='lines', name='Volatilidade'),\n    row=2, col=1\n)\n\nfig.update_layout(\n    height=600,\n    width=900,\n    title_text=\"Retorno vs. Volatilidade (GARCH) - ZC=F\",\n    xaxis2_title=\"Data\",\n    yaxis1_title=\"Retorno\",\n    yaxis2_title=\"Volatilidade Condicional\"\n)\n\nfig.show()\n\n\nEm alguns casos, a vari√¢ncia condicional pode apresentar grandes oscila√ß√µes se houver outliers nos retornos ou problemas de converg√™ncia do modelo. Verifique:\n\nQualidade e limpeza dos dados\nResumo do ajuste (par√¢metros \\(\\alpha,\\beta\\) plaus√≠veis?)\nDistribui√ß√£o (\\(t\\) vs.¬†normal)\nModelos alternativos (EGARCH, GJR-GARCH, etc.)\n\n\n\nPlotando retorno x risco\nAqui iremos visualizar o comportamento do ativo ZC=F, futuros de milho:\n\nEsse gr√°fico em Python, pode ser obtido com:\n\n\nCode\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Para o ativo \"ZC=F\"\nreturns_zc = log_returns[['date', 'BEEF3.SA']].copy()\nvol_zc = var_condicional[['date', 'BEEF3.SA']].copy()\n\n# Converter \"date\" para datetime, se necess√°rio\nreturns_zc['date'] = pd.to_datetime(returns_zc['date'])\nvol_zc['date'] = pd.to_datetime(vol_zc['date'])\n\n# Criar figura com dois subplots compartilhando o eixo x\nfig = make_subplots(\n    rows=2, cols=1,\n    shared_xaxes=True,\n    vertical_spacing=0.05,\n    subplot_titles=(\"Retornos Di√°rios - BEEF3.SA\", \"Volatilidade Condicional (GARCH) - BEEF3.SA\")\n)\n\n# Adicionar o gr√°fico de retornos\nfig.add_trace(\n    go.Scatter(x=returns_zc['date'], y=returns_zc['BEEF3.SA'], mode='lines', name='Retornos'),\n    row=1, col=1\n)\n\n# Adicionar o gr√°fico de volatilidade condicional\nfig.add_trace(\n    go.Scatter(x=vol_zc['date'], y=vol_zc['BEEF3.SA'], mode='lines', name='Volatilidade'),\n    row=2, col=1\n)\n\nfig.update_layout(\n    height=600,\n    width=900,\n    title_text=\"Retorno vs. Volatilidade (GARCH) - BEEF3.SA\",\n    xaxis2_title=\"Data\",\n    yaxis1_title=\"Retorno\",\n    yaxis2_title=\"Volatilidade Condicional\"\n)\n\nfig.show()"
  }
]